{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p_ky5FszZSh",
        "outputId": "a065bcf6-d991-47aa-b105-029f7dc0c205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.12474\tvalid_1's l1: 0.202508\n",
            "[400]\ttraining's l1: 0.0746857\tvalid_1's l1: 0.186713\n",
            "[600]\ttraining's l1: 0.0484242\tvalid_1's l1: 0.178418\n",
            "[800]\ttraining's l1: 0.0328702\tvalid_1's l1: 0.173155\n",
            "[1000]\ttraining's l1: 0.0231374\tvalid_1's l1: 0.17003\n",
            "[1200]\ttraining's l1: 0.0170938\tvalid_1's l1: 0.167826\n",
            "[1400]\ttraining's l1: 0.0129644\tvalid_1's l1: 0.166492\n",
            "[1600]\ttraining's l1: 0.00998153\tvalid_1's l1: 0.165687\n",
            "[1800]\ttraining's l1: 0.00780908\tvalid_1's l1: 0.165174\n",
            "[2000]\ttraining's l1: 0.00626257\tvalid_1's l1: 0.164797\n",
            "[2200]\ttraining's l1: 0.00511298\tvalid_1's l1: 0.16453\n",
            "[2400]\ttraining's l1: 0.00423438\tvalid_1's l1: 0.164344\n",
            "[2600]\ttraining's l1: 0.00352876\tvalid_1's l1: 0.164225\n",
            "[2800]\ttraining's l1: 0.00298945\tvalid_1's l1: 0.164111\n",
            "[3000]\ttraining's l1: 0.00253804\tvalid_1's l1: 0.164034\n",
            "[3200]\ttraining's l1: 0.00217207\tvalid_1's l1: 0.163951\n",
            "[3400]\ttraining's l1: 0.00188136\tvalid_1's l1: 0.163916\n",
            "[3600]\ttraining's l1: 0.00165329\tvalid_1's l1: 0.163889\n",
            "[3800]\ttraining's l1: 0.00145535\tvalid_1's l1: 0.163853\n",
            "[4000]\ttraining's l1: 0.00129559\tvalid_1's l1: 0.163839\n",
            "[4200]\ttraining's l1: 0.00115705\tvalid_1's l1: 0.163827\n",
            "Early stopping, best iteration is:\n",
            "[4181]\ttraining's l1: 0.00117012\tvalid_1's l1: 0.163825\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.122616\tvalid_1's l1: 0.208896\n",
            "[400]\ttraining's l1: 0.072667\tvalid_1's l1: 0.19543\n",
            "[600]\ttraining's l1: 0.0470788\tvalid_1's l1: 0.189237\n",
            "[800]\ttraining's l1: 0.0322404\tvalid_1's l1: 0.184736\n",
            "[1000]\ttraining's l1: 0.0228228\tvalid_1's l1: 0.181602\n",
            "[1200]\ttraining's l1: 0.0167952\tvalid_1's l1: 0.17949\n",
            "[1400]\ttraining's l1: 0.0128347\tvalid_1's l1: 0.178434\n",
            "[1600]\ttraining's l1: 0.00982015\tvalid_1's l1: 0.177715\n",
            "[1800]\ttraining's l1: 0.00773315\tvalid_1's l1: 0.177259\n",
            "[2000]\ttraining's l1: 0.00624667\tvalid_1's l1: 0.17699\n",
            "[2200]\ttraining's l1: 0.00510247\tvalid_1's l1: 0.176785\n",
            "[2400]\ttraining's l1: 0.00422959\tvalid_1's l1: 0.176601\n",
            "[2600]\ttraining's l1: 0.00354387\tvalid_1's l1: 0.176544\n",
            "Early stopping, best iteration is:\n",
            "[2651]\ttraining's l1: 0.0033943\tvalid_1's l1: 0.176524\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.122224\tvalid_1's l1: 0.218376\n",
            "[400]\ttraining's l1: 0.0726245\tvalid_1's l1: 0.202379\n",
            "[600]\ttraining's l1: 0.0468954\tvalid_1's l1: 0.194677\n",
            "[800]\ttraining's l1: 0.0321399\tvalid_1's l1: 0.189985\n",
            "[1000]\ttraining's l1: 0.0227458\tvalid_1's l1: 0.186861\n",
            "[1200]\ttraining's l1: 0.016674\tvalid_1's l1: 0.185044\n",
            "[1400]\ttraining's l1: 0.0125191\tvalid_1's l1: 0.183694\n",
            "[1600]\ttraining's l1: 0.00956661\tvalid_1's l1: 0.182869\n",
            "[1800]\ttraining's l1: 0.00743326\tvalid_1's l1: 0.182339\n",
            "[2000]\ttraining's l1: 0.00589606\tvalid_1's l1: 0.182027\n",
            "[2200]\ttraining's l1: 0.00474439\tvalid_1's l1: 0.181796\n",
            "[2400]\ttraining's l1: 0.0038986\tvalid_1's l1: 0.181674\n",
            "[2600]\ttraining's l1: 0.00324397\tvalid_1's l1: 0.181555\n",
            "[2800]\ttraining's l1: 0.0027362\tvalid_1's l1: 0.181499\n",
            "[3000]\ttraining's l1: 0.0023418\tvalid_1's l1: 0.181451\n",
            "[3200]\ttraining's l1: 0.00201126\tvalid_1's l1: 0.181406\n",
            "[3400]\ttraining's l1: 0.00174289\tvalid_1's l1: 0.181391\n",
            "[3600]\ttraining's l1: 0.00152803\tvalid_1's l1: 0.181367\n",
            "[3800]\ttraining's l1: 0.00134372\tvalid_1's l1: 0.181345\n",
            "Early stopping, best iteration is:\n",
            "[3895]\ttraining's l1: 0.00127003\tvalid_1's l1: 0.18134\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.119336\tvalid_1's l1: 0.224588\n",
            "[400]\ttraining's l1: 0.0714808\tvalid_1's l1: 0.211458\n",
            "[600]\ttraining's l1: 0.0461975\tvalid_1's l1: 0.202809\n",
            "[800]\ttraining's l1: 0.0314268\tvalid_1's l1: 0.198218\n",
            "[1000]\ttraining's l1: 0.0222768\tvalid_1's l1: 0.195064\n",
            "[1200]\ttraining's l1: 0.0164315\tvalid_1's l1: 0.193407\n",
            "[1400]\ttraining's l1: 0.0124776\tvalid_1's l1: 0.192208\n",
            "[1600]\ttraining's l1: 0.00964645\tvalid_1's l1: 0.191558\n",
            "[1800]\ttraining's l1: 0.00751636\tvalid_1's l1: 0.190997\n",
            "[2000]\ttraining's l1: 0.00598781\tvalid_1's l1: 0.190618\n",
            "[2200]\ttraining's l1: 0.00488197\tvalid_1's l1: 0.190416\n",
            "[2400]\ttraining's l1: 0.00401984\tvalid_1's l1: 0.190279\n",
            "[2600]\ttraining's l1: 0.0033137\tvalid_1's l1: 0.190176\n",
            "[2800]\ttraining's l1: 0.00278373\tvalid_1's l1: 0.190129\n",
            "[3000]\ttraining's l1: 0.00237749\tvalid_1's l1: 0.190076\n",
            "[3200]\ttraining's l1: 0.00203379\tvalid_1's l1: 0.190026\n",
            "[3400]\ttraining's l1: 0.00176518\tvalid_1's l1: 0.189981\n",
            "Early stopping, best iteration is:\n",
            "[3442]\ttraining's l1: 0.00171346\tvalid_1's l1: 0.189968\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.123961\tvalid_1's l1: 0.214649\n",
            "[400]\ttraining's l1: 0.0740082\tvalid_1's l1: 0.200691\n",
            "[600]\ttraining's l1: 0.0481176\tvalid_1's l1: 0.191499\n",
            "[800]\ttraining's l1: 0.0328936\tvalid_1's l1: 0.185318\n",
            "[1000]\ttraining's l1: 0.0235639\tvalid_1's l1: 0.181757\n",
            "[1200]\ttraining's l1: 0.0173461\tvalid_1's l1: 0.179325\n",
            "[1400]\ttraining's l1: 0.0129317\tvalid_1's l1: 0.177755\n",
            "[1600]\ttraining's l1: 0.0100274\tvalid_1's l1: 0.176797\n",
            "[1800]\ttraining's l1: 0.0078869\tvalid_1's l1: 0.176123\n",
            "[2000]\ttraining's l1: 0.00631536\tvalid_1's l1: 0.175655\n",
            "[2200]\ttraining's l1: 0.0051358\tvalid_1's l1: 0.175346\n",
            "[2400]\ttraining's l1: 0.00425056\tvalid_1's l1: 0.175171\n",
            "[2600]\ttraining's l1: 0.00356123\tvalid_1's l1: 0.175036\n",
            "[2800]\ttraining's l1: 0.00301683\tvalid_1's l1: 0.174884\n",
            "[3000]\ttraining's l1: 0.00257883\tvalid_1's l1: 0.174859\n",
            "[3200]\ttraining's l1: 0.00222656\tvalid_1's l1: 0.174802\n",
            "[3400]\ttraining's l1: 0.00194191\tvalid_1's l1: 0.174768\n",
            "[3600]\ttraining's l1: 0.00169105\tvalid_1's l1: 0.174748\n",
            "[3800]\ttraining's l1: 0.00148887\tvalid_1's l1: 0.174732\n",
            "[4000]\ttraining's l1: 0.00131389\tvalid_1's l1: 0.174717\n",
            "[4200]\ttraining's l1: 0.00116665\tvalid_1's l1: 0.174711\n",
            "Early stopping, best iteration is:\n",
            "[4137]\ttraining's l1: 0.00121861\tvalid_1's l1: 0.174708\n",
            "\n",
            "✅ CV MAE: 0.17727\n",
            "✅ submission.csv 저장 완료\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드 함수\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 함수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 존재하지 않습니다.\")\n",
        "\n",
        "    # ID 제거\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "    else:\n",
        "        train_id, test_id = None, None\n",
        "\n",
        "    # 숫자 / 범주형 컬럼 구분\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    # target_col 제외\n",
        "    if target_col in num_cols:\n",
        "        num_cols.remove(target_col)\n",
        "    if target_col in cat_cols:\n",
        "        cat_cols.remove(target_col)\n",
        "\n",
        "    # 결측치 처리: 숫자는 평균, 범주형은 최빈값\n",
        "    for col in num_cols:\n",
        "        train[col] = train[col].fillna(train[col].mean())\n",
        "        test[col] = test[col].fillna(train[col].mean())\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode)\n",
        "        test[col] = test[col].fillna(mode)\n",
        "\n",
        "    # 범주형 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "\n",
        "    # train/test 컬럼 맞추기\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측 함수 (KFold + LGBM)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"num_leaves\": 31,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "\n",
        "        model = lgb.train(\n",
        "        params,\n",
        "        lgb_train,\n",
        "        valid_sets=[lgb_train, lgb_val],\n",
        "        num_boost_round=10000,\n",
        "        callbacks=[\n",
        "            early_stopping(stopping_rounds=100),\n",
        "            log_evaluation(period=200)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장 함수\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0  # 컬럼 없으면 생성\n",
        "\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"✅ submission.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 파이프라인 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드 함수\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 함수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 존재하지 않습니다.\")\n",
        "\n",
        "    # ID 제거\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 숫자 / 범주형 컬럼 구분\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    # target_col 제외\n",
        "    if target_col in num_cols:\n",
        "        num_cols.remove(target_col)\n",
        "    if target_col in cat_cols:\n",
        "        cat_cols.remove(target_col)\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols:\n",
        "        train[col] = train[col].fillna(train[col].mean())\n",
        "        test[col] = test[col].fillna(train[col].mean())\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode)\n",
        "        test[col] = test[col].fillna(mode)\n",
        "\n",
        "    # 범주형 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "\n",
        "    # train/test 컬럼 맞추기\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측 함수 (KFold + LGBM)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"num_leaves\": 31,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=100),\n",
        "                log_evaluation(period=200)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장 함수\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission2.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission2.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 파이프라인 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3Seok0f290i",
        "outputId": "31988c43-dade-4c07-bb8c-46e39df6c87a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.12474\tvalid_1's l1: 0.202508\n",
            "[400]\ttraining's l1: 0.0746857\tvalid_1's l1: 0.186713\n",
            "[600]\ttraining's l1: 0.0484242\tvalid_1's l1: 0.178418\n",
            "[800]\ttraining's l1: 0.0328702\tvalid_1's l1: 0.173155\n",
            "[1000]\ttraining's l1: 0.0231374\tvalid_1's l1: 0.17003\n",
            "[1200]\ttraining's l1: 0.0170938\tvalid_1's l1: 0.167826\n",
            "[1400]\ttraining's l1: 0.0129644\tvalid_1's l1: 0.166492\n",
            "[1600]\ttraining's l1: 0.00998153\tvalid_1's l1: 0.165687\n",
            "[1800]\ttraining's l1: 0.00780908\tvalid_1's l1: 0.165174\n",
            "[2000]\ttraining's l1: 0.00626257\tvalid_1's l1: 0.164797\n",
            "[2200]\ttraining's l1: 0.00511298\tvalid_1's l1: 0.16453\n",
            "[2400]\ttraining's l1: 0.00423438\tvalid_1's l1: 0.164344\n",
            "[2600]\ttraining's l1: 0.00352876\tvalid_1's l1: 0.164225\n",
            "[2800]\ttraining's l1: 0.00298945\tvalid_1's l1: 0.164111\n",
            "[3000]\ttraining's l1: 0.00253804\tvalid_1's l1: 0.164034\n",
            "[3200]\ttraining's l1: 0.00217207\tvalid_1's l1: 0.163951\n",
            "[3400]\ttraining's l1: 0.00188136\tvalid_1's l1: 0.163916\n",
            "[3600]\ttraining's l1: 0.00165329\tvalid_1's l1: 0.163889\n",
            "[3800]\ttraining's l1: 0.00145535\tvalid_1's l1: 0.163853\n",
            "[4000]\ttraining's l1: 0.00129559\tvalid_1's l1: 0.163839\n",
            "[4200]\ttraining's l1: 0.00115705\tvalid_1's l1: 0.163827\n",
            "Early stopping, best iteration is:\n",
            "[4181]\ttraining's l1: 0.00117012\tvalid_1's l1: 0.163825\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.122616\tvalid_1's l1: 0.208896\n",
            "[400]\ttraining's l1: 0.072667\tvalid_1's l1: 0.19543\n",
            "[600]\ttraining's l1: 0.0470788\tvalid_1's l1: 0.189237\n",
            "[800]\ttraining's l1: 0.0322404\tvalid_1's l1: 0.184736\n",
            "[1000]\ttraining's l1: 0.0228228\tvalid_1's l1: 0.181602\n",
            "[1200]\ttraining's l1: 0.0167952\tvalid_1's l1: 0.17949\n",
            "[1400]\ttraining's l1: 0.0128347\tvalid_1's l1: 0.178434\n",
            "[1600]\ttraining's l1: 0.00982015\tvalid_1's l1: 0.177715\n",
            "[1800]\ttraining's l1: 0.00773315\tvalid_1's l1: 0.177259\n",
            "[2000]\ttraining's l1: 0.00624667\tvalid_1's l1: 0.17699\n",
            "[2200]\ttraining's l1: 0.00510247\tvalid_1's l1: 0.176785\n",
            "[2400]\ttraining's l1: 0.00422959\tvalid_1's l1: 0.176601\n",
            "[2600]\ttraining's l1: 0.00354387\tvalid_1's l1: 0.176544\n",
            "Early stopping, best iteration is:\n",
            "[2651]\ttraining's l1: 0.0033943\tvalid_1's l1: 0.176524\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.122224\tvalid_1's l1: 0.218376\n",
            "[400]\ttraining's l1: 0.0726245\tvalid_1's l1: 0.202379\n",
            "[600]\ttraining's l1: 0.0468954\tvalid_1's l1: 0.194677\n",
            "[800]\ttraining's l1: 0.0321399\tvalid_1's l1: 0.189985\n",
            "[1000]\ttraining's l1: 0.0227458\tvalid_1's l1: 0.186861\n",
            "[1200]\ttraining's l1: 0.016674\tvalid_1's l1: 0.185044\n",
            "[1400]\ttraining's l1: 0.0125191\tvalid_1's l1: 0.183694\n",
            "[1600]\ttraining's l1: 0.00956661\tvalid_1's l1: 0.182869\n",
            "[1800]\ttraining's l1: 0.00743326\tvalid_1's l1: 0.182339\n",
            "[2000]\ttraining's l1: 0.00589606\tvalid_1's l1: 0.182027\n",
            "[2200]\ttraining's l1: 0.00474439\tvalid_1's l1: 0.181796\n",
            "[2400]\ttraining's l1: 0.0038986\tvalid_1's l1: 0.181674\n",
            "[2600]\ttraining's l1: 0.00324397\tvalid_1's l1: 0.181555\n",
            "[2800]\ttraining's l1: 0.0027362\tvalid_1's l1: 0.181499\n",
            "[3000]\ttraining's l1: 0.0023418\tvalid_1's l1: 0.181451\n",
            "[3200]\ttraining's l1: 0.00201126\tvalid_1's l1: 0.181406\n",
            "[3400]\ttraining's l1: 0.00174289\tvalid_1's l1: 0.181391\n",
            "[3600]\ttraining's l1: 0.00152803\tvalid_1's l1: 0.181367\n",
            "[3800]\ttraining's l1: 0.00134372\tvalid_1's l1: 0.181345\n",
            "Early stopping, best iteration is:\n",
            "[3895]\ttraining's l1: 0.00127003\tvalid_1's l1: 0.18134\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.119336\tvalid_1's l1: 0.224588\n",
            "[400]\ttraining's l1: 0.0714808\tvalid_1's l1: 0.211458\n",
            "[600]\ttraining's l1: 0.0461975\tvalid_1's l1: 0.202809\n",
            "[800]\ttraining's l1: 0.0314268\tvalid_1's l1: 0.198218\n",
            "[1000]\ttraining's l1: 0.0222768\tvalid_1's l1: 0.195064\n",
            "[1200]\ttraining's l1: 0.0164315\tvalid_1's l1: 0.193407\n",
            "[1400]\ttraining's l1: 0.0124776\tvalid_1's l1: 0.192208\n",
            "[1600]\ttraining's l1: 0.00964645\tvalid_1's l1: 0.191558\n",
            "[1800]\ttraining's l1: 0.00751636\tvalid_1's l1: 0.190997\n",
            "[2000]\ttraining's l1: 0.00598781\tvalid_1's l1: 0.190618\n",
            "[2200]\ttraining's l1: 0.00488197\tvalid_1's l1: 0.190416\n",
            "[2400]\ttraining's l1: 0.00401984\tvalid_1's l1: 0.190279\n",
            "[2600]\ttraining's l1: 0.0033137\tvalid_1's l1: 0.190176\n",
            "[2800]\ttraining's l1: 0.00278373\tvalid_1's l1: 0.190129\n",
            "[3000]\ttraining's l1: 0.00237749\tvalid_1's l1: 0.190076\n",
            "[3200]\ttraining's l1: 0.00203379\tvalid_1's l1: 0.190026\n",
            "[3400]\ttraining's l1: 0.00176518\tvalid_1's l1: 0.189981\n",
            "Early stopping, best iteration is:\n",
            "[3442]\ttraining's l1: 0.00171346\tvalid_1's l1: 0.189968\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.123961\tvalid_1's l1: 0.214649\n",
            "[400]\ttraining's l1: 0.0740082\tvalid_1's l1: 0.200691\n",
            "[600]\ttraining's l1: 0.0481176\tvalid_1's l1: 0.191499\n",
            "[800]\ttraining's l1: 0.0328936\tvalid_1's l1: 0.185318\n",
            "[1000]\ttraining's l1: 0.0235639\tvalid_1's l1: 0.181757\n",
            "[1200]\ttraining's l1: 0.0173461\tvalid_1's l1: 0.179325\n",
            "[1400]\ttraining's l1: 0.0129317\tvalid_1's l1: 0.177755\n",
            "[1600]\ttraining's l1: 0.0100274\tvalid_1's l1: 0.176797\n",
            "[1800]\ttraining's l1: 0.0078869\tvalid_1's l1: 0.176123\n",
            "[2000]\ttraining's l1: 0.00631536\tvalid_1's l1: 0.175655\n",
            "[2200]\ttraining's l1: 0.0051358\tvalid_1's l1: 0.175346\n",
            "[2400]\ttraining's l1: 0.00425056\tvalid_1's l1: 0.175171\n",
            "[2600]\ttraining's l1: 0.00356123\tvalid_1's l1: 0.175036\n",
            "[2800]\ttraining's l1: 0.00301683\tvalid_1's l1: 0.174884\n",
            "[3000]\ttraining's l1: 0.00257883\tvalid_1's l1: 0.174859\n",
            "[3200]\ttraining's l1: 0.00222656\tvalid_1's l1: 0.174802\n",
            "[3400]\ttraining's l1: 0.00194191\tvalid_1's l1: 0.174768\n",
            "[3600]\ttraining's l1: 0.00169105\tvalid_1's l1: 0.174748\n",
            "[3800]\ttraining's l1: 0.00148887\tvalid_1's l1: 0.174732\n",
            "[4000]\ttraining's l1: 0.00131389\tvalid_1's l1: 0.174717\n",
            "[4200]\ttraining's l1: 0.00116665\tvalid_1's l1: 0.174711\n",
            "Early stopping, best iteration is:\n",
            "[4137]\ttraining's l1: 0.00121861\tvalid_1's l1: 0.174708\n",
            "\n",
            "✅ CV MAE: 0.17727\n",
            "✅ submission2.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 존재하지 않습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols:\n",
        "        train[col].fillna(train[col].mean(), inplace=True)\n",
        "        test[col].fillna(train[col].mean(), inplace=True)\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col].fillna(mode, inplace=True)\n",
        "        test[col].fillna(mode, inplace=True)\n",
        "\n",
        "    # 범주형 원-핫\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "\n",
        "    # train/test 컬럼 맞추기\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. LightGBM 학습 및 예측\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    params = {\n",
        "        \"objective\": \"regression\",\n",
        "        \"metric\": \"mae\",\n",
        "        \"learning_rate\": 0.03,     # 낮춰서 안정적 학습\n",
        "        \"num_leaves\": 64,\n",
        "        \"max_depth\": 7,\n",
        "        \"min_data_in_leaf\": 20,\n",
        "        \"feature_fraction\": 0.8,\n",
        "        \"bagging_fraction\": 0.8,\n",
        "        \"bagging_freq\": 1,\n",
        "        \"seed\": seed,\n",
        "        \"verbose\": -1\n",
        "    }\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=200),\n",
        "                log_evaluation(period=200)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 파이프라인 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StnvKwmo3s36",
        "outputId": "bc02053e-5314-4954-8668-9b50ad2cf061"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.174952\tvalid_1's l1: 0.217251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2556236565.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-2556236565.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(train[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-2556236565.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(mode, inplace=True)\n",
            "/tmp/ipython-input-2556236565.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(mode, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[400]\ttraining's l1: 0.134041\tvalid_1's l1: 0.20606\n",
            "[600]\ttraining's l1: 0.103838\tvalid_1's l1: 0.197413\n",
            "[800]\ttraining's l1: 0.0801091\tvalid_1's l1: 0.189885\n",
            "[1000]\ttraining's l1: 0.0638253\tvalid_1's l1: 0.184591\n",
            "[1200]\ttraining's l1: 0.0517832\tvalid_1's l1: 0.180545\n",
            "[1400]\ttraining's l1: 0.0422522\tvalid_1's l1: 0.177167\n",
            "[1600]\ttraining's l1: 0.0346805\tvalid_1's l1: 0.174563\n",
            "[1800]\ttraining's l1: 0.0287087\tvalid_1's l1: 0.172774\n",
            "[2000]\ttraining's l1: 0.0238217\tvalid_1's l1: 0.171057\n",
            "[2200]\ttraining's l1: 0.0200541\tvalid_1's l1: 0.16979\n",
            "[2400]\ttraining's l1: 0.0170706\tvalid_1's l1: 0.168741\n",
            "[2600]\ttraining's l1: 0.0146074\tvalid_1's l1: 0.167854\n",
            "[2800]\ttraining's l1: 0.0126327\tvalid_1's l1: 0.167179\n",
            "[3000]\ttraining's l1: 0.0109953\tvalid_1's l1: 0.166563\n",
            "[3200]\ttraining's l1: 0.00960318\tvalid_1's l1: 0.166158\n",
            "[3400]\ttraining's l1: 0.0084702\tvalid_1's l1: 0.165785\n",
            "[3600]\ttraining's l1: 0.00749994\tvalid_1's l1: 0.165531\n",
            "[3800]\ttraining's l1: 0.00666955\tvalid_1's l1: 0.165334\n",
            "[4000]\ttraining's l1: 0.00599137\tvalid_1's l1: 0.165148\n",
            "[4200]\ttraining's l1: 0.0053934\tvalid_1's l1: 0.164968\n",
            "[4400]\ttraining's l1: 0.00488344\tvalid_1's l1: 0.164841\n",
            "[4600]\ttraining's l1: 0.00446703\tvalid_1's l1: 0.164747\n",
            "[4800]\ttraining's l1: 0.00409747\tvalid_1's l1: 0.164648\n",
            "[5000]\ttraining's l1: 0.00375357\tvalid_1's l1: 0.164538\n",
            "[5200]\ttraining's l1: 0.00346472\tvalid_1's l1: 0.164478\n",
            "[5400]\ttraining's l1: 0.00319688\tvalid_1's l1: 0.164404\n",
            "[5600]\ttraining's l1: 0.00296449\tvalid_1's l1: 0.164345\n",
            "[5800]\ttraining's l1: 0.00275375\tvalid_1's l1: 0.164307\n",
            "[6000]\ttraining's l1: 0.00258297\tvalid_1's l1: 0.164273\n",
            "[6200]\ttraining's l1: 0.00241448\tvalid_1's l1: 0.164222\n",
            "[6400]\ttraining's l1: 0.00226828\tvalid_1's l1: 0.164183\n",
            "[6600]\ttraining's l1: 0.00213125\tvalid_1's l1: 0.164156\n",
            "[6800]\ttraining's l1: 0.00201791\tvalid_1's l1: 0.164123\n",
            "[7000]\ttraining's l1: 0.00191122\tvalid_1's l1: 0.164086\n",
            "[7200]\ttraining's l1: 0.0018094\tvalid_1's l1: 0.164071\n",
            "[7400]\ttraining's l1: 0.00171633\tvalid_1's l1: 0.164044\n",
            "[7600]\ttraining's l1: 0.00163141\tvalid_1's l1: 0.164015\n",
            "[7800]\ttraining's l1: 0.00154896\tvalid_1's l1: 0.164007\n",
            "[8000]\ttraining's l1: 0.00147024\tvalid_1's l1: 0.163993\n",
            "[8200]\ttraining's l1: 0.0014069\tvalid_1's l1: 0.163983\n",
            "[8400]\ttraining's l1: 0.00134333\tvalid_1's l1: 0.163962\n",
            "[8600]\ttraining's l1: 0.00128465\tvalid_1's l1: 0.163951\n",
            "[8800]\ttraining's l1: 0.00122515\tvalid_1's l1: 0.163942\n",
            "[9000]\ttraining's l1: 0.00117169\tvalid_1's l1: 0.163928\n",
            "[9200]\ttraining's l1: 0.00112153\tvalid_1's l1: 0.163917\n",
            "[9400]\ttraining's l1: 0.00107459\tvalid_1's l1: 0.163904\n",
            "[9600]\ttraining's l1: 0.00103124\tvalid_1's l1: 0.16389\n",
            "[9800]\ttraining's l1: 0.000988944\tvalid_1's l1: 0.16388\n",
            "[10000]\ttraining's l1: 0.0009494\tvalid_1's l1: 0.163863\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[10000]\ttraining's l1: 0.0009494\tvalid_1's l1: 0.163863\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.171694\tvalid_1's l1: 0.222217\n",
            "[400]\ttraining's l1: 0.130313\tvalid_1's l1: 0.21167\n",
            "[600]\ttraining's l1: 0.0990649\tvalid_1's l1: 0.203191\n",
            "[800]\ttraining's l1: 0.076221\tvalid_1's l1: 0.196628\n",
            "[1000]\ttraining's l1: 0.060418\tvalid_1's l1: 0.192102\n",
            "[1200]\ttraining's l1: 0.0483177\tvalid_1's l1: 0.188667\n",
            "[1400]\ttraining's l1: 0.0389351\tvalid_1's l1: 0.185552\n",
            "[1600]\ttraining's l1: 0.0318033\tvalid_1's l1: 0.183368\n",
            "[1800]\ttraining's l1: 0.0264406\tvalid_1's l1: 0.181469\n",
            "[2000]\ttraining's l1: 0.0222423\tvalid_1's l1: 0.179989\n",
            "[2200]\ttraining's l1: 0.0188636\tvalid_1's l1: 0.178856\n",
            "[2400]\ttraining's l1: 0.0160144\tvalid_1's l1: 0.177993\n",
            "[2600]\ttraining's l1: 0.0137812\tvalid_1's l1: 0.177472\n",
            "[2800]\ttraining's l1: 0.0118336\tvalid_1's l1: 0.176918\n",
            "[3000]\ttraining's l1: 0.0103766\tvalid_1's l1: 0.176433\n",
            "[3200]\ttraining's l1: 0.00905001\tvalid_1's l1: 0.176047\n",
            "[3400]\ttraining's l1: 0.00799426\tvalid_1's l1: 0.175743\n",
            "[3600]\ttraining's l1: 0.00709861\tvalid_1's l1: 0.175532\n",
            "[3800]\ttraining's l1: 0.00638707\tvalid_1's l1: 0.175393\n",
            "[4000]\ttraining's l1: 0.00574127\tvalid_1's l1: 0.175174\n",
            "[4200]\ttraining's l1: 0.00519603\tvalid_1's l1: 0.175053\n",
            "[4400]\ttraining's l1: 0.00475091\tvalid_1's l1: 0.174927\n",
            "[4600]\ttraining's l1: 0.0043413\tvalid_1's l1: 0.174863\n",
            "[4800]\ttraining's l1: 0.00399742\tvalid_1's l1: 0.174799\n",
            "[5000]\ttraining's l1: 0.0037036\tvalid_1's l1: 0.174726\n",
            "[5200]\ttraining's l1: 0.00343015\tvalid_1's l1: 0.174664\n",
            "[5400]\ttraining's l1: 0.00319175\tvalid_1's l1: 0.174636\n",
            "[5600]\ttraining's l1: 0.002973\tvalid_1's l1: 0.174598\n",
            "[5800]\ttraining's l1: 0.00278049\tvalid_1's l1: 0.174556\n",
            "[6000]\ttraining's l1: 0.00260778\tvalid_1's l1: 0.174527\n",
            "[6200]\ttraining's l1: 0.0024531\tvalid_1's l1: 0.174503\n",
            "[6400]\ttraining's l1: 0.00230817\tvalid_1's l1: 0.174478\n",
            "[6600]\ttraining's l1: 0.00217482\tvalid_1's l1: 0.174456\n",
            "[6800]\ttraining's l1: 0.00204547\tvalid_1's l1: 0.17443\n",
            "[7000]\ttraining's l1: 0.00194282\tvalid_1's l1: 0.174413\n",
            "[7200]\ttraining's l1: 0.00184055\tvalid_1's l1: 0.174384\n",
            "[7400]\ttraining's l1: 0.00174563\tvalid_1's l1: 0.174353\n",
            "[7600]\ttraining's l1: 0.00165975\tvalid_1's l1: 0.174334\n",
            "[7800]\ttraining's l1: 0.00158522\tvalid_1's l1: 0.174328\n",
            "[8000]\ttraining's l1: 0.00150811\tvalid_1's l1: 0.174305\n",
            "[8200]\ttraining's l1: 0.00143407\tvalid_1's l1: 0.174293\n",
            "[8400]\ttraining's l1: 0.00136924\tvalid_1's l1: 0.174275\n",
            "[8600]\ttraining's l1: 0.00130137\tvalid_1's l1: 0.174269\n",
            "[8800]\ttraining's l1: 0.00124488\tvalid_1's l1: 0.174254\n",
            "[9000]\ttraining's l1: 0.00119522\tvalid_1's l1: 0.174245\n",
            "[9200]\ttraining's l1: 0.0011455\tvalid_1's l1: 0.174236\n",
            "[9400]\ttraining's l1: 0.00109518\tvalid_1's l1: 0.174233\n",
            "[9600]\ttraining's l1: 0.00104704\tvalid_1's l1: 0.174228\n",
            "[9800]\ttraining's l1: 0.00100618\tvalid_1's l1: 0.174221\n",
            "[10000]\ttraining's l1: 0.000963022\tvalid_1's l1: 0.174214\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9979]\ttraining's l1: 0.000967185\tvalid_1's l1: 0.174214\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.171708\tvalid_1's l1: 0.229075\n",
            "[400]\ttraining's l1: 0.127473\tvalid_1's l1: 0.217434\n",
            "[600]\ttraining's l1: 0.0986534\tvalid_1's l1: 0.210133\n",
            "[800]\ttraining's l1: 0.0768133\tvalid_1's l1: 0.203389\n",
            "[1000]\ttraining's l1: 0.0606474\tvalid_1's l1: 0.19836\n",
            "[1200]\ttraining's l1: 0.0487543\tvalid_1's l1: 0.194633\n",
            "[1400]\ttraining's l1: 0.0397315\tvalid_1's l1: 0.19179\n",
            "[1600]\ttraining's l1: 0.0324248\tvalid_1's l1: 0.189351\n",
            "[1800]\ttraining's l1: 0.0267217\tvalid_1's l1: 0.18755\n",
            "[2000]\ttraining's l1: 0.0222891\tvalid_1's l1: 0.186302\n",
            "[2200]\ttraining's l1: 0.0188256\tvalid_1's l1: 0.185206\n",
            "[2400]\ttraining's l1: 0.0159038\tvalid_1's l1: 0.184257\n",
            "[2600]\ttraining's l1: 0.0136139\tvalid_1's l1: 0.18373\n",
            "[2800]\ttraining's l1: 0.0117297\tvalid_1's l1: 0.18318\n",
            "[3000]\ttraining's l1: 0.0101916\tvalid_1's l1: 0.182729\n",
            "[3200]\ttraining's l1: 0.00891893\tvalid_1's l1: 0.182383\n",
            "[3400]\ttraining's l1: 0.00786177\tvalid_1's l1: 0.182116\n",
            "[3600]\ttraining's l1: 0.00696574\tvalid_1's l1: 0.181916\n",
            "[3800]\ttraining's l1: 0.00621571\tvalid_1's l1: 0.181786\n",
            "[4000]\ttraining's l1: 0.00555317\tvalid_1's l1: 0.181669\n",
            "[4200]\ttraining's l1: 0.00500224\tvalid_1's l1: 0.18159\n",
            "[4400]\ttraining's l1: 0.00452625\tvalid_1's l1: 0.181488\n",
            "[4600]\ttraining's l1: 0.0041382\tvalid_1's l1: 0.181443\n",
            "[4800]\ttraining's l1: 0.00378921\tvalid_1's l1: 0.181372\n",
            "[5000]\ttraining's l1: 0.00347775\tvalid_1's l1: 0.181347\n",
            "[5200]\ttraining's l1: 0.00320719\tvalid_1's l1: 0.181313\n",
            "[5400]\ttraining's l1: 0.00298371\tvalid_1's l1: 0.181283\n",
            "[5600]\ttraining's l1: 0.00277501\tvalid_1's l1: 0.181249\n",
            "[5800]\ttraining's l1: 0.00258725\tvalid_1's l1: 0.181219\n",
            "[6000]\ttraining's l1: 0.0024191\tvalid_1's l1: 0.181198\n",
            "[6200]\ttraining's l1: 0.00227708\tvalid_1's l1: 0.181177\n",
            "[6400]\ttraining's l1: 0.0021382\tvalid_1's l1: 0.18115\n",
            "[6600]\ttraining's l1: 0.00202215\tvalid_1's l1: 0.181137\n",
            "[6800]\ttraining's l1: 0.00191183\tvalid_1's l1: 0.181121\n",
            "[7000]\ttraining's l1: 0.00180841\tvalid_1's l1: 0.181101\n",
            "[7200]\ttraining's l1: 0.00171402\tvalid_1's l1: 0.18109\n",
            "[7400]\ttraining's l1: 0.00162226\tvalid_1's l1: 0.181075\n",
            "[7600]\ttraining's l1: 0.00154615\tvalid_1's l1: 0.181058\n",
            "[7800]\ttraining's l1: 0.00147302\tvalid_1's l1: 0.181057\n",
            "[8000]\ttraining's l1: 0.00140199\tvalid_1's l1: 0.181053\n",
            "[8200]\ttraining's l1: 0.00133703\tvalid_1's l1: 0.181041\n",
            "[8400]\ttraining's l1: 0.00127813\tvalid_1's l1: 0.181038\n",
            "[8600]\ttraining's l1: 0.00122154\tvalid_1's l1: 0.181024\n",
            "[8800]\ttraining's l1: 0.00116689\tvalid_1's l1: 0.181019\n",
            "[9000]\ttraining's l1: 0.00111432\tvalid_1's l1: 0.181013\n",
            "[9200]\ttraining's l1: 0.0010689\tvalid_1's l1: 0.18101\n",
            "[9400]\ttraining's l1: 0.00102456\tvalid_1's l1: 0.181003\n",
            "[9600]\ttraining's l1: 0.000982374\tvalid_1's l1: 0.181\n",
            "[9800]\ttraining's l1: 0.000942102\tvalid_1's l1: 0.180992\n",
            "[10000]\ttraining's l1: 0.000904639\tvalid_1's l1: 0.180989\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9948]\ttraining's l1: 0.000914921\tvalid_1's l1: 0.180987\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.170843\tvalid_1's l1: 0.236881\n",
            "[400]\ttraining's l1: 0.125824\tvalid_1's l1: 0.227255\n",
            "[600]\ttraining's l1: 0.095387\tvalid_1's l1: 0.219718\n",
            "[800]\ttraining's l1: 0.0739576\tvalid_1's l1: 0.213271\n",
            "[1000]\ttraining's l1: 0.0586879\tvalid_1's l1: 0.20878\n",
            "[1200]\ttraining's l1: 0.047196\tvalid_1's l1: 0.20488\n",
            "[1400]\ttraining's l1: 0.0381315\tvalid_1's l1: 0.202179\n",
            "[1600]\ttraining's l1: 0.0315438\tvalid_1's l1: 0.200294\n",
            "[1800]\ttraining's l1: 0.026274\tvalid_1's l1: 0.198571\n",
            "[2000]\ttraining's l1: 0.0219865\tvalid_1's l1: 0.197168\n",
            "[2200]\ttraining's l1: 0.0186431\tvalid_1's l1: 0.195999\n",
            "[2400]\ttraining's l1: 0.0158587\tvalid_1's l1: 0.195312\n",
            "[2600]\ttraining's l1: 0.0136082\tvalid_1's l1: 0.19464\n",
            "[2800]\ttraining's l1: 0.0117329\tvalid_1's l1: 0.194092\n",
            "[3000]\ttraining's l1: 0.0102281\tvalid_1's l1: 0.193689\n",
            "[3200]\ttraining's l1: 0.00894641\tvalid_1's l1: 0.193305\n",
            "[3400]\ttraining's l1: 0.00789437\tvalid_1's l1: 0.193099\n",
            "[3600]\ttraining's l1: 0.00705062\tvalid_1's l1: 0.192879\n",
            "[3800]\ttraining's l1: 0.00629287\tvalid_1's l1: 0.19268\n",
            "[4000]\ttraining's l1: 0.00569328\tvalid_1's l1: 0.192503\n",
            "[4200]\ttraining's l1: 0.00516895\tvalid_1's l1: 0.192371\n",
            "[4400]\ttraining's l1: 0.00468858\tvalid_1's l1: 0.192267\n",
            "[4600]\ttraining's l1: 0.00426563\tvalid_1's l1: 0.192194\n",
            "[4800]\ttraining's l1: 0.0039224\tvalid_1's l1: 0.192121\n",
            "[5000]\ttraining's l1: 0.00360816\tvalid_1's l1: 0.192047\n",
            "[5200]\ttraining's l1: 0.00334839\tvalid_1's l1: 0.192008\n",
            "[5400]\ttraining's l1: 0.0031178\tvalid_1's l1: 0.19196\n",
            "[5600]\ttraining's l1: 0.00290566\tvalid_1's l1: 0.191926\n",
            "[5800]\ttraining's l1: 0.00270693\tvalid_1's l1: 0.191887\n",
            "[6000]\ttraining's l1: 0.00254671\tvalid_1's l1: 0.191841\n",
            "[6200]\ttraining's l1: 0.00239637\tvalid_1's l1: 0.191816\n",
            "[6400]\ttraining's l1: 0.00224596\tvalid_1's l1: 0.191787\n",
            "[6600]\ttraining's l1: 0.00211183\tvalid_1's l1: 0.191772\n",
            "[6800]\ttraining's l1: 0.00199847\tvalid_1's l1: 0.191753\n",
            "[7000]\ttraining's l1: 0.00188736\tvalid_1's l1: 0.19173\n",
            "[7200]\ttraining's l1: 0.00178432\tvalid_1's l1: 0.191712\n",
            "[7400]\ttraining's l1: 0.00169183\tvalid_1's l1: 0.191689\n",
            "[7600]\ttraining's l1: 0.0016107\tvalid_1's l1: 0.191677\n",
            "[7800]\ttraining's l1: 0.00153067\tvalid_1's l1: 0.191673\n",
            "[8000]\ttraining's l1: 0.00145417\tvalid_1's l1: 0.191665\n",
            "Early stopping, best iteration is:\n",
            "[7900]\ttraining's l1: 0.00148843\tvalid_1's l1: 0.19166\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.175111\tvalid_1's l1: 0.225917\n",
            "[400]\ttraining's l1: 0.129754\tvalid_1's l1: 0.213483\n",
            "[600]\ttraining's l1: 0.10034\tvalid_1's l1: 0.204609\n",
            "[800]\ttraining's l1: 0.0781888\tvalid_1's l1: 0.197866\n",
            "[1000]\ttraining's l1: 0.0619285\tvalid_1's l1: 0.193084\n",
            "[1200]\ttraining's l1: 0.0496308\tvalid_1's l1: 0.188536\n",
            "[1400]\ttraining's l1: 0.0405686\tvalid_1's l1: 0.184823\n",
            "[1600]\ttraining's l1: 0.0337243\tvalid_1's l1: 0.182501\n",
            "[1800]\ttraining's l1: 0.0279121\tvalid_1's l1: 0.180266\n",
            "[2000]\ttraining's l1: 0.0234459\tvalid_1's l1: 0.178783\n",
            "[2200]\ttraining's l1: 0.0196916\tvalid_1's l1: 0.17739\n",
            "[2400]\ttraining's l1: 0.0167979\tvalid_1's l1: 0.176486\n",
            "[2600]\ttraining's l1: 0.0143243\tvalid_1's l1: 0.175535\n",
            "[2800]\ttraining's l1: 0.0124208\tvalid_1's l1: 0.174989\n",
            "[3000]\ttraining's l1: 0.0108227\tvalid_1's l1: 0.174542\n",
            "[3200]\ttraining's l1: 0.00944771\tvalid_1's l1: 0.174205\n",
            "[3400]\ttraining's l1: 0.00833206\tvalid_1's l1: 0.173905\n",
            "[3600]\ttraining's l1: 0.00736105\tvalid_1's l1: 0.173676\n",
            "[3800]\ttraining's l1: 0.00655954\tvalid_1's l1: 0.173516\n",
            "[4000]\ttraining's l1: 0.00590178\tvalid_1's l1: 0.173393\n",
            "[4200]\ttraining's l1: 0.00532173\tvalid_1's l1: 0.173284\n",
            "[4400]\ttraining's l1: 0.00480998\tvalid_1's l1: 0.173212\n",
            "[4600]\ttraining's l1: 0.00438058\tvalid_1's l1: 0.173189\n",
            "[4800]\ttraining's l1: 0.00399454\tvalid_1's l1: 0.173134\n",
            "[5000]\ttraining's l1: 0.00367853\tvalid_1's l1: 0.173101\n",
            "[5200]\ttraining's l1: 0.00340012\tvalid_1's l1: 0.173019\n",
            "[5400]\ttraining's l1: 0.00315176\tvalid_1's l1: 0.172997\n",
            "[5600]\ttraining's l1: 0.00292662\tvalid_1's l1: 0.172983\n",
            "[5800]\ttraining's l1: 0.00274029\tvalid_1's l1: 0.17297\n",
            "[6000]\ttraining's l1: 0.00255914\tvalid_1's l1: 0.172937\n",
            "[6200]\ttraining's l1: 0.00238454\tvalid_1's l1: 0.17294\n",
            "Early stopping, best iteration is:\n",
            "[6021]\ttraining's l1: 0.00253616\tvalid_1's l1: 0.172932\n",
            "\n",
            "✅ CV MAE: 0.17673\n",
            "✅ submission.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 존재하지 않습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols:\n",
        "        train[col].fillna(train[col].mean(), inplace=True)\n",
        "        test[col].fillna(train[col].mean(), inplace=True)\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col].fillna(mode, inplace=True)\n",
        "        test[col].fillna(mode, inplace=True)\n",
        "\n",
        "    # 범주형 원-핫\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "\n",
        "    # train/test 컬럼 맞추기\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. LightGBM 학습 및 예측\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    params = {\n",
        "        \"objective\": \"regression\",\n",
        "        \"metric\": \"mae\",\n",
        "        \"learning_rate\": 0.03,     # 낮춰서 안정적 학습\n",
        "        \"num_leaves\": 64,\n",
        "        \"max_depth\": 7,\n",
        "        \"min_data_in_leaf\": 20,\n",
        "        \"feature_fraction\": 0.8,\n",
        "        \"bagging_fraction\": 0.8,\n",
        "        \"bagging_freq\": 1,\n",
        "        \"seed\": seed,\n",
        "        \"verbose\": -1\n",
        "    }\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=200),\n",
        "                log_evaluation(period=200)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission3.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission3.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 파이프라인 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_s6n4Pl4FJh",
        "outputId": "4d67b771-bbc9-4576-b97b-3601e7b2ac41"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-656890222.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-656890222.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(train[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-656890222.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(mode, inplace=True)\n",
            "/tmp/ipython-input-656890222.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(mode, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttraining's l1: 0.174952\tvalid_1's l1: 0.217251\n",
            "[400]\ttraining's l1: 0.134041\tvalid_1's l1: 0.20606\n",
            "[600]\ttraining's l1: 0.103838\tvalid_1's l1: 0.197413\n",
            "[800]\ttraining's l1: 0.0801091\tvalid_1's l1: 0.189885\n",
            "[1000]\ttraining's l1: 0.0638253\tvalid_1's l1: 0.184591\n",
            "[1200]\ttraining's l1: 0.0517832\tvalid_1's l1: 0.180545\n",
            "[1400]\ttraining's l1: 0.0422522\tvalid_1's l1: 0.177167\n",
            "[1600]\ttraining's l1: 0.0346805\tvalid_1's l1: 0.174563\n",
            "[1800]\ttraining's l1: 0.0287087\tvalid_1's l1: 0.172774\n",
            "[2000]\ttraining's l1: 0.0238217\tvalid_1's l1: 0.171057\n",
            "[2200]\ttraining's l1: 0.0200541\tvalid_1's l1: 0.16979\n",
            "[2400]\ttraining's l1: 0.0170706\tvalid_1's l1: 0.168741\n",
            "[2600]\ttraining's l1: 0.0146074\tvalid_1's l1: 0.167854\n",
            "[2800]\ttraining's l1: 0.0126327\tvalid_1's l1: 0.167179\n",
            "[3000]\ttraining's l1: 0.0109953\tvalid_1's l1: 0.166563\n",
            "[3200]\ttraining's l1: 0.00960318\tvalid_1's l1: 0.166158\n",
            "[3400]\ttraining's l1: 0.0084702\tvalid_1's l1: 0.165785\n",
            "[3600]\ttraining's l1: 0.00749994\tvalid_1's l1: 0.165531\n",
            "[3800]\ttraining's l1: 0.00666955\tvalid_1's l1: 0.165334\n",
            "[4000]\ttraining's l1: 0.00599137\tvalid_1's l1: 0.165148\n",
            "[4200]\ttraining's l1: 0.0053934\tvalid_1's l1: 0.164968\n",
            "[4400]\ttraining's l1: 0.00488344\tvalid_1's l1: 0.164841\n",
            "[4600]\ttraining's l1: 0.00446703\tvalid_1's l1: 0.164747\n",
            "[4800]\ttraining's l1: 0.00409747\tvalid_1's l1: 0.164648\n",
            "[5000]\ttraining's l1: 0.00375357\tvalid_1's l1: 0.164538\n",
            "[5200]\ttraining's l1: 0.00346472\tvalid_1's l1: 0.164478\n",
            "[5400]\ttraining's l1: 0.00319688\tvalid_1's l1: 0.164404\n",
            "[5600]\ttraining's l1: 0.00296449\tvalid_1's l1: 0.164345\n",
            "[5800]\ttraining's l1: 0.00275375\tvalid_1's l1: 0.164307\n",
            "[6000]\ttraining's l1: 0.00258297\tvalid_1's l1: 0.164273\n",
            "[6200]\ttraining's l1: 0.00241448\tvalid_1's l1: 0.164222\n",
            "[6400]\ttraining's l1: 0.00226828\tvalid_1's l1: 0.164183\n",
            "[6600]\ttraining's l1: 0.00213125\tvalid_1's l1: 0.164156\n",
            "[6800]\ttraining's l1: 0.00201791\tvalid_1's l1: 0.164123\n",
            "[7000]\ttraining's l1: 0.00191122\tvalid_1's l1: 0.164086\n",
            "[7200]\ttraining's l1: 0.0018094\tvalid_1's l1: 0.164071\n",
            "[7400]\ttraining's l1: 0.00171633\tvalid_1's l1: 0.164044\n",
            "[7600]\ttraining's l1: 0.00163141\tvalid_1's l1: 0.164015\n",
            "[7800]\ttraining's l1: 0.00154896\tvalid_1's l1: 0.164007\n",
            "[8000]\ttraining's l1: 0.00147024\tvalid_1's l1: 0.163993\n",
            "[8200]\ttraining's l1: 0.0014069\tvalid_1's l1: 0.163983\n",
            "[8400]\ttraining's l1: 0.00134333\tvalid_1's l1: 0.163962\n",
            "[8600]\ttraining's l1: 0.00128465\tvalid_1's l1: 0.163951\n",
            "[8800]\ttraining's l1: 0.00122515\tvalid_1's l1: 0.163942\n",
            "[9000]\ttraining's l1: 0.00117169\tvalid_1's l1: 0.163928\n",
            "[9200]\ttraining's l1: 0.00112153\tvalid_1's l1: 0.163917\n",
            "[9400]\ttraining's l1: 0.00107459\tvalid_1's l1: 0.163904\n",
            "[9600]\ttraining's l1: 0.00103124\tvalid_1's l1: 0.16389\n",
            "[9800]\ttraining's l1: 0.000988944\tvalid_1's l1: 0.16388\n",
            "[10000]\ttraining's l1: 0.0009494\tvalid_1's l1: 0.163863\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[10000]\ttraining's l1: 0.0009494\tvalid_1's l1: 0.163863\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.171694\tvalid_1's l1: 0.222217\n",
            "[400]\ttraining's l1: 0.130313\tvalid_1's l1: 0.21167\n",
            "[600]\ttraining's l1: 0.0990649\tvalid_1's l1: 0.203191\n",
            "[800]\ttraining's l1: 0.076221\tvalid_1's l1: 0.196628\n",
            "[1000]\ttraining's l1: 0.060418\tvalid_1's l1: 0.192102\n",
            "[1200]\ttraining's l1: 0.0483177\tvalid_1's l1: 0.188667\n",
            "[1400]\ttraining's l1: 0.0389351\tvalid_1's l1: 0.185552\n",
            "[1600]\ttraining's l1: 0.0318033\tvalid_1's l1: 0.183368\n",
            "[1800]\ttraining's l1: 0.0264406\tvalid_1's l1: 0.181469\n",
            "[2000]\ttraining's l1: 0.0222423\tvalid_1's l1: 0.179989\n",
            "[2200]\ttraining's l1: 0.0188636\tvalid_1's l1: 0.178856\n",
            "[2400]\ttraining's l1: 0.0160144\tvalid_1's l1: 0.177993\n",
            "[2600]\ttraining's l1: 0.0137812\tvalid_1's l1: 0.177472\n",
            "[2800]\ttraining's l1: 0.0118336\tvalid_1's l1: 0.176918\n",
            "[3000]\ttraining's l1: 0.0103766\tvalid_1's l1: 0.176433\n",
            "[3200]\ttraining's l1: 0.00905001\tvalid_1's l1: 0.176047\n",
            "[3400]\ttraining's l1: 0.00799426\tvalid_1's l1: 0.175743\n",
            "[3600]\ttraining's l1: 0.00709861\tvalid_1's l1: 0.175532\n",
            "[3800]\ttraining's l1: 0.00638707\tvalid_1's l1: 0.175393\n",
            "[4000]\ttraining's l1: 0.00574127\tvalid_1's l1: 0.175174\n",
            "[4200]\ttraining's l1: 0.00519603\tvalid_1's l1: 0.175053\n",
            "[4400]\ttraining's l1: 0.00475091\tvalid_1's l1: 0.174927\n",
            "[4600]\ttraining's l1: 0.0043413\tvalid_1's l1: 0.174863\n",
            "[4800]\ttraining's l1: 0.00399742\tvalid_1's l1: 0.174799\n",
            "[5000]\ttraining's l1: 0.0037036\tvalid_1's l1: 0.174726\n",
            "[5200]\ttraining's l1: 0.00343015\tvalid_1's l1: 0.174664\n",
            "[5400]\ttraining's l1: 0.00319175\tvalid_1's l1: 0.174636\n",
            "[5600]\ttraining's l1: 0.002973\tvalid_1's l1: 0.174598\n",
            "[5800]\ttraining's l1: 0.00278049\tvalid_1's l1: 0.174556\n",
            "[6000]\ttraining's l1: 0.00260778\tvalid_1's l1: 0.174527\n",
            "[6200]\ttraining's l1: 0.0024531\tvalid_1's l1: 0.174503\n",
            "[6400]\ttraining's l1: 0.00230817\tvalid_1's l1: 0.174478\n",
            "[6600]\ttraining's l1: 0.00217482\tvalid_1's l1: 0.174456\n",
            "[6800]\ttraining's l1: 0.00204547\tvalid_1's l1: 0.17443\n",
            "[7000]\ttraining's l1: 0.00194282\tvalid_1's l1: 0.174413\n",
            "[7200]\ttraining's l1: 0.00184055\tvalid_1's l1: 0.174384\n",
            "[7400]\ttraining's l1: 0.00174563\tvalid_1's l1: 0.174353\n",
            "[7600]\ttraining's l1: 0.00165975\tvalid_1's l1: 0.174334\n",
            "[7800]\ttraining's l1: 0.00158522\tvalid_1's l1: 0.174328\n",
            "[8000]\ttraining's l1: 0.00150811\tvalid_1's l1: 0.174305\n",
            "[8200]\ttraining's l1: 0.00143407\tvalid_1's l1: 0.174293\n",
            "[8400]\ttraining's l1: 0.00136924\tvalid_1's l1: 0.174275\n",
            "[8600]\ttraining's l1: 0.00130137\tvalid_1's l1: 0.174269\n",
            "[8800]\ttraining's l1: 0.00124488\tvalid_1's l1: 0.174254\n",
            "[9000]\ttraining's l1: 0.00119522\tvalid_1's l1: 0.174245\n",
            "[9200]\ttraining's l1: 0.0011455\tvalid_1's l1: 0.174236\n",
            "[9400]\ttraining's l1: 0.00109518\tvalid_1's l1: 0.174233\n",
            "[9600]\ttraining's l1: 0.00104704\tvalid_1's l1: 0.174228\n",
            "[9800]\ttraining's l1: 0.00100618\tvalid_1's l1: 0.174221\n",
            "[10000]\ttraining's l1: 0.000963022\tvalid_1's l1: 0.174214\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9979]\ttraining's l1: 0.000967185\tvalid_1's l1: 0.174214\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.171708\tvalid_1's l1: 0.229075\n",
            "[400]\ttraining's l1: 0.127473\tvalid_1's l1: 0.217434\n",
            "[600]\ttraining's l1: 0.0986534\tvalid_1's l1: 0.210133\n",
            "[800]\ttraining's l1: 0.0768133\tvalid_1's l1: 0.203389\n",
            "[1000]\ttraining's l1: 0.0606474\tvalid_1's l1: 0.19836\n",
            "[1200]\ttraining's l1: 0.0487543\tvalid_1's l1: 0.194633\n",
            "[1400]\ttraining's l1: 0.0397315\tvalid_1's l1: 0.19179\n",
            "[1600]\ttraining's l1: 0.0324248\tvalid_1's l1: 0.189351\n",
            "[1800]\ttraining's l1: 0.0267217\tvalid_1's l1: 0.18755\n",
            "[2000]\ttraining's l1: 0.0222891\tvalid_1's l1: 0.186302\n",
            "[2200]\ttraining's l1: 0.0188256\tvalid_1's l1: 0.185206\n",
            "[2400]\ttraining's l1: 0.0159038\tvalid_1's l1: 0.184257\n",
            "[2600]\ttraining's l1: 0.0136139\tvalid_1's l1: 0.18373\n",
            "[2800]\ttraining's l1: 0.0117297\tvalid_1's l1: 0.18318\n",
            "[3000]\ttraining's l1: 0.0101916\tvalid_1's l1: 0.182729\n",
            "[3200]\ttraining's l1: 0.00891893\tvalid_1's l1: 0.182383\n",
            "[3400]\ttraining's l1: 0.00786177\tvalid_1's l1: 0.182116\n",
            "[3600]\ttraining's l1: 0.00696574\tvalid_1's l1: 0.181916\n",
            "[3800]\ttraining's l1: 0.00621571\tvalid_1's l1: 0.181786\n",
            "[4000]\ttraining's l1: 0.00555317\tvalid_1's l1: 0.181669\n",
            "[4200]\ttraining's l1: 0.00500224\tvalid_1's l1: 0.18159\n",
            "[4400]\ttraining's l1: 0.00452625\tvalid_1's l1: 0.181488\n",
            "[4600]\ttraining's l1: 0.0041382\tvalid_1's l1: 0.181443\n",
            "[4800]\ttraining's l1: 0.00378921\tvalid_1's l1: 0.181372\n",
            "[5000]\ttraining's l1: 0.00347775\tvalid_1's l1: 0.181347\n",
            "[5200]\ttraining's l1: 0.00320719\tvalid_1's l1: 0.181313\n",
            "[5400]\ttraining's l1: 0.00298371\tvalid_1's l1: 0.181283\n",
            "[5600]\ttraining's l1: 0.00277501\tvalid_1's l1: 0.181249\n",
            "[5800]\ttraining's l1: 0.00258725\tvalid_1's l1: 0.181219\n",
            "[6000]\ttraining's l1: 0.0024191\tvalid_1's l1: 0.181198\n",
            "[6200]\ttraining's l1: 0.00227708\tvalid_1's l1: 0.181177\n",
            "[6400]\ttraining's l1: 0.0021382\tvalid_1's l1: 0.18115\n",
            "[6600]\ttraining's l1: 0.00202215\tvalid_1's l1: 0.181137\n",
            "[6800]\ttraining's l1: 0.00191183\tvalid_1's l1: 0.181121\n",
            "[7000]\ttraining's l1: 0.00180841\tvalid_1's l1: 0.181101\n",
            "[7200]\ttraining's l1: 0.00171402\tvalid_1's l1: 0.18109\n",
            "[7400]\ttraining's l1: 0.00162226\tvalid_1's l1: 0.181075\n",
            "[7600]\ttraining's l1: 0.00154615\tvalid_1's l1: 0.181058\n",
            "[7800]\ttraining's l1: 0.00147302\tvalid_1's l1: 0.181057\n",
            "[8000]\ttraining's l1: 0.00140199\tvalid_1's l1: 0.181053\n",
            "[8200]\ttraining's l1: 0.00133703\tvalid_1's l1: 0.181041\n",
            "[8400]\ttraining's l1: 0.00127813\tvalid_1's l1: 0.181038\n",
            "[8600]\ttraining's l1: 0.00122154\tvalid_1's l1: 0.181024\n",
            "[8800]\ttraining's l1: 0.00116689\tvalid_1's l1: 0.181019\n",
            "[9000]\ttraining's l1: 0.00111432\tvalid_1's l1: 0.181013\n",
            "[9200]\ttraining's l1: 0.0010689\tvalid_1's l1: 0.18101\n",
            "[9400]\ttraining's l1: 0.00102456\tvalid_1's l1: 0.181003\n",
            "[9600]\ttraining's l1: 0.000982374\tvalid_1's l1: 0.181\n",
            "[9800]\ttraining's l1: 0.000942102\tvalid_1's l1: 0.180992\n",
            "[10000]\ttraining's l1: 0.000904639\tvalid_1's l1: 0.180989\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9948]\ttraining's l1: 0.000914921\tvalid_1's l1: 0.180987\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.170843\tvalid_1's l1: 0.236881\n",
            "[400]\ttraining's l1: 0.125824\tvalid_1's l1: 0.227255\n",
            "[600]\ttraining's l1: 0.095387\tvalid_1's l1: 0.219718\n",
            "[800]\ttraining's l1: 0.0739576\tvalid_1's l1: 0.213271\n",
            "[1000]\ttraining's l1: 0.0586879\tvalid_1's l1: 0.20878\n",
            "[1200]\ttraining's l1: 0.047196\tvalid_1's l1: 0.20488\n",
            "[1400]\ttraining's l1: 0.0381315\tvalid_1's l1: 0.202179\n",
            "[1600]\ttraining's l1: 0.0315438\tvalid_1's l1: 0.200294\n",
            "[1800]\ttraining's l1: 0.026274\tvalid_1's l1: 0.198571\n",
            "[2000]\ttraining's l1: 0.0219865\tvalid_1's l1: 0.197168\n",
            "[2200]\ttraining's l1: 0.0186431\tvalid_1's l1: 0.195999\n",
            "[2400]\ttraining's l1: 0.0158587\tvalid_1's l1: 0.195312\n",
            "[2600]\ttraining's l1: 0.0136082\tvalid_1's l1: 0.19464\n",
            "[2800]\ttraining's l1: 0.0117329\tvalid_1's l1: 0.194092\n",
            "[3000]\ttraining's l1: 0.0102281\tvalid_1's l1: 0.193689\n",
            "[3200]\ttraining's l1: 0.00894641\tvalid_1's l1: 0.193305\n",
            "[3400]\ttraining's l1: 0.00789437\tvalid_1's l1: 0.193099\n",
            "[3600]\ttraining's l1: 0.00705062\tvalid_1's l1: 0.192879\n",
            "[3800]\ttraining's l1: 0.00629287\tvalid_1's l1: 0.19268\n",
            "[4000]\ttraining's l1: 0.00569328\tvalid_1's l1: 0.192503\n",
            "[4200]\ttraining's l1: 0.00516895\tvalid_1's l1: 0.192371\n",
            "[4400]\ttraining's l1: 0.00468858\tvalid_1's l1: 0.192267\n",
            "[4600]\ttraining's l1: 0.00426563\tvalid_1's l1: 0.192194\n",
            "[4800]\ttraining's l1: 0.0039224\tvalid_1's l1: 0.192121\n",
            "[5000]\ttraining's l1: 0.00360816\tvalid_1's l1: 0.192047\n",
            "[5200]\ttraining's l1: 0.00334839\tvalid_1's l1: 0.192008\n",
            "[5400]\ttraining's l1: 0.0031178\tvalid_1's l1: 0.19196\n",
            "[5600]\ttraining's l1: 0.00290566\tvalid_1's l1: 0.191926\n",
            "[5800]\ttraining's l1: 0.00270693\tvalid_1's l1: 0.191887\n",
            "[6000]\ttraining's l1: 0.00254671\tvalid_1's l1: 0.191841\n",
            "[6200]\ttraining's l1: 0.00239637\tvalid_1's l1: 0.191816\n",
            "[6400]\ttraining's l1: 0.00224596\tvalid_1's l1: 0.191787\n",
            "[6600]\ttraining's l1: 0.00211183\tvalid_1's l1: 0.191772\n",
            "[6800]\ttraining's l1: 0.00199847\tvalid_1's l1: 0.191753\n",
            "[7000]\ttraining's l1: 0.00188736\tvalid_1's l1: 0.19173\n",
            "[7200]\ttraining's l1: 0.00178432\tvalid_1's l1: 0.191712\n",
            "[7400]\ttraining's l1: 0.00169183\tvalid_1's l1: 0.191689\n",
            "[7600]\ttraining's l1: 0.0016107\tvalid_1's l1: 0.191677\n",
            "[7800]\ttraining's l1: 0.00153067\tvalid_1's l1: 0.191673\n",
            "[8000]\ttraining's l1: 0.00145417\tvalid_1's l1: 0.191665\n",
            "Early stopping, best iteration is:\n",
            "[7900]\ttraining's l1: 0.00148843\tvalid_1's l1: 0.19166\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.175111\tvalid_1's l1: 0.225917\n",
            "[400]\ttraining's l1: 0.129754\tvalid_1's l1: 0.213483\n",
            "[600]\ttraining's l1: 0.10034\tvalid_1's l1: 0.204609\n",
            "[800]\ttraining's l1: 0.0781888\tvalid_1's l1: 0.197866\n",
            "[1000]\ttraining's l1: 0.0619285\tvalid_1's l1: 0.193084\n",
            "[1200]\ttraining's l1: 0.0496308\tvalid_1's l1: 0.188536\n",
            "[1400]\ttraining's l1: 0.0405686\tvalid_1's l1: 0.184823\n",
            "[1600]\ttraining's l1: 0.0337243\tvalid_1's l1: 0.182501\n",
            "[1800]\ttraining's l1: 0.0279121\tvalid_1's l1: 0.180266\n",
            "[2000]\ttraining's l1: 0.0234459\tvalid_1's l1: 0.178783\n",
            "[2200]\ttraining's l1: 0.0196916\tvalid_1's l1: 0.17739\n",
            "[2400]\ttraining's l1: 0.0167979\tvalid_1's l1: 0.176486\n",
            "[2600]\ttraining's l1: 0.0143243\tvalid_1's l1: 0.175535\n",
            "[2800]\ttraining's l1: 0.0124208\tvalid_1's l1: 0.174989\n",
            "[3000]\ttraining's l1: 0.0108227\tvalid_1's l1: 0.174542\n",
            "[3200]\ttraining's l1: 0.00944771\tvalid_1's l1: 0.174205\n",
            "[3400]\ttraining's l1: 0.00833206\tvalid_1's l1: 0.173905\n",
            "[3600]\ttraining's l1: 0.00736105\tvalid_1's l1: 0.173676\n",
            "[3800]\ttraining's l1: 0.00655954\tvalid_1's l1: 0.173516\n",
            "[4000]\ttraining's l1: 0.00590178\tvalid_1's l1: 0.173393\n",
            "[4200]\ttraining's l1: 0.00532173\tvalid_1's l1: 0.173284\n",
            "[4400]\ttraining's l1: 0.00480998\tvalid_1's l1: 0.173212\n",
            "[4600]\ttraining's l1: 0.00438058\tvalid_1's l1: 0.173189\n",
            "[4800]\ttraining's l1: 0.00399454\tvalid_1's l1: 0.173134\n",
            "[5000]\ttraining's l1: 0.00367853\tvalid_1's l1: 0.173101\n",
            "[5200]\ttraining's l1: 0.00340012\tvalid_1's l1: 0.173019\n",
            "[5400]\ttraining's l1: 0.00315176\tvalid_1's l1: 0.172997\n",
            "[5600]\ttraining's l1: 0.00292662\tvalid_1's l1: 0.172983\n",
            "[5800]\ttraining's l1: 0.00274029\tvalid_1's l1: 0.17297\n",
            "[6000]\ttraining's l1: 0.00255914\tvalid_1's l1: 0.172937\n",
            "[6200]\ttraining's l1: 0.00238454\tvalid_1's l1: 0.17294\n",
            "Early stopping, best iteration is:\n",
            "[6021]\ttraining's l1: 0.00253616\tvalid_1's l1: 0.172932\n",
            "\n",
            "✅ CV MAE: 0.17673\n",
            "✅ submission3.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + Feature Engineering\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 존재하지 않습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 결측치 처리\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    for col in num_cols:\n",
        "        train[col].fillna(train[col].mean(), inplace=True)\n",
        "        test[col].fillna(train[col].mean(), inplace=True)\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col].fillna(mode, inplace=True)\n",
        "        test[col].fillna(mode, inplace=True)\n",
        "\n",
        "    # Feature Engineering\n",
        "    # BMI\n",
        "    if \"weight\" in train.columns and \"height\" in train.columns:\n",
        "        train[\"BMI\"] = train[\"weight\"] / ((train[\"height\"]/100)**2)\n",
        "        test[\"BMI\"] = test[\"weight\"] / ((test[\"height\"]/100)**2)\n",
        "    # 혈압 비율\n",
        "    if \"systolic_blood_pressure\" in train.columns and \"diastolic_blood_pressure\" in train.columns:\n",
        "        train[\"bp_ratio\"] = train[\"systolic_blood_pressure\"] / train[\"diastolic_blood_pressure\"]\n",
        "        test[\"bp_ratio\"] = test[\"systolic_blood_pressure\"] / test[\"diastolic_blood_pressure\"]\n",
        "\n",
        "    # 범주형 원-핫\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "\n",
        "    # 컬럼 맞추기\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. LGBM 학습\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    params = {\n",
        "        \"objective\": \"regression\",\n",
        "        \"metric\": \"mae\",\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"num_leaves\": 128,\n",
        "        \"max_depth\": 8,\n",
        "        \"min_data_in_leaf\": 15,\n",
        "        \"feature_fraction\": 0.85,\n",
        "        \"bagging_fraction\": 0.85,\n",
        "        \"bagging_freq\": 1,\n",
        "        \"lambda_l1\": 0.5,\n",
        "        \"lambda_l2\": 0.5,\n",
        "        \"seed\": seed,\n",
        "        \"verbose\": -1\n",
        "    }\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=20000,\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=300),\n",
        "                log_evaluation(period=200)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission4.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission4.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k31WO-gz4sv1",
        "outputId": "ec6493d7-80c0-4600-8365-d4e1826b4422"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 300 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-968091161.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-968091161.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(train[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-968091161.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(mode, inplace=True)\n",
            "/tmp/ipython-input-968091161.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(mode, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttraining's l1: 0.178438\tvalid_1's l1: 0.218953\n",
            "[400]\ttraining's l1: 0.13092\tvalid_1's l1: 0.205418\n",
            "[600]\ttraining's l1: 0.0997589\tvalid_1's l1: 0.195767\n",
            "[800]\ttraining's l1: 0.076828\tvalid_1's l1: 0.188041\n",
            "[1000]\ttraining's l1: 0.0617598\tvalid_1's l1: 0.183541\n",
            "[1200]\ttraining's l1: 0.0515541\tvalid_1's l1: 0.180131\n",
            "[1400]\ttraining's l1: 0.0445498\tvalid_1's l1: 0.177921\n",
            "[1600]\ttraining's l1: 0.0398258\tvalid_1's l1: 0.176447\n",
            "[1800]\ttraining's l1: 0.03637\tvalid_1's l1: 0.175484\n",
            "[2000]\ttraining's l1: 0.0338195\tvalid_1's l1: 0.174686\n",
            "[2200]\ttraining's l1: 0.0317818\tvalid_1's l1: 0.174079\n",
            "[2400]\ttraining's l1: 0.0302\tvalid_1's l1: 0.173575\n",
            "[2600]\ttraining's l1: 0.0289386\tvalid_1's l1: 0.173139\n",
            "[2800]\ttraining's l1: 0.027865\tvalid_1's l1: 0.172787\n",
            "[3000]\ttraining's l1: 0.0269673\tvalid_1's l1: 0.17252\n",
            "[3200]\ttraining's l1: 0.0261694\tvalid_1's l1: 0.17223\n",
            "[3400]\ttraining's l1: 0.0254707\tvalid_1's l1: 0.172001\n",
            "[3600]\ttraining's l1: 0.0248345\tvalid_1's l1: 0.171786\n",
            "[3800]\ttraining's l1: 0.0243166\tvalid_1's l1: 0.171588\n",
            "[4000]\ttraining's l1: 0.0238414\tvalid_1's l1: 0.171433\n",
            "[4200]\ttraining's l1: 0.0234053\tvalid_1's l1: 0.171304\n",
            "[4400]\ttraining's l1: 0.0230309\tvalid_1's l1: 0.171156\n",
            "[4600]\ttraining's l1: 0.0226757\tvalid_1's l1: 0.171001\n",
            "[4800]\ttraining's l1: 0.0223476\tvalid_1's l1: 0.1709\n",
            "[5000]\ttraining's l1: 0.0220248\tvalid_1's l1: 0.170784\n",
            "[5200]\ttraining's l1: 0.0217395\tvalid_1's l1: 0.170658\n",
            "[5400]\ttraining's l1: 0.0214856\tvalid_1's l1: 0.170567\n",
            "[5600]\ttraining's l1: 0.0212532\tvalid_1's l1: 0.17047\n",
            "[5800]\ttraining's l1: 0.0210112\tvalid_1's l1: 0.170378\n",
            "[6000]\ttraining's l1: 0.020806\tvalid_1's l1: 0.170289\n",
            "[6200]\ttraining's l1: 0.0205949\tvalid_1's l1: 0.170218\n",
            "[6400]\ttraining's l1: 0.0204107\tvalid_1's l1: 0.170136\n",
            "[6600]\ttraining's l1: 0.0202182\tvalid_1's l1: 0.170078\n",
            "[6800]\ttraining's l1: 0.0200505\tvalid_1's l1: 0.170004\n",
            "[7000]\ttraining's l1: 0.0198806\tvalid_1's l1: 0.16996\n",
            "[7200]\ttraining's l1: 0.0197193\tvalid_1's l1: 0.169906\n",
            "[7400]\ttraining's l1: 0.0195868\tvalid_1's l1: 0.169853\n",
            "[7600]\ttraining's l1: 0.0194478\tvalid_1's l1: 0.169822\n",
            "[7800]\ttraining's l1: 0.0193016\tvalid_1's l1: 0.16977\n",
            "[8000]\ttraining's l1: 0.019176\tvalid_1's l1: 0.169706\n",
            "[8200]\ttraining's l1: 0.0190419\tvalid_1's l1: 0.169654\n",
            "[8400]\ttraining's l1: 0.0189292\tvalid_1's l1: 0.169602\n",
            "[8600]\ttraining's l1: 0.0188022\tvalid_1's l1: 0.169565\n",
            "[8800]\ttraining's l1: 0.0186938\tvalid_1's l1: 0.169526\n",
            "[9000]\ttraining's l1: 0.0185911\tvalid_1's l1: 0.169479\n",
            "[9200]\ttraining's l1: 0.0184877\tvalid_1's l1: 0.169452\n",
            "[9400]\ttraining's l1: 0.0183916\tvalid_1's l1: 0.169415\n",
            "[9600]\ttraining's l1: 0.0183033\tvalid_1's l1: 0.169393\n",
            "[9800]\ttraining's l1: 0.018223\tvalid_1's l1: 0.169361\n",
            "[10000]\ttraining's l1: 0.018127\tvalid_1's l1: 0.169322\n",
            "[10200]\ttraining's l1: 0.0180437\tvalid_1's l1: 0.169286\n",
            "[10400]\ttraining's l1: 0.0179498\tvalid_1's l1: 0.169263\n",
            "[10600]\ttraining's l1: 0.0178742\tvalid_1's l1: 0.169233\n",
            "[10800]\ttraining's l1: 0.0177921\tvalid_1's l1: 0.169199\n",
            "[11000]\ttraining's l1: 0.0177105\tvalid_1's l1: 0.169168\n",
            "[11200]\ttraining's l1: 0.0176405\tvalid_1's l1: 0.169137\n",
            "[11400]\ttraining's l1: 0.017571\tvalid_1's l1: 0.169107\n",
            "[11600]\ttraining's l1: 0.0175046\tvalid_1's l1: 0.169087\n",
            "[11800]\ttraining's l1: 0.0174293\tvalid_1's l1: 0.169062\n",
            "[12000]\ttraining's l1: 0.0173524\tvalid_1's l1: 0.169022\n",
            "[12200]\ttraining's l1: 0.0172856\tvalid_1's l1: 0.168998\n",
            "[12400]\ttraining's l1: 0.0172214\tvalid_1's l1: 0.168977\n",
            "[12600]\ttraining's l1: 0.0171599\tvalid_1's l1: 0.168952\n",
            "[12800]\ttraining's l1: 0.0171007\tvalid_1's l1: 0.168942\n",
            "[13000]\ttraining's l1: 0.0170331\tvalid_1's l1: 0.168908\n",
            "[13200]\ttraining's l1: 0.0169788\tvalid_1's l1: 0.168891\n",
            "[13400]\ttraining's l1: 0.0169258\tvalid_1's l1: 0.168868\n",
            "[13600]\ttraining's l1: 0.0168717\tvalid_1's l1: 0.168853\n",
            "[13800]\ttraining's l1: 0.0168184\tvalid_1's l1: 0.168829\n",
            "[14000]\ttraining's l1: 0.0167628\tvalid_1's l1: 0.168808\n",
            "[14200]\ttraining's l1: 0.0167067\tvalid_1's l1: 0.168788\n",
            "[14400]\ttraining's l1: 0.0166559\tvalid_1's l1: 0.168762\n",
            "[14600]\ttraining's l1: 0.0166034\tvalid_1's l1: 0.168742\n",
            "[14800]\ttraining's l1: 0.0165606\tvalid_1's l1: 0.168728\n",
            "[15000]\ttraining's l1: 0.0165132\tvalid_1's l1: 0.168715\n",
            "[15200]\ttraining's l1: 0.0164625\tvalid_1's l1: 0.168694\n",
            "[15400]\ttraining's l1: 0.0164198\tvalid_1's l1: 0.168689\n",
            "[15600]\ttraining's l1: 0.0163805\tvalid_1's l1: 0.16866\n",
            "[15800]\ttraining's l1: 0.0163356\tvalid_1's l1: 0.168647\n",
            "[16000]\ttraining's l1: 0.0162977\tvalid_1's l1: 0.168627\n",
            "[16200]\ttraining's l1: 0.0162511\tvalid_1's l1: 0.168617\n",
            "[16400]\ttraining's l1: 0.0162139\tvalid_1's l1: 0.168608\n",
            "[16600]\ttraining's l1: 0.016169\tvalid_1's l1: 0.168586\n",
            "[16800]\ttraining's l1: 0.0161258\tvalid_1's l1: 0.16856\n",
            "[17000]\ttraining's l1: 0.0160897\tvalid_1's l1: 0.168555\n",
            "[17200]\ttraining's l1: 0.0160425\tvalid_1's l1: 0.168528\n",
            "[17400]\ttraining's l1: 0.016001\tvalid_1's l1: 0.168512\n",
            "[17600]\ttraining's l1: 0.015957\tvalid_1's l1: 0.16851\n",
            "[17800]\ttraining's l1: 0.0159199\tvalid_1's l1: 0.168498\n",
            "[18000]\ttraining's l1: 0.0158891\tvalid_1's l1: 0.168487\n",
            "[18200]\ttraining's l1: 0.0158517\tvalid_1's l1: 0.168479\n",
            "[18400]\ttraining's l1: 0.0158147\tvalid_1's l1: 0.168466\n",
            "[18600]\ttraining's l1: 0.0157825\tvalid_1's l1: 0.168445\n",
            "[18800]\ttraining's l1: 0.0157507\tvalid_1's l1: 0.168432\n",
            "[19000]\ttraining's l1: 0.0157188\tvalid_1's l1: 0.168413\n",
            "[19200]\ttraining's l1: 0.0156861\tvalid_1's l1: 0.168408\n",
            "[19400]\ttraining's l1: 0.0156501\tvalid_1's l1: 0.168395\n",
            "[19600]\ttraining's l1: 0.0156166\tvalid_1's l1: 0.168381\n",
            "[19800]\ttraining's l1: 0.0155825\tvalid_1's l1: 0.168364\n",
            "[20000]\ttraining's l1: 0.0155527\tvalid_1's l1: 0.168356\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[19994]\ttraining's l1: 0.0155537\tvalid_1's l1: 0.168355\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[200]\ttraining's l1: 0.174787\tvalid_1's l1: 0.224617\n",
            "[400]\ttraining's l1: 0.126998\tvalid_1's l1: 0.210003\n",
            "[600]\ttraining's l1: 0.0954347\tvalid_1's l1: 0.201874\n",
            "[800]\ttraining's l1: 0.0739255\tvalid_1's l1: 0.195918\n",
            "[1000]\ttraining's l1: 0.0595572\tvalid_1's l1: 0.19163\n",
            "[1200]\ttraining's l1: 0.0496668\tvalid_1's l1: 0.188553\n",
            "[1400]\ttraining's l1: 0.0431715\tvalid_1's l1: 0.186736\n",
            "[1600]\ttraining's l1: 0.0385655\tvalid_1's l1: 0.185393\n",
            "[1800]\ttraining's l1: 0.0351926\tvalid_1's l1: 0.184373\n",
            "[2000]\ttraining's l1: 0.032736\tvalid_1's l1: 0.183676\n",
            "[2200]\ttraining's l1: 0.0307991\tvalid_1's l1: 0.183064\n",
            "[2400]\ttraining's l1: 0.0292705\tvalid_1's l1: 0.182579\n",
            "[2600]\ttraining's l1: 0.0280506\tvalid_1's l1: 0.182147\n",
            "[2800]\ttraining's l1: 0.0270404\tvalid_1's l1: 0.181805\n",
            "[3000]\ttraining's l1: 0.0261394\tvalid_1's l1: 0.181552\n",
            "[3200]\ttraining's l1: 0.0253894\tvalid_1's l1: 0.181275\n",
            "[3400]\ttraining's l1: 0.0247764\tvalid_1's l1: 0.181054\n",
            "[3600]\ttraining's l1: 0.0241826\tvalid_1's l1: 0.180823\n",
            "[3800]\ttraining's l1: 0.023653\tvalid_1's l1: 0.180591\n",
            "[4000]\ttraining's l1: 0.0231704\tvalid_1's l1: 0.180433\n",
            "[4200]\ttraining's l1: 0.0227506\tvalid_1's l1: 0.180303\n",
            "[4400]\ttraining's l1: 0.022377\tvalid_1's l1: 0.180196\n",
            "[4600]\ttraining's l1: 0.0220208\tvalid_1's l1: 0.180054\n",
            "[4800]\ttraining's l1: 0.0217106\tvalid_1's l1: 0.179944\n",
            "[5000]\ttraining's l1: 0.0214236\tvalid_1's l1: 0.179847\n",
            "[5200]\ttraining's l1: 0.0211552\tvalid_1's l1: 0.179741\n",
            "[5400]\ttraining's l1: 0.0208978\tvalid_1's l1: 0.179655\n",
            "[5600]\ttraining's l1: 0.0206421\tvalid_1's l1: 0.179554\n",
            "[5800]\ttraining's l1: 0.0204036\tvalid_1's l1: 0.179456\n",
            "[6000]\ttraining's l1: 0.0201894\tvalid_1's l1: 0.179365\n",
            "[6200]\ttraining's l1: 0.0199786\tvalid_1's l1: 0.179269\n",
            "[6400]\ttraining's l1: 0.0197804\tvalid_1's l1: 0.179197\n",
            "[6600]\ttraining's l1: 0.019613\tvalid_1's l1: 0.179133\n",
            "[6800]\ttraining's l1: 0.0194441\tvalid_1's l1: 0.179061\n",
            "[7000]\ttraining's l1: 0.0192906\tvalid_1's l1: 0.178995\n",
            "[7200]\ttraining's l1: 0.0191355\tvalid_1's l1: 0.178937\n",
            "[7400]\ttraining's l1: 0.0189751\tvalid_1's l1: 0.178878\n",
            "[7600]\ttraining's l1: 0.018832\tvalid_1's l1: 0.178846\n",
            "[7800]\ttraining's l1: 0.0186915\tvalid_1's l1: 0.178789\n",
            "[8000]\ttraining's l1: 0.018562\tvalid_1's l1: 0.178729\n",
            "[8200]\ttraining's l1: 0.0184437\tvalid_1's l1: 0.178692\n",
            "[8400]\ttraining's l1: 0.018338\tvalid_1's l1: 0.178636\n",
            "[8600]\ttraining's l1: 0.0182205\tvalid_1's l1: 0.178607\n",
            "[8800]\ttraining's l1: 0.0181225\tvalid_1's l1: 0.178568\n",
            "[9000]\ttraining's l1: 0.0180191\tvalid_1's l1: 0.178549\n",
            "[9200]\ttraining's l1: 0.0179216\tvalid_1's l1: 0.178496\n",
            "[9400]\ttraining's l1: 0.0178259\tvalid_1's l1: 0.178456\n",
            "[9600]\ttraining's l1: 0.0177382\tvalid_1's l1: 0.17842\n",
            "[9800]\ttraining's l1: 0.0176473\tvalid_1's l1: 0.178388\n",
            "[10000]\ttraining's l1: 0.0175605\tvalid_1's l1: 0.178349\n",
            "[10200]\ttraining's l1: 0.0174744\tvalid_1's l1: 0.178314\n",
            "[10400]\ttraining's l1: 0.0173998\tvalid_1's l1: 0.178284\n",
            "[10600]\ttraining's l1: 0.0173226\tvalid_1's l1: 0.178246\n",
            "[10800]\ttraining's l1: 0.0172442\tvalid_1's l1: 0.178226\n",
            "[11000]\ttraining's l1: 0.017168\tvalid_1's l1: 0.178195\n",
            "[11200]\ttraining's l1: 0.0170919\tvalid_1's l1: 0.178166\n",
            "[11400]\ttraining's l1: 0.0170239\tvalid_1's l1: 0.178147\n",
            "[11600]\ttraining's l1: 0.0169449\tvalid_1's l1: 0.178116\n",
            "[11800]\ttraining's l1: 0.0168812\tvalid_1's l1: 0.178084\n",
            "[12000]\ttraining's l1: 0.0168171\tvalid_1's l1: 0.178065\n",
            "[12200]\ttraining's l1: 0.0167541\tvalid_1's l1: 0.178048\n",
            "[12400]\ttraining's l1: 0.0166948\tvalid_1's l1: 0.178027\n",
            "[12600]\ttraining's l1: 0.0166281\tvalid_1's l1: 0.177996\n",
            "[12800]\ttraining's l1: 0.0165845\tvalid_1's l1: 0.177978\n",
            "[13000]\ttraining's l1: 0.0165174\tvalid_1's l1: 0.177947\n",
            "[13200]\ttraining's l1: 0.0164552\tvalid_1's l1: 0.177925\n",
            "[13400]\ttraining's l1: 0.0163936\tvalid_1's l1: 0.177906\n",
            "[13600]\ttraining's l1: 0.0163371\tvalid_1's l1: 0.177879\n",
            "[13800]\ttraining's l1: 0.0162815\tvalid_1's l1: 0.177856\n",
            "[14000]\ttraining's l1: 0.0162344\tvalid_1's l1: 0.177834\n",
            "[14200]\ttraining's l1: 0.0161816\tvalid_1's l1: 0.177815\n",
            "[14400]\ttraining's l1: 0.0161335\tvalid_1's l1: 0.177791\n",
            "[14600]\ttraining's l1: 0.0160847\tvalid_1's l1: 0.177774\n",
            "[14800]\ttraining's l1: 0.0160427\tvalid_1's l1: 0.177759\n",
            "[15000]\ttraining's l1: 0.0159971\tvalid_1's l1: 0.177748\n",
            "[15200]\ttraining's l1: 0.0159529\tvalid_1's l1: 0.177727\n",
            "[15400]\ttraining's l1: 0.0159049\tvalid_1's l1: 0.177718\n",
            "[15600]\ttraining's l1: 0.0158618\tvalid_1's l1: 0.177704\n",
            "[15800]\ttraining's l1: 0.0158194\tvalid_1's l1: 0.177683\n",
            "[16000]\ttraining's l1: 0.0157759\tvalid_1's l1: 0.177659\n",
            "[16200]\ttraining's l1: 0.0157339\tvalid_1's l1: 0.17765\n",
            "[16400]\ttraining's l1: 0.0156946\tvalid_1's l1: 0.17764\n",
            "[16600]\ttraining's l1: 0.0156579\tvalid_1's l1: 0.177628\n",
            "[16800]\ttraining's l1: 0.0156192\tvalid_1's l1: 0.177603\n",
            "[17000]\ttraining's l1: 0.0155806\tvalid_1's l1: 0.17759\n",
            "[17200]\ttraining's l1: 0.0155366\tvalid_1's l1: 0.177582\n",
            "[17400]\ttraining's l1: 0.015505\tvalid_1's l1: 0.177566\n",
            "[17600]\ttraining's l1: 0.0154715\tvalid_1's l1: 0.177552\n",
            "[17800]\ttraining's l1: 0.0154331\tvalid_1's l1: 0.177534\n",
            "[18000]\ttraining's l1: 0.0153925\tvalid_1's l1: 0.177521\n",
            "[18200]\ttraining's l1: 0.01535\tvalid_1's l1: 0.177506\n",
            "[18400]\ttraining's l1: 0.01531\tvalid_1's l1: 0.177488\n",
            "[18600]\ttraining's l1: 0.0152701\tvalid_1's l1: 0.177479\n",
            "[18800]\ttraining's l1: 0.0152364\tvalid_1's l1: 0.177467\n",
            "[19000]\ttraining's l1: 0.0152022\tvalid_1's l1: 0.177451\n",
            "[19200]\ttraining's l1: 0.0151703\tvalid_1's l1: 0.17744\n",
            "[19400]\ttraining's l1: 0.0151368\tvalid_1's l1: 0.177422\n",
            "[19600]\ttraining's l1: 0.0151016\tvalid_1's l1: 0.177415\n",
            "[19800]\ttraining's l1: 0.0150727\tvalid_1's l1: 0.177401\n",
            "[20000]\ttraining's l1: 0.0150384\tvalid_1's l1: 0.177397\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[19969]\ttraining's l1: 0.0150435\tvalid_1's l1: 0.177396\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[200]\ttraining's l1: 0.173053\tvalid_1's l1: 0.229399\n",
            "[400]\ttraining's l1: 0.125489\tvalid_1's l1: 0.217078\n",
            "[600]\ttraining's l1: 0.0937616\tvalid_1's l1: 0.209007\n",
            "[800]\ttraining's l1: 0.0727908\tvalid_1's l1: 0.203163\n",
            "[1000]\ttraining's l1: 0.0591565\tvalid_1's l1: 0.198965\n",
            "[1200]\ttraining's l1: 0.0494801\tvalid_1's l1: 0.195761\n",
            "[1400]\ttraining's l1: 0.0433119\tvalid_1's l1: 0.193601\n",
            "[1600]\ttraining's l1: 0.0387823\tvalid_1's l1: 0.192167\n",
            "[1800]\ttraining's l1: 0.035502\tvalid_1's l1: 0.190986\n",
            "[2000]\ttraining's l1: 0.033072\tvalid_1's l1: 0.19016\n",
            "[2200]\ttraining's l1: 0.0311063\tvalid_1's l1: 0.189478\n",
            "[2400]\ttraining's l1: 0.0296082\tvalid_1's l1: 0.188948\n",
            "[2600]\ttraining's l1: 0.0283634\tvalid_1's l1: 0.188495\n",
            "[2800]\ttraining's l1: 0.0273793\tvalid_1's l1: 0.188144\n",
            "[3000]\ttraining's l1: 0.0264932\tvalid_1's l1: 0.18783\n",
            "[3200]\ttraining's l1: 0.025743\tvalid_1's l1: 0.187521\n",
            "[3400]\ttraining's l1: 0.0250796\tvalid_1's l1: 0.187279\n",
            "[3600]\ttraining's l1: 0.024511\tvalid_1's l1: 0.187081\n",
            "[3800]\ttraining's l1: 0.0239804\tvalid_1's l1: 0.186915\n",
            "[4000]\ttraining's l1: 0.0234914\tvalid_1's l1: 0.18674\n",
            "[4200]\ttraining's l1: 0.0230475\tvalid_1's l1: 0.186585\n",
            "[4400]\ttraining's l1: 0.0226553\tvalid_1's l1: 0.186467\n",
            "[4600]\ttraining's l1: 0.0222941\tvalid_1's l1: 0.186309\n",
            "[4800]\ttraining's l1: 0.0219684\tvalid_1's l1: 0.186172\n",
            "[5000]\ttraining's l1: 0.0216692\tvalid_1's l1: 0.186027\n",
            "[5200]\ttraining's l1: 0.0213615\tvalid_1's l1: 0.185907\n",
            "[5400]\ttraining's l1: 0.0210862\tvalid_1's l1: 0.185828\n",
            "[5600]\ttraining's l1: 0.0208463\tvalid_1's l1: 0.185758\n",
            "[5800]\ttraining's l1: 0.0206177\tvalid_1's l1: 0.185711\n",
            "[6000]\ttraining's l1: 0.0204016\tvalid_1's l1: 0.185611\n",
            "[6200]\ttraining's l1: 0.0201936\tvalid_1's l1: 0.185542\n",
            "[6400]\ttraining's l1: 0.0200046\tvalid_1's l1: 0.185478\n",
            "[6600]\ttraining's l1: 0.0198152\tvalid_1's l1: 0.185417\n",
            "[6800]\ttraining's l1: 0.0196461\tvalid_1's l1: 0.185379\n",
            "[7000]\ttraining's l1: 0.0194902\tvalid_1's l1: 0.185307\n",
            "[7200]\ttraining's l1: 0.0193422\tvalid_1's l1: 0.18525\n",
            "[7400]\ttraining's l1: 0.0192078\tvalid_1's l1: 0.185213\n",
            "[7600]\ttraining's l1: 0.0190644\tvalid_1's l1: 0.185156\n",
            "[7800]\ttraining's l1: 0.0189433\tvalid_1's l1: 0.185099\n",
            "[8000]\ttraining's l1: 0.018814\tvalid_1's l1: 0.185047\n",
            "[8200]\ttraining's l1: 0.0186971\tvalid_1's l1: 0.185003\n",
            "[8400]\ttraining's l1: 0.0185833\tvalid_1's l1: 0.184956\n",
            "[8600]\ttraining's l1: 0.0184761\tvalid_1's l1: 0.184917\n",
            "[8800]\ttraining's l1: 0.0183649\tvalid_1's l1: 0.184871\n",
            "[9000]\ttraining's l1: 0.0182539\tvalid_1's l1: 0.184818\n",
            "[9200]\ttraining's l1: 0.0181589\tvalid_1's l1: 0.184779\n",
            "[9400]\ttraining's l1: 0.0180629\tvalid_1's l1: 0.184749\n",
            "[9600]\ttraining's l1: 0.0179717\tvalid_1's l1: 0.184712\n",
            "[9800]\ttraining's l1: 0.0178863\tvalid_1's l1: 0.184672\n",
            "[10000]\ttraining's l1: 0.0177941\tvalid_1's l1: 0.184644\n",
            "[10200]\ttraining's l1: 0.0177149\tvalid_1's l1: 0.18462\n",
            "[10400]\ttraining's l1: 0.0176285\tvalid_1's l1: 0.18459\n",
            "[10600]\ttraining's l1: 0.017541\tvalid_1's l1: 0.184559\n",
            "[10800]\ttraining's l1: 0.0174644\tvalid_1's l1: 0.184524\n",
            "[11000]\ttraining's l1: 0.0173825\tvalid_1's l1: 0.184498\n",
            "[11200]\ttraining's l1: 0.0173017\tvalid_1's l1: 0.184469\n",
            "[11400]\ttraining's l1: 0.0172309\tvalid_1's l1: 0.184446\n",
            "[11600]\ttraining's l1: 0.0171538\tvalid_1's l1: 0.184416\n",
            "[11800]\ttraining's l1: 0.0170929\tvalid_1's l1: 0.184383\n",
            "[12000]\ttraining's l1: 0.0170322\tvalid_1's l1: 0.184375\n",
            "[12200]\ttraining's l1: 0.0169692\tvalid_1's l1: 0.184349\n",
            "[12400]\ttraining's l1: 0.0168978\tvalid_1's l1: 0.184337\n",
            "[12600]\ttraining's l1: 0.016827\tvalid_1's l1: 0.18431\n",
            "[12800]\ttraining's l1: 0.0167688\tvalid_1's l1: 0.184297\n",
            "[13000]\ttraining's l1: 0.0167049\tvalid_1's l1: 0.184275\n",
            "[13200]\ttraining's l1: 0.0166521\tvalid_1's l1: 0.184251\n",
            "[13400]\ttraining's l1: 0.0165941\tvalid_1's l1: 0.184236\n",
            "[13600]\ttraining's l1: 0.0165274\tvalid_1's l1: 0.184209\n",
            "[13800]\ttraining's l1: 0.016478\tvalid_1's l1: 0.184183\n",
            "[14000]\ttraining's l1: 0.0164245\tvalid_1's l1: 0.184172\n",
            "[14200]\ttraining's l1: 0.0163832\tvalid_1's l1: 0.184141\n",
            "[14400]\ttraining's l1: 0.0163288\tvalid_1's l1: 0.184123\n",
            "[14600]\ttraining's l1: 0.0162793\tvalid_1's l1: 0.184108\n",
            "[14800]\ttraining's l1: 0.0162239\tvalid_1's l1: 0.184081\n",
            "[15000]\ttraining's l1: 0.0161735\tvalid_1's l1: 0.184064\n",
            "[15200]\ttraining's l1: 0.0161249\tvalid_1's l1: 0.184048\n",
            "[15400]\ttraining's l1: 0.0160852\tvalid_1's l1: 0.184032\n",
            "[15600]\ttraining's l1: 0.0160389\tvalid_1's l1: 0.184017\n",
            "[15800]\ttraining's l1: 0.0159978\tvalid_1's l1: 0.183999\n",
            "[16000]\ttraining's l1: 0.0159491\tvalid_1's l1: 0.183981\n",
            "[16200]\ttraining's l1: 0.0159047\tvalid_1's l1: 0.183968\n",
            "[16400]\ttraining's l1: 0.0158564\tvalid_1's l1: 0.183948\n",
            "[16600]\ttraining's l1: 0.0158149\tvalid_1's l1: 0.183931\n",
            "[16800]\ttraining's l1: 0.0157773\tvalid_1's l1: 0.183916\n",
            "[17000]\ttraining's l1: 0.0157431\tvalid_1's l1: 0.183902\n",
            "[17200]\ttraining's l1: 0.0157018\tvalid_1's l1: 0.18389\n",
            "[17400]\ttraining's l1: 0.0156602\tvalid_1's l1: 0.183875\n",
            "[17600]\ttraining's l1: 0.0156232\tvalid_1's l1: 0.183865\n",
            "[17800]\ttraining's l1: 0.0155853\tvalid_1's l1: 0.18384\n",
            "[18000]\ttraining's l1: 0.0155478\tvalid_1's l1: 0.183836\n",
            "[18200]\ttraining's l1: 0.0155082\tvalid_1's l1: 0.183825\n",
            "[18400]\ttraining's l1: 0.0154716\tvalid_1's l1: 0.183814\n",
            "[18600]\ttraining's l1: 0.0154336\tvalid_1's l1: 0.183794\n",
            "[18800]\ttraining's l1: 0.0154005\tvalid_1's l1: 0.183782\n",
            "[19000]\ttraining's l1: 0.0153685\tvalid_1's l1: 0.183774\n",
            "[19200]\ttraining's l1: 0.0153356\tvalid_1's l1: 0.183764\n",
            "[19400]\ttraining's l1: 0.0153002\tvalid_1's l1: 0.183752\n",
            "[19600]\ttraining's l1: 0.015263\tvalid_1's l1: 0.18373\n",
            "[19800]\ttraining's l1: 0.015231\tvalid_1's l1: 0.183716\n",
            "[20000]\ttraining's l1: 0.0152022\tvalid_1's l1: 0.18371\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[19887]\ttraining's l1: 0.0152215\tvalid_1's l1: 0.183709\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[200]\ttraining's l1: 0.17133\tvalid_1's l1: 0.234502\n",
            "[400]\ttraining's l1: 0.125078\tvalid_1's l1: 0.22259\n",
            "[600]\ttraining's l1: 0.0940349\tvalid_1's l1: 0.213274\n",
            "[800]\ttraining's l1: 0.0729002\tvalid_1's l1: 0.206574\n",
            "[1000]\ttraining's l1: 0.0587662\tvalid_1's l1: 0.20191\n",
            "[1200]\ttraining's l1: 0.0494675\tvalid_1's l1: 0.198614\n",
            "[1400]\ttraining's l1: 0.0430391\tvalid_1's l1: 0.196565\n",
            "[1600]\ttraining's l1: 0.0385241\tvalid_1's l1: 0.194851\n",
            "[1800]\ttraining's l1: 0.03527\tvalid_1's l1: 0.193741\n",
            "[2000]\ttraining's l1: 0.0327676\tvalid_1's l1: 0.192814\n",
            "[2200]\ttraining's l1: 0.0308338\tvalid_1's l1: 0.19216\n",
            "[2400]\ttraining's l1: 0.0292494\tvalid_1's l1: 0.191494\n",
            "[2600]\ttraining's l1: 0.0279975\tvalid_1's l1: 0.191136\n",
            "[2800]\ttraining's l1: 0.026959\tvalid_1's l1: 0.190756\n",
            "[3000]\ttraining's l1: 0.0260803\tvalid_1's l1: 0.190424\n",
            "[3200]\ttraining's l1: 0.0253038\tvalid_1's l1: 0.190178\n",
            "[3400]\ttraining's l1: 0.0246516\tvalid_1's l1: 0.189969\n",
            "[3600]\ttraining's l1: 0.0240547\tvalid_1's l1: 0.189765\n",
            "[3800]\ttraining's l1: 0.0235369\tvalid_1's l1: 0.189607\n",
            "[4000]\ttraining's l1: 0.0230862\tvalid_1's l1: 0.189462\n",
            "[4200]\ttraining's l1: 0.0226531\tvalid_1's l1: 0.1893\n",
            "[4400]\ttraining's l1: 0.022258\tvalid_1's l1: 0.189162\n",
            "[4600]\ttraining's l1: 0.0219012\tvalid_1's l1: 0.189027\n",
            "[4800]\ttraining's l1: 0.0215785\tvalid_1's l1: 0.188909\n",
            "[5000]\ttraining's l1: 0.0212794\tvalid_1's l1: 0.188811\n",
            "[5200]\ttraining's l1: 0.0210025\tvalid_1's l1: 0.188708\n",
            "[5400]\ttraining's l1: 0.0207569\tvalid_1's l1: 0.188617\n",
            "[5600]\ttraining's l1: 0.0205272\tvalid_1's l1: 0.188535\n",
            "[5800]\ttraining's l1: 0.0203107\tvalid_1's l1: 0.18845\n",
            "[6000]\ttraining's l1: 0.0200999\tvalid_1's l1: 0.188355\n",
            "[6200]\ttraining's l1: 0.0199113\tvalid_1's l1: 0.188285\n",
            "[6400]\ttraining's l1: 0.0197257\tvalid_1's l1: 0.1882\n",
            "[6600]\ttraining's l1: 0.0195641\tvalid_1's l1: 0.188156\n",
            "[6800]\ttraining's l1: 0.0193992\tvalid_1's l1: 0.188106\n",
            "[7000]\ttraining's l1: 0.0192422\tvalid_1's l1: 0.188061\n",
            "[7200]\ttraining's l1: 0.0190819\tvalid_1's l1: 0.187995\n",
            "[7400]\ttraining's l1: 0.0189321\tvalid_1's l1: 0.187941\n",
            "[7600]\ttraining's l1: 0.01879\tvalid_1's l1: 0.187884\n",
            "[7800]\ttraining's l1: 0.0186549\tvalid_1's l1: 0.187839\n",
            "[8000]\ttraining's l1: 0.0185357\tvalid_1's l1: 0.18781\n",
            "[8200]\ttraining's l1: 0.018428\tvalid_1's l1: 0.187773\n",
            "[8400]\ttraining's l1: 0.0183213\tvalid_1's l1: 0.187749\n",
            "[8600]\ttraining's l1: 0.0182149\tvalid_1's l1: 0.187694\n",
            "[8800]\ttraining's l1: 0.0181083\tvalid_1's l1: 0.18766\n",
            "[9000]\ttraining's l1: 0.0180005\tvalid_1's l1: 0.187612\n",
            "[9200]\ttraining's l1: 0.0178977\tvalid_1's l1: 0.187595\n",
            "[9400]\ttraining's l1: 0.0178131\tvalid_1's l1: 0.187551\n",
            "[9600]\ttraining's l1: 0.0177177\tvalid_1's l1: 0.187524\n",
            "[9800]\ttraining's l1: 0.0176337\tvalid_1's l1: 0.187494\n",
            "[10000]\ttraining's l1: 0.0175432\tvalid_1's l1: 0.187466\n",
            "[10200]\ttraining's l1: 0.0174618\tvalid_1's l1: 0.187448\n",
            "[10400]\ttraining's l1: 0.0173835\tvalid_1's l1: 0.187426\n",
            "[10600]\ttraining's l1: 0.017313\tvalid_1's l1: 0.187419\n",
            "[10800]\ttraining's l1: 0.0172397\tvalid_1's l1: 0.187398\n",
            "[11000]\ttraining's l1: 0.0171666\tvalid_1's l1: 0.18737\n",
            "[11200]\ttraining's l1: 0.0170967\tvalid_1's l1: 0.187346\n",
            "[11400]\ttraining's l1: 0.0170274\tvalid_1's l1: 0.187321\n",
            "[11600]\ttraining's l1: 0.0169582\tvalid_1's l1: 0.187288\n",
            "[11800]\ttraining's l1: 0.0168922\tvalid_1's l1: 0.187266\n",
            "[12000]\ttraining's l1: 0.0168313\tvalid_1's l1: 0.187238\n",
            "[12200]\ttraining's l1: 0.0167621\tvalid_1's l1: 0.187219\n",
            "[12400]\ttraining's l1: 0.016699\tvalid_1's l1: 0.187193\n",
            "[12600]\ttraining's l1: 0.0166437\tvalid_1's l1: 0.187187\n",
            "[12800]\ttraining's l1: 0.0165854\tvalid_1's l1: 0.187155\n",
            "[13000]\ttraining's l1: 0.0165242\tvalid_1's l1: 0.187141\n",
            "[13200]\ttraining's l1: 0.0164698\tvalid_1's l1: 0.187127\n",
            "[13400]\ttraining's l1: 0.016414\tvalid_1's l1: 0.187102\n",
            "[13600]\ttraining's l1: 0.0163621\tvalid_1's l1: 0.187077\n",
            "[13800]\ttraining's l1: 0.0163154\tvalid_1's l1: 0.187066\n",
            "[14000]\ttraining's l1: 0.0162565\tvalid_1's l1: 0.187048\n",
            "[14200]\ttraining's l1: 0.0162011\tvalid_1's l1: 0.187022\n",
            "[14400]\ttraining's l1: 0.0161543\tvalid_1's l1: 0.187018\n",
            "[14600]\ttraining's l1: 0.0161124\tvalid_1's l1: 0.187011\n",
            "[14800]\ttraining's l1: 0.0160615\tvalid_1's l1: 0.186998\n",
            "[15000]\ttraining's l1: 0.0160161\tvalid_1's l1: 0.186988\n",
            "[15200]\ttraining's l1: 0.0159709\tvalid_1's l1: 0.186969\n",
            "[15400]\ttraining's l1: 0.0159265\tvalid_1's l1: 0.186952\n",
            "[15600]\ttraining's l1: 0.0158845\tvalid_1's l1: 0.186941\n",
            "[15800]\ttraining's l1: 0.0158463\tvalid_1's l1: 0.186932\n",
            "[16000]\ttraining's l1: 0.0158056\tvalid_1's l1: 0.186923\n",
            "[16200]\ttraining's l1: 0.0157671\tvalid_1's l1: 0.186919\n",
            "[16400]\ttraining's l1: 0.0157297\tvalid_1's l1: 0.186907\n",
            "[16600]\ttraining's l1: 0.0156876\tvalid_1's l1: 0.186881\n",
            "[16800]\ttraining's l1: 0.0156554\tvalid_1's l1: 0.186869\n",
            "[17000]\ttraining's l1: 0.0156149\tvalid_1's l1: 0.186861\n",
            "[17200]\ttraining's l1: 0.0155766\tvalid_1's l1: 0.186849\n",
            "[17400]\ttraining's l1: 0.0155332\tvalid_1's l1: 0.186835\n",
            "[17600]\ttraining's l1: 0.0155034\tvalid_1's l1: 0.186823\n",
            "[17800]\ttraining's l1: 0.0154616\tvalid_1's l1: 0.186806\n",
            "[18000]\ttraining's l1: 0.0154249\tvalid_1's l1: 0.18679\n",
            "[18200]\ttraining's l1: 0.0153867\tvalid_1's l1: 0.186779\n",
            "[18400]\ttraining's l1: 0.0153477\tvalid_1's l1: 0.186771\n",
            "[18600]\ttraining's l1: 0.0153145\tvalid_1's l1: 0.186756\n",
            "[18800]\ttraining's l1: 0.0152848\tvalid_1's l1: 0.186752\n",
            "[19000]\ttraining's l1: 0.0152525\tvalid_1's l1: 0.186735\n",
            "[19200]\ttraining's l1: 0.01522\tvalid_1's l1: 0.186725\n",
            "[19400]\ttraining's l1: 0.0151905\tvalid_1's l1: 0.18672\n",
            "[19600]\ttraining's l1: 0.0151581\tvalid_1's l1: 0.186709\n",
            "[19800]\ttraining's l1: 0.015131\tvalid_1's l1: 0.186705\n",
            "[20000]\ttraining's l1: 0.0150995\tvalid_1's l1: 0.186697\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[19968]\ttraining's l1: 0.0151043\tvalid_1's l1: 0.186696\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[200]\ttraining's l1: 0.174455\tvalid_1's l1: 0.225821\n",
            "[400]\ttraining's l1: 0.127607\tvalid_1's l1: 0.214077\n",
            "[600]\ttraining's l1: 0.0958234\tvalid_1's l1: 0.204752\n",
            "[800]\ttraining's l1: 0.074625\tvalid_1's l1: 0.198458\n",
            "[1000]\ttraining's l1: 0.0603473\tvalid_1's l1: 0.193782\n",
            "[1200]\ttraining's l1: 0.0505029\tvalid_1's l1: 0.190329\n",
            "[1400]\ttraining's l1: 0.0440012\tvalid_1's l1: 0.188148\n",
            "[1600]\ttraining's l1: 0.0394309\tvalid_1's l1: 0.18662\n",
            "[1800]\ttraining's l1: 0.0360641\tvalid_1's l1: 0.185427\n",
            "[2000]\ttraining's l1: 0.033667\tvalid_1's l1: 0.184595\n",
            "[2200]\ttraining's l1: 0.0316501\tvalid_1's l1: 0.183958\n",
            "[2400]\ttraining's l1: 0.0300824\tvalid_1's l1: 0.183365\n",
            "[2600]\ttraining's l1: 0.0288008\tvalid_1's l1: 0.182947\n",
            "[2800]\ttraining's l1: 0.0277611\tvalid_1's l1: 0.182507\n",
            "[3000]\ttraining's l1: 0.0268535\tvalid_1's l1: 0.182273\n",
            "[3200]\ttraining's l1: 0.0260426\tvalid_1's l1: 0.182004\n",
            "[3400]\ttraining's l1: 0.0253853\tvalid_1's l1: 0.181748\n",
            "[3600]\ttraining's l1: 0.0247926\tvalid_1's l1: 0.181529\n",
            "[3800]\ttraining's l1: 0.0242589\tvalid_1's l1: 0.181324\n",
            "[4000]\ttraining's l1: 0.0237904\tvalid_1's l1: 0.181147\n",
            "[4200]\ttraining's l1: 0.0233757\tvalid_1's l1: 0.181035\n",
            "[4400]\ttraining's l1: 0.0229581\tvalid_1's l1: 0.180854\n",
            "[4600]\ttraining's l1: 0.0225906\tvalid_1's l1: 0.180732\n",
            "[4800]\ttraining's l1: 0.022259\tvalid_1's l1: 0.18063\n",
            "[5000]\ttraining's l1: 0.0219565\tvalid_1's l1: 0.180499\n",
            "[5200]\ttraining's l1: 0.0216767\tvalid_1's l1: 0.180392\n",
            "[5400]\ttraining's l1: 0.021404\tvalid_1's l1: 0.18027\n",
            "[5600]\ttraining's l1: 0.0211467\tvalid_1's l1: 0.1802\n",
            "[5800]\ttraining's l1: 0.0209039\tvalid_1's l1: 0.180129\n",
            "[6000]\ttraining's l1: 0.0206939\tvalid_1's l1: 0.180046\n",
            "[6200]\ttraining's l1: 0.0204905\tvalid_1's l1: 0.180005\n",
            "[6400]\ttraining's l1: 0.0202797\tvalid_1's l1: 0.179915\n",
            "[6600]\ttraining's l1: 0.0200717\tvalid_1's l1: 0.179812\n",
            "[6800]\ttraining's l1: 0.0199055\tvalid_1's l1: 0.17974\n",
            "[7000]\ttraining's l1: 0.0197369\tvalid_1's l1: 0.179663\n",
            "[7200]\ttraining's l1: 0.0195765\tvalid_1's l1: 0.179609\n",
            "[7400]\ttraining's l1: 0.0194259\tvalid_1's l1: 0.17955\n",
            "[7600]\ttraining's l1: 0.0192883\tvalid_1's l1: 0.179515\n",
            "[7800]\ttraining's l1: 0.0191646\tvalid_1's l1: 0.179456\n",
            "[8000]\ttraining's l1: 0.0190401\tvalid_1's l1: 0.179427\n",
            "[8200]\ttraining's l1: 0.0189251\tvalid_1's l1: 0.179369\n",
            "[8400]\ttraining's l1: 0.0188132\tvalid_1's l1: 0.17933\n",
            "[8600]\ttraining's l1: 0.0187083\tvalid_1's l1: 0.179308\n",
            "[8800]\ttraining's l1: 0.0185992\tvalid_1's l1: 0.179271\n",
            "[9000]\ttraining's l1: 0.0184939\tvalid_1's l1: 0.179233\n",
            "[9200]\ttraining's l1: 0.0183802\tvalid_1's l1: 0.179199\n",
            "[9400]\ttraining's l1: 0.0182694\tvalid_1's l1: 0.179168\n",
            "[9600]\ttraining's l1: 0.018164\tvalid_1's l1: 0.179112\n",
            "[9800]\ttraining's l1: 0.0180772\tvalid_1's l1: 0.179074\n",
            "[10000]\ttraining's l1: 0.0179889\tvalid_1's l1: 0.179052\n",
            "[10200]\ttraining's l1: 0.0178971\tvalid_1's l1: 0.179014\n",
            "[10400]\ttraining's l1: 0.0178021\tvalid_1's l1: 0.178979\n",
            "[10600]\ttraining's l1: 0.0177189\tvalid_1's l1: 0.17896\n",
            "[10800]\ttraining's l1: 0.0176389\tvalid_1's l1: 0.178928\n",
            "[11000]\ttraining's l1: 0.0175694\tvalid_1's l1: 0.178895\n",
            "[11200]\ttraining's l1: 0.017497\tvalid_1's l1: 0.178868\n",
            "[11400]\ttraining's l1: 0.017425\tvalid_1's l1: 0.178833\n",
            "[11600]\ttraining's l1: 0.0173476\tvalid_1's l1: 0.178822\n",
            "[11800]\ttraining's l1: 0.0172815\tvalid_1's l1: 0.178796\n",
            "[12000]\ttraining's l1: 0.0172171\tvalid_1's l1: 0.178781\n",
            "[12200]\ttraining's l1: 0.0171475\tvalid_1's l1: 0.178756\n",
            "[12400]\ttraining's l1: 0.0170803\tvalid_1's l1: 0.178731\n",
            "[12600]\ttraining's l1: 0.0170182\tvalid_1's l1: 0.178694\n",
            "[12800]\ttraining's l1: 0.0169458\tvalid_1's l1: 0.178679\n",
            "[13000]\ttraining's l1: 0.016894\tvalid_1's l1: 0.178659\n",
            "[13200]\ttraining's l1: 0.0168431\tvalid_1's l1: 0.178651\n",
            "[13400]\ttraining's l1: 0.0167802\tvalid_1's l1: 0.178635\n",
            "[13600]\ttraining's l1: 0.0167203\tvalid_1's l1: 0.178602\n",
            "[13800]\ttraining's l1: 0.0166644\tvalid_1's l1: 0.178578\n",
            "[14000]\ttraining's l1: 0.0166077\tvalid_1's l1: 0.178559\n",
            "[14200]\ttraining's l1: 0.0165536\tvalid_1's l1: 0.178546\n",
            "[14400]\ttraining's l1: 0.0164982\tvalid_1's l1: 0.178529\n",
            "[14600]\ttraining's l1: 0.0164461\tvalid_1's l1: 0.17851\n",
            "[14800]\ttraining's l1: 0.0163913\tvalid_1's l1: 0.178504\n",
            "[15000]\ttraining's l1: 0.0163341\tvalid_1's l1: 0.178487\n",
            "[15200]\ttraining's l1: 0.0162799\tvalid_1's l1: 0.178466\n",
            "[15400]\ttraining's l1: 0.0162404\tvalid_1's l1: 0.178452\n",
            "[15600]\ttraining's l1: 0.0161966\tvalid_1's l1: 0.178431\n",
            "[15800]\ttraining's l1: 0.0161512\tvalid_1's l1: 0.17842\n",
            "[16000]\ttraining's l1: 0.0161094\tvalid_1's l1: 0.178402\n",
            "[16200]\ttraining's l1: 0.0160675\tvalid_1's l1: 0.178398\n",
            "Early stopping, best iteration is:\n",
            "[16028]\ttraining's l1: 0.0161037\tvalid_1's l1: 0.178396\n",
            "\n",
            "✅ CV MAE: 0.17891\n",
            "✅ submission4.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 없습니다.\")\n",
        "\n",
        "    # ID 분리\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 숫자 / 범주형 컬럼 구분\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 수치형 컬럼 문자열 → 숫자형 변환\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\")\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "    for col in cat_cols:\n",
        "        mode_val = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode_val)\n",
        "        test[col]  = test[col].fillna(mode_val)\n",
        "\n",
        "    # 범주형 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test  = pd.get_dummies(test,  columns=cat_cols)\n",
        "\n",
        "    # train/test 컬럼 맞추기\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"num_leaves\": 31,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=100),\n",
        "                log_evaluation(period=200)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_final5.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_final5.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efRan31L5uX0",
        "outputId": "5a16df8e-1d86-4a39-94e8-601aa0223ea9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.12474\tvalid_1's l1: 0.202508\n",
            "[400]\ttraining's l1: 0.0746857\tvalid_1's l1: 0.186713\n",
            "[600]\ttraining's l1: 0.0484242\tvalid_1's l1: 0.178418\n",
            "[800]\ttraining's l1: 0.0328702\tvalid_1's l1: 0.173155\n",
            "[1000]\ttraining's l1: 0.0231374\tvalid_1's l1: 0.17003\n",
            "[1200]\ttraining's l1: 0.0170938\tvalid_1's l1: 0.167826\n",
            "[1400]\ttraining's l1: 0.0129644\tvalid_1's l1: 0.166492\n",
            "[1600]\ttraining's l1: 0.00998153\tvalid_1's l1: 0.165687\n",
            "[1800]\ttraining's l1: 0.00780908\tvalid_1's l1: 0.165174\n",
            "[2000]\ttraining's l1: 0.00626257\tvalid_1's l1: 0.164797\n",
            "[2200]\ttraining's l1: 0.00511298\tvalid_1's l1: 0.16453\n",
            "[2400]\ttraining's l1: 0.00423438\tvalid_1's l1: 0.164344\n",
            "[2600]\ttraining's l1: 0.00352876\tvalid_1's l1: 0.164225\n",
            "[2800]\ttraining's l1: 0.00298945\tvalid_1's l1: 0.164111\n",
            "[3000]\ttraining's l1: 0.00253804\tvalid_1's l1: 0.164034\n",
            "[3200]\ttraining's l1: 0.00217207\tvalid_1's l1: 0.163951\n",
            "[3400]\ttraining's l1: 0.00188136\tvalid_1's l1: 0.163916\n",
            "[3600]\ttraining's l1: 0.00165329\tvalid_1's l1: 0.163889\n",
            "[3800]\ttraining's l1: 0.00145535\tvalid_1's l1: 0.163853\n",
            "[4000]\ttraining's l1: 0.00129559\tvalid_1's l1: 0.163839\n",
            "[4200]\ttraining's l1: 0.00115705\tvalid_1's l1: 0.163827\n",
            "Early stopping, best iteration is:\n",
            "[4181]\ttraining's l1: 0.00117012\tvalid_1's l1: 0.163825\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.122616\tvalid_1's l1: 0.208896\n",
            "[400]\ttraining's l1: 0.072667\tvalid_1's l1: 0.19543\n",
            "[600]\ttraining's l1: 0.0470788\tvalid_1's l1: 0.189237\n",
            "[800]\ttraining's l1: 0.0322404\tvalid_1's l1: 0.184736\n",
            "[1000]\ttraining's l1: 0.0228228\tvalid_1's l1: 0.181602\n",
            "[1200]\ttraining's l1: 0.0167952\tvalid_1's l1: 0.17949\n",
            "[1400]\ttraining's l1: 0.0128347\tvalid_1's l1: 0.178434\n",
            "[1600]\ttraining's l1: 0.00982015\tvalid_1's l1: 0.177715\n",
            "[1800]\ttraining's l1: 0.00773315\tvalid_1's l1: 0.177259\n",
            "[2000]\ttraining's l1: 0.00624667\tvalid_1's l1: 0.17699\n",
            "[2200]\ttraining's l1: 0.00510247\tvalid_1's l1: 0.176785\n",
            "[2400]\ttraining's l1: 0.00422959\tvalid_1's l1: 0.176601\n",
            "[2600]\ttraining's l1: 0.00354387\tvalid_1's l1: 0.176544\n",
            "Early stopping, best iteration is:\n",
            "[2651]\ttraining's l1: 0.0033943\tvalid_1's l1: 0.176524\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.122224\tvalid_1's l1: 0.218376\n",
            "[400]\ttraining's l1: 0.0726245\tvalid_1's l1: 0.202379\n",
            "[600]\ttraining's l1: 0.0468954\tvalid_1's l1: 0.194677\n",
            "[800]\ttraining's l1: 0.0321399\tvalid_1's l1: 0.189985\n",
            "[1000]\ttraining's l1: 0.0227458\tvalid_1's l1: 0.186861\n",
            "[1200]\ttraining's l1: 0.016674\tvalid_1's l1: 0.185044\n",
            "[1400]\ttraining's l1: 0.0125191\tvalid_1's l1: 0.183694\n",
            "[1600]\ttraining's l1: 0.00956661\tvalid_1's l1: 0.182869\n",
            "[1800]\ttraining's l1: 0.00743326\tvalid_1's l1: 0.182339\n",
            "[2000]\ttraining's l1: 0.00589606\tvalid_1's l1: 0.182027\n",
            "[2200]\ttraining's l1: 0.00474439\tvalid_1's l1: 0.181796\n",
            "[2400]\ttraining's l1: 0.0038986\tvalid_1's l1: 0.181674\n",
            "[2600]\ttraining's l1: 0.00324397\tvalid_1's l1: 0.181555\n",
            "[2800]\ttraining's l1: 0.0027362\tvalid_1's l1: 0.181499\n",
            "[3000]\ttraining's l1: 0.0023418\tvalid_1's l1: 0.181451\n",
            "[3200]\ttraining's l1: 0.00201126\tvalid_1's l1: 0.181406\n",
            "[3400]\ttraining's l1: 0.00174289\tvalid_1's l1: 0.181391\n",
            "[3600]\ttraining's l1: 0.00152803\tvalid_1's l1: 0.181367\n",
            "[3800]\ttraining's l1: 0.00134372\tvalid_1's l1: 0.181345\n",
            "Early stopping, best iteration is:\n",
            "[3895]\ttraining's l1: 0.00127003\tvalid_1's l1: 0.18134\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.119336\tvalid_1's l1: 0.224588\n",
            "[400]\ttraining's l1: 0.0714808\tvalid_1's l1: 0.211458\n",
            "[600]\ttraining's l1: 0.0461975\tvalid_1's l1: 0.202809\n",
            "[800]\ttraining's l1: 0.0314268\tvalid_1's l1: 0.198218\n",
            "[1000]\ttraining's l1: 0.0222768\tvalid_1's l1: 0.195064\n",
            "[1200]\ttraining's l1: 0.0164315\tvalid_1's l1: 0.193407\n",
            "[1400]\ttraining's l1: 0.0124776\tvalid_1's l1: 0.192208\n",
            "[1600]\ttraining's l1: 0.00964645\tvalid_1's l1: 0.191558\n",
            "[1800]\ttraining's l1: 0.00751636\tvalid_1's l1: 0.190997\n",
            "[2000]\ttraining's l1: 0.00598781\tvalid_1's l1: 0.190618\n",
            "[2200]\ttraining's l1: 0.00488197\tvalid_1's l1: 0.190416\n",
            "[2400]\ttraining's l1: 0.00401984\tvalid_1's l1: 0.190279\n",
            "[2600]\ttraining's l1: 0.0033137\tvalid_1's l1: 0.190176\n",
            "[2800]\ttraining's l1: 0.00278373\tvalid_1's l1: 0.190129\n",
            "[3000]\ttraining's l1: 0.00237749\tvalid_1's l1: 0.190076\n",
            "[3200]\ttraining's l1: 0.00203379\tvalid_1's l1: 0.190026\n",
            "[3400]\ttraining's l1: 0.00176518\tvalid_1's l1: 0.189981\n",
            "Early stopping, best iteration is:\n",
            "[3442]\ttraining's l1: 0.00171346\tvalid_1's l1: 0.189968\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.123961\tvalid_1's l1: 0.214649\n",
            "[400]\ttraining's l1: 0.0740082\tvalid_1's l1: 0.200691\n",
            "[600]\ttraining's l1: 0.0481176\tvalid_1's l1: 0.191499\n",
            "[800]\ttraining's l1: 0.0328936\tvalid_1's l1: 0.185318\n",
            "[1000]\ttraining's l1: 0.0235639\tvalid_1's l1: 0.181757\n",
            "[1200]\ttraining's l1: 0.0173461\tvalid_1's l1: 0.179325\n",
            "[1400]\ttraining's l1: 0.0129317\tvalid_1's l1: 0.177755\n",
            "[1600]\ttraining's l1: 0.0100274\tvalid_1's l1: 0.176797\n",
            "[1800]\ttraining's l1: 0.0078869\tvalid_1's l1: 0.176123\n",
            "[2000]\ttraining's l1: 0.00631536\tvalid_1's l1: 0.175655\n",
            "[2200]\ttraining's l1: 0.0051358\tvalid_1's l1: 0.175346\n",
            "[2400]\ttraining's l1: 0.00425056\tvalid_1's l1: 0.175171\n",
            "[2600]\ttraining's l1: 0.00356123\tvalid_1's l1: 0.175036\n",
            "[2800]\ttraining's l1: 0.00301683\tvalid_1's l1: 0.174884\n",
            "[3000]\ttraining's l1: 0.00257883\tvalid_1's l1: 0.174859\n",
            "[3200]\ttraining's l1: 0.00222656\tvalid_1's l1: 0.174802\n",
            "[3400]\ttraining's l1: 0.00194191\tvalid_1's l1: 0.174768\n",
            "[3600]\ttraining's l1: 0.00169105\tvalid_1's l1: 0.174748\n",
            "[3800]\ttraining's l1: 0.00148887\tvalid_1's l1: 0.174732\n",
            "[4000]\ttraining's l1: 0.00131389\tvalid_1's l1: 0.174717\n",
            "[4200]\ttraining's l1: 0.00116665\tvalid_1's l1: 0.174711\n",
            "Early stopping, best iteration is:\n",
            "[4137]\ttraining's l1: 0.00121861\tvalid_1's l1: 0.174708\n",
            "\n",
            "✅ CV MAE: 0.17727\n",
            "✅ submission_final5.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 없습니다.\")\n",
        "\n",
        "    # ID 분리\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 수치형/범주형 컬럼 구분\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 수치형 문자열 → 숫자\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\")\n",
        "\n",
        "    # 파생 변수 생성\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols + [\"BMI\",\"bp_ratio\"]:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    for col in cat_cols:\n",
        "        mode_val = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode_val)\n",
        "        test[col]  = test[col].fillna(mode_val)\n",
        "\n",
        "    # 범주형 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test  = pd.get_dummies(test, columns=cat_cols)\n",
        "\n",
        "    # train/test 컬럼 맞추기\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=200),\n",
        "                log_evaluation(period=200)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_upgrade.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_upgrade.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDembWAW5uVl",
        "outputId": "3cf75b22-b4df-41ab-a98e-a1bd7dbaca6d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.161673\tvalid_1's l1: 0.213423\n",
            "[400]\ttraining's l1: 0.110674\tvalid_1's l1: 0.198642\n",
            "[600]\ttraining's l1: 0.0788124\tvalid_1's l1: 0.188029\n",
            "[800]\ttraining's l1: 0.0580446\tvalid_1's l1: 0.182076\n",
            "[1000]\ttraining's l1: 0.0428326\tvalid_1's l1: 0.177431\n",
            "[1200]\ttraining's l1: 0.0335409\tvalid_1's l1: 0.174141\n",
            "[1400]\ttraining's l1: 0.0260026\tvalid_1's l1: 0.171755\n",
            "[1600]\ttraining's l1: 0.0202569\tvalid_1's l1: 0.169801\n",
            "[1800]\ttraining's l1: 0.0160592\tvalid_1's l1: 0.168264\n",
            "[2000]\ttraining's l1: 0.0128696\tvalid_1's l1: 0.167239\n",
            "[2200]\ttraining's l1: 0.0105459\tvalid_1's l1: 0.166577\n",
            "[2400]\ttraining's l1: 0.00859967\tvalid_1's l1: 0.166076\n",
            "[2600]\ttraining's l1: 0.00726469\tvalid_1's l1: 0.165686\n",
            "[2800]\ttraining's l1: 0.00619297\tvalid_1's l1: 0.165406\n",
            "[3000]\ttraining's l1: 0.00525413\tvalid_1's l1: 0.165134\n",
            "[3200]\ttraining's l1: 0.00452161\tvalid_1's l1: 0.164956\n",
            "[3400]\ttraining's l1: 0.00397838\tvalid_1's l1: 0.16483\n",
            "[3600]\ttraining's l1: 0.00347776\tvalid_1's l1: 0.164728\n",
            "[3800]\ttraining's l1: 0.00308328\tvalid_1's l1: 0.164614\n",
            "[4000]\ttraining's l1: 0.00273892\tvalid_1's l1: 0.164514\n",
            "[4200]\ttraining's l1: 0.0024808\tvalid_1's l1: 0.164444\n",
            "[4400]\ttraining's l1: 0.00224272\tvalid_1's l1: 0.164374\n",
            "[4600]\ttraining's l1: 0.002038\tvalid_1's l1: 0.164322\n",
            "[4800]\ttraining's l1: 0.00187499\tvalid_1's l1: 0.164273\n",
            "[5000]\ttraining's l1: 0.0017308\tvalid_1's l1: 0.164245\n",
            "[5200]\ttraining's l1: 0.00157873\tvalid_1's l1: 0.164203\n",
            "[5400]\ttraining's l1: 0.00145869\tvalid_1's l1: 0.164171\n",
            "[5600]\ttraining's l1: 0.00135262\tvalid_1's l1: 0.164136\n",
            "[5800]\ttraining's l1: 0.0012581\tvalid_1's l1: 0.16412\n",
            "[6000]\ttraining's l1: 0.00117772\tvalid_1's l1: 0.164104\n",
            "[6200]\ttraining's l1: 0.00110304\tvalid_1's l1: 0.164078\n",
            "[6400]\ttraining's l1: 0.00102552\tvalid_1's l1: 0.164067\n",
            "[6600]\ttraining's l1: 0.00096207\tvalid_1's l1: 0.164047\n",
            "[6800]\ttraining's l1: 0.000902632\tvalid_1's l1: 0.164033\n",
            "[7000]\ttraining's l1: 0.000847879\tvalid_1's l1: 0.164026\n",
            "[7200]\ttraining's l1: 0.000799227\tvalid_1's l1: 0.164016\n",
            "[7400]\ttraining's l1: 0.000747852\tvalid_1's l1: 0.164002\n",
            "[7600]\ttraining's l1: 0.000706896\tvalid_1's l1: 0.163993\n",
            "[7800]\ttraining's l1: 0.000665657\tvalid_1's l1: 0.163983\n",
            "[8000]\ttraining's l1: 0.000630749\tvalid_1's l1: 0.163978\n",
            "[8200]\ttraining's l1: 0.000598286\tvalid_1's l1: 0.163978\n",
            "[8400]\ttraining's l1: 0.000565426\tvalid_1's l1: 0.163971\n",
            "[8600]\ttraining's l1: 0.000534525\tvalid_1's l1: 0.163959\n",
            "[8800]\ttraining's l1: 0.000502535\tvalid_1's l1: 0.163956\n",
            "[9000]\ttraining's l1: 0.000476306\tvalid_1's l1: 0.163948\n",
            "[9200]\ttraining's l1: 0.00045386\tvalid_1's l1: 0.163943\n",
            "[9400]\ttraining's l1: 0.000427741\tvalid_1's l1: 0.163937\n",
            "[9600]\ttraining's l1: 0.000407387\tvalid_1's l1: 0.163936\n",
            "[9800]\ttraining's l1: 0.000386511\tvalid_1's l1: 0.163932\n",
            "[10000]\ttraining's l1: 0.0003677\tvalid_1's l1: 0.163927\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9921]\ttraining's l1: 0.000374216\tvalid_1's l1: 0.163927\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.156493\tvalid_1's l1: 0.217582\n",
            "[400]\ttraining's l1: 0.106175\tvalid_1's l1: 0.20273\n",
            "[600]\ttraining's l1: 0.0749752\tvalid_1's l1: 0.195229\n",
            "[800]\ttraining's l1: 0.0544752\tvalid_1's l1: 0.189117\n",
            "[1000]\ttraining's l1: 0.040454\tvalid_1's l1: 0.185045\n",
            "[1200]\ttraining's l1: 0.0313592\tvalid_1's l1: 0.182511\n",
            "[1400]\ttraining's l1: 0.024627\tvalid_1's l1: 0.180461\n",
            "[1600]\ttraining's l1: 0.0191898\tvalid_1's l1: 0.178434\n",
            "[1800]\ttraining's l1: 0.0152686\tvalid_1's l1: 0.177361\n",
            "[2000]\ttraining's l1: 0.0123888\tvalid_1's l1: 0.176464\n",
            "[2200]\ttraining's l1: 0.0102153\tvalid_1's l1: 0.175858\n",
            "[2400]\ttraining's l1: 0.00854389\tvalid_1's l1: 0.175281\n",
            "[2600]\ttraining's l1: 0.00714872\tvalid_1's l1: 0.174868\n",
            "[2800]\ttraining's l1: 0.00611519\tvalid_1's l1: 0.174587\n",
            "[3000]\ttraining's l1: 0.0051845\tvalid_1's l1: 0.174357\n",
            "[3200]\ttraining's l1: 0.00454171\tvalid_1's l1: 0.174231\n",
            "[3400]\ttraining's l1: 0.00399061\tvalid_1's l1: 0.17415\n",
            "[3600]\ttraining's l1: 0.00352632\tvalid_1's l1: 0.174064\n",
            "[3800]\ttraining's l1: 0.00312924\tvalid_1's l1: 0.173968\n",
            "[4000]\ttraining's l1: 0.00281939\tvalid_1's l1: 0.173909\n",
            "[4200]\ttraining's l1: 0.00251209\tvalid_1's l1: 0.173844\n",
            "[4400]\ttraining's l1: 0.00228206\tvalid_1's l1: 0.173827\n",
            "[4600]\ttraining's l1: 0.0020807\tvalid_1's l1: 0.173795\n",
            "[4800]\ttraining's l1: 0.00188316\tvalid_1's l1: 0.173756\n",
            "[5000]\ttraining's l1: 0.00172713\tvalid_1's l1: 0.173732\n",
            "[5200]\ttraining's l1: 0.00160724\tvalid_1's l1: 0.173722\n",
            "[5400]\ttraining's l1: 0.00147828\tvalid_1's l1: 0.173706\n",
            "[5600]\ttraining's l1: 0.00136007\tvalid_1's l1: 0.173674\n",
            "[5800]\ttraining's l1: 0.00126071\tvalid_1's l1: 0.173669\n",
            "[6000]\ttraining's l1: 0.00116775\tvalid_1's l1: 0.173656\n",
            "[6200]\ttraining's l1: 0.00108655\tvalid_1's l1: 0.173634\n",
            "[6400]\ttraining's l1: 0.00100889\tvalid_1's l1: 0.173621\n",
            "[6600]\ttraining's l1: 0.000941432\tvalid_1's l1: 0.17361\n",
            "[6800]\ttraining's l1: 0.000882487\tvalid_1's l1: 0.173595\n",
            "[7000]\ttraining's l1: 0.000827032\tvalid_1's l1: 0.173598\n",
            "Early stopping, best iteration is:\n",
            "[6819]\ttraining's l1: 0.000878692\tvalid_1's l1: 0.173592\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.153007\tvalid_1's l1: 0.225776\n",
            "[400]\ttraining's l1: 0.102963\tvalid_1's l1: 0.213557\n",
            "[600]\ttraining's l1: 0.074147\tvalid_1's l1: 0.204951\n",
            "[800]\ttraining's l1: 0.0550318\tvalid_1's l1: 0.199743\n",
            "[1000]\ttraining's l1: 0.0415313\tvalid_1's l1: 0.195411\n",
            "[1200]\ttraining's l1: 0.0319814\tvalid_1's l1: 0.191906\n",
            "[1400]\ttraining's l1: 0.0246852\tvalid_1's l1: 0.189559\n",
            "[1600]\ttraining's l1: 0.019839\tvalid_1's l1: 0.18807\n",
            "[1800]\ttraining's l1: 0.0158817\tvalid_1's l1: 0.186853\n",
            "[2000]\ttraining's l1: 0.0128801\tvalid_1's l1: 0.185767\n",
            "[2200]\ttraining's l1: 0.0105148\tvalid_1's l1: 0.18506\n",
            "[2400]\ttraining's l1: 0.00874591\tvalid_1's l1: 0.184623\n",
            "[2600]\ttraining's l1: 0.00729839\tvalid_1's l1: 0.184281\n",
            "[2800]\ttraining's l1: 0.00619953\tvalid_1's l1: 0.184012\n",
            "[3000]\ttraining's l1: 0.00531529\tvalid_1's l1: 0.183862\n",
            "[3200]\ttraining's l1: 0.00455235\tvalid_1's l1: 0.183738\n",
            "[3400]\ttraining's l1: 0.0040277\tvalid_1's l1: 0.183628\n",
            "[3600]\ttraining's l1: 0.003582\tvalid_1's l1: 0.183553\n",
            "[3800]\ttraining's l1: 0.00319351\tvalid_1's l1: 0.183494\n",
            "[4000]\ttraining's l1: 0.00288625\tvalid_1's l1: 0.183446\n",
            "[4200]\ttraining's l1: 0.00262917\tvalid_1's l1: 0.183402\n",
            "[4400]\ttraining's l1: 0.00236735\tvalid_1's l1: 0.183373\n",
            "[4600]\ttraining's l1: 0.00215579\tvalid_1's l1: 0.18337\n",
            "Early stopping, best iteration is:\n",
            "[4530]\ttraining's l1: 0.00222059\tvalid_1's l1: 0.183356\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.155608\tvalid_1's l1: 0.231427\n",
            "[400]\ttraining's l1: 0.103341\tvalid_1's l1: 0.217781\n",
            "[600]\ttraining's l1: 0.0747729\tvalid_1's l1: 0.20933\n",
            "[800]\ttraining's l1: 0.0546469\tvalid_1's l1: 0.202802\n",
            "[1000]\ttraining's l1: 0.0410052\tvalid_1's l1: 0.198093\n",
            "[1200]\ttraining's l1: 0.0312442\tvalid_1's l1: 0.194889\n",
            "[1400]\ttraining's l1: 0.0243167\tvalid_1's l1: 0.19259\n",
            "[1600]\ttraining's l1: 0.0190261\tvalid_1's l1: 0.190912\n",
            "[1800]\ttraining's l1: 0.0153954\tvalid_1's l1: 0.189736\n",
            "[2000]\ttraining's l1: 0.0123978\tvalid_1's l1: 0.188934\n",
            "[2200]\ttraining's l1: 0.0103834\tvalid_1's l1: 0.188412\n",
            "[2400]\ttraining's l1: 0.00860152\tvalid_1's l1: 0.188057\n",
            "[2600]\ttraining's l1: 0.00723845\tvalid_1's l1: 0.187793\n",
            "[2800]\ttraining's l1: 0.00621831\tvalid_1's l1: 0.187537\n",
            "[3000]\ttraining's l1: 0.00537671\tvalid_1's l1: 0.187354\n",
            "[3200]\ttraining's l1: 0.00472485\tvalid_1's l1: 0.187227\n",
            "[3400]\ttraining's l1: 0.00418338\tvalid_1's l1: 0.187148\n",
            "[3600]\ttraining's l1: 0.00371255\tvalid_1's l1: 0.187005\n",
            "[3800]\ttraining's l1: 0.00329089\tvalid_1's l1: 0.186933\n",
            "[4000]\ttraining's l1: 0.00301169\tvalid_1's l1: 0.186887\n",
            "[4200]\ttraining's l1: 0.00270928\tvalid_1's l1: 0.186822\n",
            "[4400]\ttraining's l1: 0.00246394\tvalid_1's l1: 0.186751\n",
            "[4600]\ttraining's l1: 0.00225112\tvalid_1's l1: 0.18673\n",
            "[4800]\ttraining's l1: 0.00207436\tvalid_1's l1: 0.186679\n",
            "[5000]\ttraining's l1: 0.00192374\tvalid_1's l1: 0.186655\n",
            "Early stopping, best iteration is:\n",
            "[4966]\ttraining's l1: 0.00194281\tvalid_1's l1: 0.186652\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.157808\tvalid_1's l1: 0.219275\n",
            "[400]\ttraining's l1: 0.106596\tvalid_1's l1: 0.206165\n",
            "[600]\ttraining's l1: 0.0768451\tvalid_1's l1: 0.197085\n",
            "[800]\ttraining's l1: 0.0571782\tvalid_1's l1: 0.191306\n",
            "[1000]\ttraining's l1: 0.0427427\tvalid_1's l1: 0.186331\n",
            "[1200]\ttraining's l1: 0.0329632\tvalid_1's l1: 0.1835\n",
            "[1400]\ttraining's l1: 0.0255983\tvalid_1's l1: 0.180738\n",
            "[1600]\ttraining's l1: 0.0197434\tvalid_1's l1: 0.178672\n",
            "[1800]\ttraining's l1: 0.0156503\tvalid_1's l1: 0.177431\n",
            "[2000]\ttraining's l1: 0.0126192\tvalid_1's l1: 0.176568\n",
            "[2200]\ttraining's l1: 0.0105119\tvalid_1's l1: 0.175913\n",
            "[2400]\ttraining's l1: 0.00879241\tvalid_1's l1: 0.175436\n",
            "[2600]\ttraining's l1: 0.00744245\tvalid_1's l1: 0.175104\n",
            "[2800]\ttraining's l1: 0.00630772\tvalid_1's l1: 0.174836\n",
            "[3000]\ttraining's l1: 0.00550088\tvalid_1's l1: 0.174624\n",
            "[3200]\ttraining's l1: 0.00474882\tvalid_1's l1: 0.174524\n",
            "[3400]\ttraining's l1: 0.00415084\tvalid_1's l1: 0.174379\n",
            "[3600]\ttraining's l1: 0.00368611\tvalid_1's l1: 0.174317\n",
            "[3800]\ttraining's l1: 0.00330926\tvalid_1's l1: 0.174253\n",
            "[4000]\ttraining's l1: 0.00297227\tvalid_1's l1: 0.174178\n",
            "[4200]\ttraining's l1: 0.00269323\tvalid_1's l1: 0.174119\n",
            "[4400]\ttraining's l1: 0.00243764\tvalid_1's l1: 0.174075\n",
            "[4600]\ttraining's l1: 0.00221031\tvalid_1's l1: 0.174031\n",
            "[4800]\ttraining's l1: 0.00204382\tvalid_1's l1: 0.174007\n",
            "[5000]\ttraining's l1: 0.0018872\tvalid_1's l1: 0.173986\n",
            "[5200]\ttraining's l1: 0.00175626\tvalid_1's l1: 0.173984\n",
            "Early stopping, best iteration is:\n",
            "[5030]\ttraining's l1: 0.00186697\tvalid_1's l1: 0.173979\n",
            "\n",
            "✅ CV MAE: 0.17630\n",
            "✅ submission_upgrade.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수 + Target Encoding\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 없습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 수치형 컬럼 (연산에 필요한 모든 컬럼 포함)\n",
        "    num_cols = [\"age\",\"height\",\"weight\",\"cholesterol\",\"systolic_blood_pressure\",\n",
        "                \"diastolic_blood_pressure\",\"glucose\",\"bone_density\",\"activity\",\n",
        "                \"sleep_pattern\",\"mean_working\"]\n",
        "\n",
        "    # 숫자형으로 변환\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\")\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # 파생 변수 생성\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "        df[\"activity_sleep\"] = df[\"activity\"] * df[\"sleep_pattern\"]\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / df[\"weight\"]\n",
        "        df[\"chol_glu_ratio\"] = df[\"cholesterol\"] / (df[\"glucose\"] + 1e-6)  # 0 나누기 방지\n",
        "\n",
        "    # 범주형 컬럼 추출\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    # Target Encoding\n",
        "    for col in cat_cols:\n",
        "        mapping = train.groupby(col)[target_col].mean()\n",
        "        train[col+\"_TE\"] = train[col].map(mapping)\n",
        "        test[col+\"_TE\"]  = test[col].map(mapping)\n",
        "\n",
        "    cat_cols_TE = [c+\"_TE\" for c in cat_cols]\n",
        "\n",
        "    # Label Encoding\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "        le.fit(combined)\n",
        "        train[col+\"_LE\"] = le.transform(train[col].astype(str))\n",
        "        test[col+\"_LE\"]  = le.transform(test[col].astype(str))\n",
        "    cat_cols_LE = [c+\"_LE\" for c in cat_cols]\n",
        "\n",
        "    # 로그 변환: 왜곡 큰 컬럼\n",
        "    for col in [\"cholesterol\",\"glucose\",\"bone_density\",\"mean_working\"]:\n",
        "        for df in [train, test]:\n",
        "            df[col] = np.log1p(df[col])\n",
        "\n",
        "    # 최종 feature 선택\n",
        "    features = num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\",\"chol_glu_ratio\"] + cat_cols_TE + cat_cols_LE\n",
        "    X = train[features]\n",
        "    y = train[target_col]\n",
        "    test_final = test[features]\n",
        "\n",
        "    return X, y, test_final, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측 (LightGBM + ExtraTrees 앙상블)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=10, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds_lgb = np.zeros(len(test))\n",
        "    test_preds_et = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        model_lgb = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=200)]\n",
        "        )\n",
        "        oof_preds[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n",
        "        test_preds_lgb += model_lgb.predict(test, num_iteration=model_lgb.best_iteration) / n_splits\n",
        "\n",
        "        # ExtraTreesRegressor\n",
        "        model_et = ExtraTreesRegressor(n_estimators=500, max_depth=12, random_state=seed)\n",
        "        model_et.fit(X_train, y_train)\n",
        "        test_preds_et += model_et.predict(test) / n_splits\n",
        "\n",
        "    # 앙상블\n",
        "    test_preds = (test_preds_lgb + test_preds_et) / 2\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_ensemble_final.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_ensemble_final.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_hXLX8r5uS8",
        "outputId": "f601b70a-0aaf-441b-fd4d-b91dcd0f3e2c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.155412\tvalid_1's l1: 0.211364\n",
            "[400]\ttraining's l1: 0.103708\tvalid_1's l1: 0.195744\n",
            "[600]\ttraining's l1: 0.0746017\tvalid_1's l1: 0.186451\n",
            "[800]\ttraining's l1: 0.0526738\tvalid_1's l1: 0.180136\n",
            "[1000]\ttraining's l1: 0.0390904\tvalid_1's l1: 0.176093\n",
            "[1200]\ttraining's l1: 0.0303305\tvalid_1's l1: 0.172754\n",
            "[1400]\ttraining's l1: 0.0234532\tvalid_1's l1: 0.170489\n",
            "[1600]\ttraining's l1: 0.0182659\tvalid_1's l1: 0.168841\n",
            "[1800]\ttraining's l1: 0.0143555\tvalid_1's l1: 0.167394\n",
            "[2000]\ttraining's l1: 0.0113838\tvalid_1's l1: 0.166371\n",
            "[2200]\ttraining's l1: 0.00925963\tvalid_1's l1: 0.165827\n",
            "[2400]\ttraining's l1: 0.00761224\tvalid_1's l1: 0.165347\n",
            "[2600]\ttraining's l1: 0.00637102\tvalid_1's l1: 0.164986\n",
            "[2800]\ttraining's l1: 0.00540573\tvalid_1's l1: 0.164725\n",
            "[3000]\ttraining's l1: 0.00458162\tvalid_1's l1: 0.16447\n",
            "[3200]\ttraining's l1: 0.00394885\tvalid_1's l1: 0.164272\n",
            "[3400]\ttraining's l1: 0.00344586\tvalid_1's l1: 0.164167\n",
            "[3600]\ttraining's l1: 0.00298836\tvalid_1's l1: 0.164061\n",
            "[3800]\ttraining's l1: 0.00263411\tvalid_1's l1: 0.163973\n",
            "[4000]\ttraining's l1: 0.00234292\tvalid_1's l1: 0.163913\n",
            "[4200]\ttraining's l1: 0.00209328\tvalid_1's l1: 0.163868\n",
            "[4400]\ttraining's l1: 0.00187466\tvalid_1's l1: 0.16382\n",
            "[4600]\ttraining's l1: 0.00169032\tvalid_1's l1: 0.16378\n",
            "[4800]\ttraining's l1: 0.00154186\tvalid_1's l1: 0.163745\n",
            "[5000]\ttraining's l1: 0.00141104\tvalid_1's l1: 0.163722\n",
            "[5200]\ttraining's l1: 0.00128717\tvalid_1's l1: 0.163708\n",
            "[5400]\ttraining's l1: 0.00117999\tvalid_1's l1: 0.163682\n",
            "[5600]\ttraining's l1: 0.00109273\tvalid_1's l1: 0.16366\n",
            "[5800]\ttraining's l1: 0.00101572\tvalid_1's l1: 0.163639\n",
            "[6000]\ttraining's l1: 0.000944768\tvalid_1's l1: 0.163637\n",
            "[6200]\ttraining's l1: 0.00087942\tvalid_1's l1: 0.163614\n",
            "[6400]\ttraining's l1: 0.00081753\tvalid_1's l1: 0.163599\n",
            "[6600]\ttraining's l1: 0.00075742\tvalid_1's l1: 0.163591\n",
            "[6800]\ttraining's l1: 0.000705481\tvalid_1's l1: 0.163577\n",
            "[7000]\ttraining's l1: 0.000659855\tvalid_1's l1: 0.163568\n",
            "[7200]\ttraining's l1: 0.00061582\tvalid_1's l1: 0.16356\n",
            "[7400]\ttraining's l1: 0.000578788\tvalid_1's l1: 0.163554\n",
            "[7600]\ttraining's l1: 0.000541514\tvalid_1's l1: 0.163548\n",
            "[7800]\ttraining's l1: 0.000507852\tvalid_1's l1: 0.163547\n",
            "[8000]\ttraining's l1: 0.000480177\tvalid_1's l1: 0.163546\n",
            "[8200]\ttraining's l1: 0.000451993\tvalid_1's l1: 0.163544\n",
            "[8400]\ttraining's l1: 0.000425041\tvalid_1's l1: 0.16354\n",
            "[8600]\ttraining's l1: 0.00040079\tvalid_1's l1: 0.163533\n",
            "[8800]\ttraining's l1: 0.000375677\tvalid_1's l1: 0.163524\n",
            "[9000]\ttraining's l1: 0.000352997\tvalid_1's l1: 0.16352\n",
            "[9200]\ttraining's l1: 0.00033299\tvalid_1's l1: 0.163518\n",
            "[9400]\ttraining's l1: 0.000314746\tvalid_1's l1: 0.163516\n",
            "[9600]\ttraining's l1: 0.000297737\tvalid_1's l1: 0.16351\n",
            "[9800]\ttraining's l1: 0.000279803\tvalid_1's l1: 0.163511\n",
            "[10000]\ttraining's l1: 0.000265404\tvalid_1's l1: 0.163507\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9965]\ttraining's l1: 0.000267603\tvalid_1's l1: 0.163505\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.154213\tvalid_1's l1: 0.216031\n",
            "[400]\ttraining's l1: 0.101027\tvalid_1's l1: 0.20212\n",
            "[600]\ttraining's l1: 0.0711038\tvalid_1's l1: 0.194983\n",
            "[800]\ttraining's l1: 0.0512875\tvalid_1's l1: 0.18902\n",
            "[1000]\ttraining's l1: 0.0381352\tvalid_1's l1: 0.185178\n",
            "[1200]\ttraining's l1: 0.0286261\tvalid_1's l1: 0.182454\n",
            "[1400]\ttraining's l1: 0.0220441\tvalid_1's l1: 0.180531\n",
            "[1600]\ttraining's l1: 0.0171909\tvalid_1's l1: 0.178965\n",
            "[1800]\ttraining's l1: 0.0135035\tvalid_1's l1: 0.177791\n",
            "[2000]\ttraining's l1: 0.0109088\tvalid_1's l1: 0.17689\n",
            "[2200]\ttraining's l1: 0.00890093\tvalid_1's l1: 0.176287\n",
            "[2400]\ttraining's l1: 0.0073809\tvalid_1's l1: 0.175836\n",
            "[2600]\ttraining's l1: 0.00628423\tvalid_1's l1: 0.175529\n",
            "[2800]\ttraining's l1: 0.00534484\tvalid_1's l1: 0.175335\n",
            "[3000]\ttraining's l1: 0.00454245\tvalid_1's l1: 0.175165\n",
            "[3200]\ttraining's l1: 0.00397072\tvalid_1's l1: 0.175047\n",
            "[3400]\ttraining's l1: 0.00344225\tvalid_1's l1: 0.174923\n",
            "[3600]\ttraining's l1: 0.00305364\tvalid_1's l1: 0.174829\n",
            "[3800]\ttraining's l1: 0.0026995\tvalid_1's l1: 0.174731\n",
            "[4000]\ttraining's l1: 0.00241953\tvalid_1's l1: 0.174672\n",
            "[4200]\ttraining's l1: 0.00216\tvalid_1's l1: 0.174613\n",
            "[4400]\ttraining's l1: 0.00195354\tvalid_1's l1: 0.174568\n",
            "[4600]\ttraining's l1: 0.00176064\tvalid_1's l1: 0.17452\n",
            "[4800]\ttraining's l1: 0.00160346\tvalid_1's l1: 0.174491\n",
            "[5000]\ttraining's l1: 0.0014617\tvalid_1's l1: 0.174465\n",
            "[5200]\ttraining's l1: 0.00134328\tvalid_1's l1: 0.174451\n",
            "[5400]\ttraining's l1: 0.00122946\tvalid_1's l1: 0.174434\n",
            "[5600]\ttraining's l1: 0.00112219\tvalid_1's l1: 0.17442\n",
            "[5800]\ttraining's l1: 0.00103435\tvalid_1's l1: 0.174407\n",
            "[6000]\ttraining's l1: 0.000957965\tvalid_1's l1: 0.174392\n",
            "[6200]\ttraining's l1: 0.000884907\tvalid_1's l1: 0.174379\n",
            "[6400]\ttraining's l1: 0.000823632\tvalid_1's l1: 0.174367\n",
            "[6600]\ttraining's l1: 0.000769454\tvalid_1's l1: 0.174368\n",
            "Early stopping, best iteration is:\n",
            "[6431]\ttraining's l1: 0.000817191\tvalid_1's l1: 0.174363\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.153408\tvalid_1's l1: 0.224984\n",
            "[400]\ttraining's l1: 0.101356\tvalid_1's l1: 0.211279\n",
            "[600]\ttraining's l1: 0.0722254\tvalid_1's l1: 0.204205\n",
            "[800]\ttraining's l1: 0.0531058\tvalid_1's l1: 0.199018\n",
            "[1000]\ttraining's l1: 0.039907\tvalid_1's l1: 0.194726\n",
            "[1200]\ttraining's l1: 0.0302298\tvalid_1's l1: 0.191666\n",
            "[1400]\ttraining's l1: 0.0227752\tvalid_1's l1: 0.189218\n",
            "[1600]\ttraining's l1: 0.0181121\tvalid_1's l1: 0.187506\n",
            "[1800]\ttraining's l1: 0.0140488\tvalid_1's l1: 0.185999\n",
            "[2000]\ttraining's l1: 0.0114233\tvalid_1's l1: 0.185146\n",
            "[2200]\ttraining's l1: 0.00916517\tvalid_1's l1: 0.184378\n",
            "[2400]\ttraining's l1: 0.00748538\tvalid_1's l1: 0.183872\n",
            "[2600]\ttraining's l1: 0.00620199\tvalid_1's l1: 0.183552\n",
            "[2800]\ttraining's l1: 0.00524393\tvalid_1's l1: 0.183274\n",
            "[3000]\ttraining's l1: 0.00450866\tvalid_1's l1: 0.183155\n",
            "[3200]\ttraining's l1: 0.0039168\tvalid_1's l1: 0.183046\n",
            "[3400]\ttraining's l1: 0.00345338\tvalid_1's l1: 0.182946\n",
            "[3600]\ttraining's l1: 0.0030693\tvalid_1's l1: 0.18286\n",
            "[3800]\ttraining's l1: 0.00273533\tvalid_1's l1: 0.182821\n",
            "[4000]\ttraining's l1: 0.00244728\tvalid_1's l1: 0.182786\n",
            "[4200]\ttraining's l1: 0.00220962\tvalid_1's l1: 0.182712\n",
            "[4400]\ttraining's l1: 0.00199753\tvalid_1's l1: 0.182684\n",
            "[4600]\ttraining's l1: 0.00181326\tvalid_1's l1: 0.182642\n",
            "[4800]\ttraining's l1: 0.00166341\tvalid_1's l1: 0.182615\n",
            "Early stopping, best iteration is:\n",
            "[4757]\ttraining's l1: 0.00169276\tvalid_1's l1: 0.182613\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.150453\tvalid_1's l1: 0.231117\n",
            "[400]\ttraining's l1: 0.100077\tvalid_1's l1: 0.218183\n",
            "[600]\ttraining's l1: 0.0708241\tvalid_1's l1: 0.208823\n",
            "[800]\ttraining's l1: 0.0509002\tvalid_1's l1: 0.201827\n",
            "[1000]\ttraining's l1: 0.037553\tvalid_1's l1: 0.197911\n",
            "[1200]\ttraining's l1: 0.0285113\tvalid_1's l1: 0.195189\n",
            "[1400]\ttraining's l1: 0.0219887\tvalid_1's l1: 0.192773\n",
            "[1600]\ttraining's l1: 0.0173033\tvalid_1's l1: 0.191287\n",
            "[1800]\ttraining's l1: 0.0138142\tvalid_1's l1: 0.190104\n",
            "[2000]\ttraining's l1: 0.011174\tvalid_1's l1: 0.189251\n",
            "[2200]\ttraining's l1: 0.00914449\tvalid_1's l1: 0.188481\n",
            "[2400]\ttraining's l1: 0.00763279\tvalid_1's l1: 0.187998\n",
            "[2600]\ttraining's l1: 0.00640175\tvalid_1's l1: 0.187706\n",
            "[2800]\ttraining's l1: 0.00538154\tvalid_1's l1: 0.187458\n",
            "[3000]\ttraining's l1: 0.00464431\tvalid_1's l1: 0.187342\n",
            "[3200]\ttraining's l1: 0.00405725\tvalid_1's l1: 0.187202\n",
            "[3400]\ttraining's l1: 0.00356006\tvalid_1's l1: 0.187129\n",
            "[3600]\ttraining's l1: 0.00316561\tvalid_1's l1: 0.187076\n",
            "[3800]\ttraining's l1: 0.00281636\tvalid_1's l1: 0.187025\n",
            "[4000]\ttraining's l1: 0.00252012\tvalid_1's l1: 0.187012\n",
            "[4200]\ttraining's l1: 0.00226998\tvalid_1's l1: 0.186977\n",
            "[4400]\ttraining's l1: 0.00206459\tvalid_1's l1: 0.18694\n",
            "[4600]\ttraining's l1: 0.00188471\tvalid_1's l1: 0.186928\n",
            "[4800]\ttraining's l1: 0.0017175\tvalid_1's l1: 0.186902\n",
            "[5000]\ttraining's l1: 0.00159148\tvalid_1's l1: 0.186891\n",
            "[5200]\ttraining's l1: 0.00146973\tvalid_1's l1: 0.186867\n",
            "[5400]\ttraining's l1: 0.00135485\tvalid_1's l1: 0.186849\n",
            "[5600]\ttraining's l1: 0.00125321\tvalid_1's l1: 0.186835\n",
            "[5800]\ttraining's l1: 0.00115461\tvalid_1's l1: 0.186821\n",
            "[6000]\ttraining's l1: 0.00107698\tvalid_1's l1: 0.186818\n",
            "[6200]\ttraining's l1: 0.00100389\tvalid_1's l1: 0.186796\n",
            "[6400]\ttraining's l1: 0.000928905\tvalid_1's l1: 0.186784\n",
            "[6600]\ttraining's l1: 0.000869559\tvalid_1's l1: 0.186771\n",
            "[6800]\ttraining's l1: 0.000815727\tvalid_1's l1: 0.18678\n",
            "Early stopping, best iteration is:\n",
            "[6633]\ttraining's l1: 0.000860586\tvalid_1's l1: 0.18677\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.153716\tvalid_1's l1: 0.220069\n",
            "[400]\ttraining's l1: 0.102743\tvalid_1's l1: 0.207118\n",
            "[600]\ttraining's l1: 0.0731934\tvalid_1's l1: 0.19828\n",
            "[800]\ttraining's l1: 0.0542002\tvalid_1's l1: 0.191991\n",
            "[1000]\ttraining's l1: 0.0400795\tvalid_1's l1: 0.187465\n",
            "[1200]\ttraining's l1: 0.0300132\tvalid_1's l1: 0.183791\n",
            "[1400]\ttraining's l1: 0.0229107\tvalid_1's l1: 0.181309\n",
            "[1600]\ttraining's l1: 0.0178362\tvalid_1's l1: 0.179569\n",
            "[1800]\ttraining's l1: 0.0140884\tvalid_1's l1: 0.178287\n",
            "[2000]\ttraining's l1: 0.0112537\tvalid_1's l1: 0.177346\n",
            "[2200]\ttraining's l1: 0.00922125\tvalid_1's l1: 0.176753\n",
            "[2400]\ttraining's l1: 0.00775072\tvalid_1's l1: 0.176363\n",
            "[2600]\ttraining's l1: 0.00646943\tvalid_1's l1: 0.175927\n",
            "[2800]\ttraining's l1: 0.0054823\tvalid_1's l1: 0.17574\n",
            "[3000]\ttraining's l1: 0.00469644\tvalid_1's l1: 0.175582\n",
            "[3200]\ttraining's l1: 0.00405974\tvalid_1's l1: 0.175398\n",
            "[3400]\ttraining's l1: 0.00355035\tvalid_1's l1: 0.17527\n",
            "[3600]\ttraining's l1: 0.00309494\tvalid_1's l1: 0.175149\n",
            "[3800]\ttraining's l1: 0.00274535\tvalid_1's l1: 0.175114\n",
            "[4000]\ttraining's l1: 0.00244927\tvalid_1's l1: 0.175038\n",
            "[4200]\ttraining's l1: 0.0022012\tvalid_1's l1: 0.174999\n",
            "[4400]\ttraining's l1: 0.00195883\tvalid_1's l1: 0.174937\n",
            "[4600]\ttraining's l1: 0.00177202\tvalid_1's l1: 0.174901\n",
            "[4800]\ttraining's l1: 0.00162506\tvalid_1's l1: 0.174881\n",
            "[5000]\ttraining's l1: 0.00147393\tvalid_1's l1: 0.174862\n",
            "[5200]\ttraining's l1: 0.0013667\tvalid_1's l1: 0.174849\n",
            "[5400]\ttraining's l1: 0.0012545\tvalid_1's l1: 0.174832\n",
            "[5600]\ttraining's l1: 0.00115626\tvalid_1's l1: 0.174824\n",
            "[5800]\ttraining's l1: 0.00107307\tvalid_1's l1: 0.174809\n",
            "[6000]\ttraining's l1: 0.000986647\tvalid_1's l1: 0.174808\n",
            "[6200]\ttraining's l1: 0.000911924\tvalid_1's l1: 0.174787\n",
            "[6400]\ttraining's l1: 0.000849092\tvalid_1's l1: 0.174786\n",
            "[6600]\ttraining's l1: 0.000791338\tvalid_1's l1: 0.174774\n",
            "[6800]\ttraining's l1: 0.000735917\tvalid_1's l1: 0.174769\n",
            "[7000]\ttraining's l1: 0.000689204\tvalid_1's l1: 0.174766\n",
            "[7200]\ttraining's l1: 0.000643255\tvalid_1's l1: 0.174763\n",
            "[7400]\ttraining's l1: 0.000603257\tvalid_1's l1: 0.174756\n",
            "Early stopping, best iteration is:\n",
            "[7298]\ttraining's l1: 0.000622684\tvalid_1's l1: 0.174755\n",
            "\n",
            "✅ CV MAE: 0.17640\n",
            "✅ submission_ensemble_final.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수 + Target Encoding\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 없습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 수치형 컬럼 안전 변환 (문자열 → 숫자)\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\")\n",
        "\n",
        "    # 파생 변수 생성\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "        df[\"activity_sleep\"] = pd.to_numeric(df[\"activity\"], errors=\"coerce\") * pd.to_numeric(df[\"sleep_pattern\"], errors=\"coerce\")\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / df[\"weight\"]\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"]:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # 범주형 Target Encoding\n",
        "    for col in cat_cols:\n",
        "        mapping = train.groupby(col)[target_col].mean()\n",
        "        train[col+\"_TE\"] = train[col].map(mapping)\n",
        "        test[col+\"_TE\"]  = test[col].map(mapping)\n",
        "    cat_cols_TE = [c+\"_TE\" for c in cat_cols]\n",
        "\n",
        "    # Label Encoding\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "        le.fit(combined)\n",
        "        train[col+\"_LE\"] = le.transform(train[col].astype(str))\n",
        "        test[col+\"_LE\"]  = le.transform(test[col].astype(str))\n",
        "    cat_cols_LE = [c+\"_LE\" for c in cat_cols]\n",
        "\n",
        "    # 로그 변환: 왜곡이 큰 컬럼\n",
        "    for col in [\"cholesterol\",\"glucose\",\"bone_density\",\"mean_working\"]:\n",
        "        for df in [train, test]:\n",
        "            df[col] = np.log1p(df[col])\n",
        "\n",
        "    # 최종 feature 선택\n",
        "    features = num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"] + cat_cols_TE + cat_cols_LE\n",
        "    X = train[features]\n",
        "    y = train[target_col]\n",
        "    test_final = test[features]\n",
        "\n",
        "    return X, y, test_final, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측 (10-Fold, LightGBM + ExtraTrees 앙상블)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=10, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds_lgb = np.zeros(len(test))\n",
        "    test_preds_et = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        model_lgb = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=200)]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n",
        "        test_preds_lgb += model_lgb.predict(test, num_iteration=model_lgb.best_iteration) / n_splits\n",
        "\n",
        "        # ExtraTreesRegressor\n",
        "        model_et = ExtraTreesRegressor(n_estimators=500, max_depth=12, random_state=seed)\n",
        "        model_et.fit(X_train, y_train)\n",
        "        test_preds_et += model_et.predict(test) / n_splits\n",
        "\n",
        "    # 앙상블: LightGBM + ExtraTrees\n",
        "    test_preds = (test_preds_lgb + test_preds_et) / 2\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.5f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_ensemble8.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_ensemble8.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=10, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opdarX0k5uQE",
        "outputId": "57aedc35-2b68-4e2c-8469-bac6e3a6c63a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.152771\tvalid_1's l1: 0.203118\n",
            "[400]\ttraining's l1: 0.101963\tvalid_1's l1: 0.187286\n",
            "[600]\ttraining's l1: 0.0694408\tvalid_1's l1: 0.177144\n",
            "[800]\ttraining's l1: 0.0499546\tvalid_1's l1: 0.170418\n",
            "[1000]\ttraining's l1: 0.0372989\tvalid_1's l1: 0.166627\n",
            "[1200]\ttraining's l1: 0.0280691\tvalid_1's l1: 0.164153\n",
            "[1400]\ttraining's l1: 0.0217255\tvalid_1's l1: 0.161834\n",
            "[1600]\ttraining's l1: 0.0169799\tvalid_1's l1: 0.160142\n",
            "[1800]\ttraining's l1: 0.013388\tvalid_1's l1: 0.158779\n",
            "[2000]\ttraining's l1: 0.0109113\tvalid_1's l1: 0.157655\n",
            "[2200]\ttraining's l1: 0.00905093\tvalid_1's l1: 0.15699\n",
            "[2400]\ttraining's l1: 0.0074581\tvalid_1's l1: 0.156617\n",
            "[2600]\ttraining's l1: 0.0063024\tvalid_1's l1: 0.156172\n",
            "[2800]\ttraining's l1: 0.00532688\tvalid_1's l1: 0.155911\n",
            "[3000]\ttraining's l1: 0.00461257\tvalid_1's l1: 0.155705\n",
            "[3200]\ttraining's l1: 0.00406532\tvalid_1's l1: 0.155573\n",
            "[3400]\ttraining's l1: 0.00356789\tvalid_1's l1: 0.155536\n",
            "[3600]\ttraining's l1: 0.00318669\tvalid_1's l1: 0.155447\n",
            "[3800]\ttraining's l1: 0.00283905\tvalid_1's l1: 0.155402\n",
            "[4000]\ttraining's l1: 0.00253289\tvalid_1's l1: 0.1553\n",
            "[4200]\ttraining's l1: 0.00227611\tvalid_1's l1: 0.155233\n",
            "[4400]\ttraining's l1: 0.00208988\tvalid_1's l1: 0.155189\n",
            "[4600]\ttraining's l1: 0.00190828\tvalid_1's l1: 0.155172\n",
            "[4800]\ttraining's l1: 0.00174333\tvalid_1's l1: 0.155137\n",
            "[5000]\ttraining's l1: 0.00158956\tvalid_1's l1: 0.15512\n",
            "[5200]\ttraining's l1: 0.00146773\tvalid_1's l1: 0.155097\n",
            "[5400]\ttraining's l1: 0.0013622\tvalid_1's l1: 0.155098\n",
            "[5600]\ttraining's l1: 0.00126104\tvalid_1's l1: 0.15507\n",
            "[5800]\ttraining's l1: 0.00117393\tvalid_1's l1: 0.155051\n",
            "[6000]\ttraining's l1: 0.00108678\tvalid_1's l1: 0.155047\n",
            "Early stopping, best iteration is:\n",
            "[5920]\ttraining's l1: 0.00112151\tvalid_1's l1: 0.15504\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.15686\tvalid_1's l1: 0.220314\n",
            "[400]\ttraining's l1: 0.102332\tvalid_1's l1: 0.200214\n",
            "[600]\ttraining's l1: 0.0720946\tvalid_1's l1: 0.187539\n",
            "[800]\ttraining's l1: 0.0522512\tvalid_1's l1: 0.177953\n",
            "[1000]\ttraining's l1: 0.0389738\tvalid_1's l1: 0.171224\n",
            "[1200]\ttraining's l1: 0.0295961\tvalid_1's l1: 0.165878\n",
            "[1400]\ttraining's l1: 0.0228178\tvalid_1's l1: 0.162555\n",
            "[1600]\ttraining's l1: 0.0176714\tvalid_1's l1: 0.160128\n",
            "[1800]\ttraining's l1: 0.0142798\tvalid_1's l1: 0.15856\n",
            "[2000]\ttraining's l1: 0.0114415\tvalid_1's l1: 0.157203\n",
            "[2200]\ttraining's l1: 0.00944912\tvalid_1's l1: 0.156308\n",
            "[2400]\ttraining's l1: 0.00779282\tvalid_1's l1: 0.155509\n",
            "[2600]\ttraining's l1: 0.00652535\tvalid_1's l1: 0.15497\n",
            "[2800]\ttraining's l1: 0.0055694\tvalid_1's l1: 0.154567\n",
            "[3000]\ttraining's l1: 0.00474781\tvalid_1's l1: 0.154193\n",
            "[3200]\ttraining's l1: 0.00414675\tvalid_1's l1: 0.154003\n",
            "[3400]\ttraining's l1: 0.00366305\tvalid_1's l1: 0.153801\n",
            "[3600]\ttraining's l1: 0.00322862\tvalid_1's l1: 0.153647\n",
            "[3800]\ttraining's l1: 0.00286929\tvalid_1's l1: 0.153548\n",
            "[4000]\ttraining's l1: 0.00257792\tvalid_1's l1: 0.153478\n",
            "[4200]\ttraining's l1: 0.00233485\tvalid_1's l1: 0.153423\n",
            "[4400]\ttraining's l1: 0.00211673\tvalid_1's l1: 0.153348\n",
            "[4600]\ttraining's l1: 0.00192564\tvalid_1's l1: 0.153313\n",
            "[4800]\ttraining's l1: 0.00176993\tvalid_1's l1: 0.153272\n",
            "[5000]\ttraining's l1: 0.00163627\tvalid_1's l1: 0.153226\n",
            "[5200]\ttraining's l1: 0.00150006\tvalid_1's l1: 0.153201\n",
            "[5400]\ttraining's l1: 0.00138017\tvalid_1's l1: 0.153176\n",
            "[5600]\ttraining's l1: 0.00128516\tvalid_1's l1: 0.153151\n",
            "[5800]\ttraining's l1: 0.00119863\tvalid_1's l1: 0.153159\n",
            "Early stopping, best iteration is:\n",
            "[5616]\ttraining's l1: 0.00128038\tvalid_1's l1: 0.153145\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.154583\tvalid_1's l1: 0.208809\n",
            "[400]\ttraining's l1: 0.104479\tvalid_1's l1: 0.189972\n",
            "[600]\ttraining's l1: 0.0740458\tvalid_1's l1: 0.180496\n",
            "[800]\ttraining's l1: 0.0528141\tvalid_1's l1: 0.173668\n",
            "[1000]\ttraining's l1: 0.0387938\tvalid_1's l1: 0.168246\n",
            "[1200]\ttraining's l1: 0.0293499\tvalid_1's l1: 0.164912\n",
            "[1400]\ttraining's l1: 0.0225868\tvalid_1's l1: 0.16217\n",
            "[1600]\ttraining's l1: 0.0179805\tvalid_1's l1: 0.160158\n",
            "[1800]\ttraining's l1: 0.0143361\tvalid_1's l1: 0.15857\n",
            "[2000]\ttraining's l1: 0.0116034\tvalid_1's l1: 0.157688\n",
            "[2200]\ttraining's l1: 0.00950332\tvalid_1's l1: 0.156938\n",
            "[2400]\ttraining's l1: 0.00789124\tvalid_1's l1: 0.156491\n",
            "[2600]\ttraining's l1: 0.00670191\tvalid_1's l1: 0.156173\n",
            "[2800]\ttraining's l1: 0.00574427\tvalid_1's l1: 0.15585\n",
            "[3000]\ttraining's l1: 0.00498857\tvalid_1's l1: 0.15563\n",
            "[3200]\ttraining's l1: 0.0043378\tvalid_1's l1: 0.155494\n",
            "[3400]\ttraining's l1: 0.00376133\tvalid_1's l1: 0.155395\n",
            "[3600]\ttraining's l1: 0.00336972\tvalid_1's l1: 0.155271\n",
            "[3800]\ttraining's l1: 0.00304909\tvalid_1's l1: 0.155175\n",
            "[4000]\ttraining's l1: 0.00277305\tvalid_1's l1: 0.155123\n",
            "[4200]\ttraining's l1: 0.00249968\tvalid_1's l1: 0.155079\n",
            "[4400]\ttraining's l1: 0.00226105\tvalid_1's l1: 0.155042\n",
            "[4600]\ttraining's l1: 0.00208268\tvalid_1's l1: 0.155012\n",
            "[4800]\ttraining's l1: 0.00190822\tvalid_1's l1: 0.154998\n",
            "[5000]\ttraining's l1: 0.00175486\tvalid_1's l1: 0.154986\n",
            "[5200]\ttraining's l1: 0.00162068\tvalid_1's l1: 0.154953\n",
            "[5400]\ttraining's l1: 0.00149488\tvalid_1's l1: 0.154952\n",
            "[5600]\ttraining's l1: 0.00139237\tvalid_1's l1: 0.154941\n",
            "[5800]\ttraining's l1: 0.00131129\tvalid_1's l1: 0.154924\n",
            "[6000]\ttraining's l1: 0.00122751\tvalid_1's l1: 0.154914\n",
            "[6200]\ttraining's l1: 0.00114794\tvalid_1's l1: 0.154903\n",
            "[6400]\ttraining's l1: 0.00107747\tvalid_1's l1: 0.154889\n",
            "[6600]\ttraining's l1: 0.0010088\tvalid_1's l1: 0.154888\n",
            "Early stopping, best iteration is:\n",
            "[6542]\ttraining's l1: 0.0010272\tvalid_1's l1: 0.154883\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.159712\tvalid_1's l1: 0.221778\n",
            "[400]\ttraining's l1: 0.105616\tvalid_1's l1: 0.207746\n",
            "[600]\ttraining's l1: 0.0737083\tvalid_1's l1: 0.197416\n",
            "[800]\ttraining's l1: 0.0526354\tvalid_1's l1: 0.191669\n",
            "[1000]\ttraining's l1: 0.0382907\tvalid_1's l1: 0.18707\n",
            "[1200]\ttraining's l1: 0.0290479\tvalid_1's l1: 0.183744\n",
            "[1400]\ttraining's l1: 0.0224688\tvalid_1's l1: 0.18106\n",
            "[1600]\ttraining's l1: 0.017566\tvalid_1's l1: 0.178924\n",
            "[1800]\ttraining's l1: 0.013922\tvalid_1's l1: 0.177506\n",
            "[2000]\ttraining's l1: 0.0112676\tvalid_1's l1: 0.176448\n",
            "[2200]\ttraining's l1: 0.00938753\tvalid_1's l1: 0.175664\n",
            "[2400]\ttraining's l1: 0.00788402\tvalid_1's l1: 0.175081\n",
            "[2600]\ttraining's l1: 0.00659486\tvalid_1's l1: 0.174537\n",
            "[2800]\ttraining's l1: 0.00558945\tvalid_1's l1: 0.17421\n",
            "[3000]\ttraining's l1: 0.0048605\tvalid_1's l1: 0.17397\n",
            "[3200]\ttraining's l1: 0.00430545\tvalid_1's l1: 0.173839\n",
            "[3400]\ttraining's l1: 0.00381417\tvalid_1's l1: 0.173731\n",
            "[3600]\ttraining's l1: 0.00345003\tvalid_1's l1: 0.173607\n",
            "[3800]\ttraining's l1: 0.00309768\tvalid_1's l1: 0.173487\n",
            "[4000]\ttraining's l1: 0.00279444\tvalid_1's l1: 0.173399\n",
            "[4200]\ttraining's l1: 0.00254731\tvalid_1's l1: 0.173355\n",
            "[4400]\ttraining's l1: 0.00232579\tvalid_1's l1: 0.1733\n",
            "[4600]\ttraining's l1: 0.00212455\tvalid_1's l1: 0.1733\n",
            "[4800]\ttraining's l1: 0.00194533\tvalid_1's l1: 0.173248\n",
            "[5000]\ttraining's l1: 0.00179217\tvalid_1's l1: 0.173213\n",
            "[5200]\ttraining's l1: 0.00164535\tvalid_1's l1: 0.173191\n",
            "[5400]\ttraining's l1: 0.00151442\tvalid_1's l1: 0.173161\n",
            "[5600]\ttraining's l1: 0.00140683\tvalid_1's l1: 0.173143\n",
            "[5800]\ttraining's l1: 0.00130875\tvalid_1's l1: 0.173123\n",
            "[6000]\ttraining's l1: 0.00122101\tvalid_1's l1: 0.173089\n",
            "[6200]\ttraining's l1: 0.0011406\tvalid_1's l1: 0.17307\n",
            "[6400]\ttraining's l1: 0.00106378\tvalid_1's l1: 0.173049\n",
            "[6600]\ttraining's l1: 0.000999173\tvalid_1's l1: 0.173038\n",
            "[6800]\ttraining's l1: 0.000936855\tvalid_1's l1: 0.173039\n",
            "Early stopping, best iteration is:\n",
            "[6668]\ttraining's l1: 0.00097983\tvalid_1's l1: 0.173032\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.154511\tvalid_1's l1: 0.225\n",
            "[400]\ttraining's l1: 0.103566\tvalid_1's l1: 0.211253\n",
            "[600]\ttraining's l1: 0.0727618\tvalid_1's l1: 0.202475\n",
            "[800]\ttraining's l1: 0.0527381\tvalid_1's l1: 0.19599\n",
            "[1000]\ttraining's l1: 0.0390944\tvalid_1's l1: 0.190872\n",
            "[1200]\ttraining's l1: 0.0289592\tvalid_1's l1: 0.186366\n",
            "[1400]\ttraining's l1: 0.0221762\tvalid_1's l1: 0.183608\n",
            "[1600]\ttraining's l1: 0.0173978\tvalid_1's l1: 0.181342\n",
            "[1800]\ttraining's l1: 0.0137764\tvalid_1's l1: 0.179788\n",
            "[2000]\ttraining's l1: 0.0111129\tvalid_1's l1: 0.178875\n",
            "[2200]\ttraining's l1: 0.00916222\tvalid_1's l1: 0.178144\n",
            "[2400]\ttraining's l1: 0.00778638\tvalid_1's l1: 0.177625\n",
            "[2600]\ttraining's l1: 0.00655081\tvalid_1's l1: 0.177294\n",
            "[2800]\ttraining's l1: 0.00558805\tvalid_1's l1: 0.177068\n",
            "[3000]\ttraining's l1: 0.0047966\tvalid_1's l1: 0.176832\n",
            "[3200]\ttraining's l1: 0.00418585\tvalid_1's l1: 0.176759\n",
            "[3400]\ttraining's l1: 0.00370892\tvalid_1's l1: 0.176685\n",
            "[3600]\ttraining's l1: 0.00327151\tvalid_1's l1: 0.176608\n",
            "[3800]\ttraining's l1: 0.00291824\tvalid_1's l1: 0.176565\n",
            "[4000]\ttraining's l1: 0.00262241\tvalid_1's l1: 0.176491\n",
            "[4200]\ttraining's l1: 0.00239134\tvalid_1's l1: 0.17646\n",
            "[4400]\ttraining's l1: 0.00218307\tvalid_1's l1: 0.176408\n",
            "[4600]\ttraining's l1: 0.00196934\tvalid_1's l1: 0.176367\n",
            "[4800]\ttraining's l1: 0.00181348\tvalid_1's l1: 0.176347\n",
            "[5000]\ttraining's l1: 0.00166581\tvalid_1's l1: 0.176339\n",
            "[5200]\ttraining's l1: 0.00154322\tvalid_1's l1: 0.176323\n",
            "[5400]\ttraining's l1: 0.00143756\tvalid_1's l1: 0.176297\n",
            "[5600]\ttraining's l1: 0.00133204\tvalid_1's l1: 0.176277\n",
            "[5800]\ttraining's l1: 0.00124676\tvalid_1's l1: 0.176278\n",
            "[6000]\ttraining's l1: 0.00116011\tvalid_1's l1: 0.17626\n",
            "[6200]\ttraining's l1: 0.00109259\tvalid_1's l1: 0.176242\n",
            "[6400]\ttraining's l1: 0.00101994\tvalid_1's l1: 0.176247\n",
            "Early stopping, best iteration is:\n",
            "[6376]\ttraining's l1: 0.00102889\tvalid_1's l1: 0.176241\n",
            "\n",
            "===== Fold 6 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.151216\tvalid_1's l1: 0.225015\n",
            "[400]\ttraining's l1: 0.104848\tvalid_1's l1: 0.20714\n",
            "[600]\ttraining's l1: 0.0749178\tvalid_1's l1: 0.19271\n",
            "[800]\ttraining's l1: 0.0534435\tvalid_1's l1: 0.182752\n",
            "[1000]\ttraining's l1: 0.0393269\tvalid_1's l1: 0.175282\n",
            "[1200]\ttraining's l1: 0.0297593\tvalid_1's l1: 0.170777\n",
            "[1400]\ttraining's l1: 0.0227659\tvalid_1's l1: 0.168052\n",
            "[1600]\ttraining's l1: 0.0179935\tvalid_1's l1: 0.165888\n",
            "[1800]\ttraining's l1: 0.0142443\tvalid_1's l1: 0.164034\n",
            "[2000]\ttraining's l1: 0.011392\tvalid_1's l1: 0.16309\n",
            "[2200]\ttraining's l1: 0.0093015\tvalid_1's l1: 0.162234\n",
            "[2400]\ttraining's l1: 0.00771049\tvalid_1's l1: 0.161451\n",
            "[2600]\ttraining's l1: 0.00651845\tvalid_1's l1: 0.161103\n",
            "[2800]\ttraining's l1: 0.00544476\tvalid_1's l1: 0.160885\n",
            "[3000]\ttraining's l1: 0.00467023\tvalid_1's l1: 0.160649\n",
            "[3200]\ttraining's l1: 0.00406776\tvalid_1's l1: 0.160517\n",
            "[3400]\ttraining's l1: 0.00356219\tvalid_1's l1: 0.16039\n",
            "[3600]\ttraining's l1: 0.00313617\tvalid_1's l1: 0.160263\n",
            "[3800]\ttraining's l1: 0.00279593\tvalid_1's l1: 0.160185\n",
            "[4000]\ttraining's l1: 0.00249773\tvalid_1's l1: 0.160102\n",
            "[4200]\ttraining's l1: 0.00225378\tvalid_1's l1: 0.160068\n",
            "[4400]\ttraining's l1: 0.00204226\tvalid_1's l1: 0.160045\n",
            "[4600]\ttraining's l1: 0.00186327\tvalid_1's l1: 0.159996\n",
            "[4800]\ttraining's l1: 0.00171076\tvalid_1's l1: 0.159982\n",
            "[5000]\ttraining's l1: 0.00157587\tvalid_1's l1: 0.159947\n",
            "[5200]\ttraining's l1: 0.00145534\tvalid_1's l1: 0.159921\n",
            "[5400]\ttraining's l1: 0.00134277\tvalid_1's l1: 0.159923\n",
            "Early stopping, best iteration is:\n",
            "[5252]\ttraining's l1: 0.00142734\tvalid_1's l1: 0.159915\n",
            "\n",
            "===== Fold 7 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.154733\tvalid_1's l1: 0.229487\n",
            "[400]\ttraining's l1: 0.104327\tvalid_1's l1: 0.215651\n",
            "[600]\ttraining's l1: 0.0752561\tvalid_1's l1: 0.204487\n",
            "[800]\ttraining's l1: 0.0554791\tvalid_1's l1: 0.196428\n",
            "[1000]\ttraining's l1: 0.0401928\tvalid_1's l1: 0.189139\n",
            "[1200]\ttraining's l1: 0.0303808\tvalid_1's l1: 0.18448\n",
            "[1400]\ttraining's l1: 0.0231457\tvalid_1's l1: 0.180614\n",
            "[1600]\ttraining's l1: 0.0183766\tvalid_1's l1: 0.17812\n",
            "[1800]\ttraining's l1: 0.0145025\tvalid_1's l1: 0.176062\n",
            "[2000]\ttraining's l1: 0.0116887\tvalid_1's l1: 0.174766\n",
            "[2200]\ttraining's l1: 0.00954097\tvalid_1's l1: 0.173503\n",
            "[2400]\ttraining's l1: 0.0079069\tvalid_1's l1: 0.172836\n",
            "[2600]\ttraining's l1: 0.00672338\tvalid_1's l1: 0.172246\n",
            "[2800]\ttraining's l1: 0.00577141\tvalid_1's l1: 0.171867\n",
            "[3000]\ttraining's l1: 0.00494033\tvalid_1's l1: 0.171552\n",
            "[3200]\ttraining's l1: 0.00427376\tvalid_1's l1: 0.171292\n",
            "[3400]\ttraining's l1: 0.003729\tvalid_1's l1: 0.171098\n",
            "[3600]\ttraining's l1: 0.00331161\tvalid_1's l1: 0.170912\n",
            "[3800]\ttraining's l1: 0.00295962\tvalid_1's l1: 0.170767\n",
            "[4000]\ttraining's l1: 0.00266413\tvalid_1's l1: 0.170686\n",
            "[4200]\ttraining's l1: 0.00240927\tvalid_1's l1: 0.170614\n",
            "[4400]\ttraining's l1: 0.00219899\tvalid_1's l1: 0.170549\n",
            "[4600]\ttraining's l1: 0.00199956\tvalid_1's l1: 0.170487\n",
            "[4800]\ttraining's l1: 0.00183722\tvalid_1's l1: 0.170431\n",
            "[5000]\ttraining's l1: 0.00168382\tvalid_1's l1: 0.170367\n",
            "[5200]\ttraining's l1: 0.0015402\tvalid_1's l1: 0.17034\n",
            "[5400]\ttraining's l1: 0.00142446\tvalid_1's l1: 0.170315\n",
            "[5600]\ttraining's l1: 0.00131328\tvalid_1's l1: 0.170289\n",
            "[5800]\ttraining's l1: 0.00122472\tvalid_1's l1: 0.170259\n",
            "[6000]\ttraining's l1: 0.00114801\tvalid_1's l1: 0.170244\n",
            "[6200]\ttraining's l1: 0.00106823\tvalid_1's l1: 0.170224\n",
            "[6400]\ttraining's l1: 0.000994685\tvalid_1's l1: 0.170213\n",
            "[6600]\ttraining's l1: 0.000931024\tvalid_1's l1: 0.170198\n",
            "[6800]\ttraining's l1: 0.000875076\tvalid_1's l1: 0.170185\n",
            "[7000]\ttraining's l1: 0.000823143\tvalid_1's l1: 0.170168\n",
            "[7200]\ttraining's l1: 0.000775626\tvalid_1's l1: 0.170155\n",
            "Early stopping, best iteration is:\n",
            "[7191]\ttraining's l1: 0.000777424\tvalid_1's l1: 0.170152\n",
            "\n",
            "===== Fold 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.152665\tvalid_1's l1: 0.225763\n",
            "[400]\ttraining's l1: 0.104156\tvalid_1's l1: 0.211704\n",
            "[600]\ttraining's l1: 0.0710107\tvalid_1's l1: 0.200545\n",
            "[800]\ttraining's l1: 0.0517315\tvalid_1's l1: 0.19414\n",
            "[1000]\ttraining's l1: 0.0383674\tvalid_1's l1: 0.188994\n",
            "[1200]\ttraining's l1: 0.0285906\tvalid_1's l1: 0.184945\n",
            "[1400]\ttraining's l1: 0.0223067\tvalid_1's l1: 0.182186\n",
            "[1600]\ttraining's l1: 0.0172159\tvalid_1's l1: 0.180156\n",
            "[1800]\ttraining's l1: 0.0136149\tvalid_1's l1: 0.178456\n",
            "[2000]\ttraining's l1: 0.0112343\tvalid_1's l1: 0.177515\n",
            "[2200]\ttraining's l1: 0.00937898\tvalid_1's l1: 0.176718\n",
            "[2400]\ttraining's l1: 0.00786733\tvalid_1's l1: 0.176124\n",
            "[2600]\ttraining's l1: 0.00671264\tvalid_1's l1: 0.175701\n",
            "[2800]\ttraining's l1: 0.00576158\tvalid_1's l1: 0.175402\n",
            "[3000]\ttraining's l1: 0.00501561\tvalid_1's l1: 0.175112\n",
            "[3200]\ttraining's l1: 0.00445707\tvalid_1's l1: 0.175013\n",
            "[3400]\ttraining's l1: 0.00395747\tvalid_1's l1: 0.174841\n",
            "[3600]\ttraining's l1: 0.00355527\tvalid_1's l1: 0.174769\n",
            "[3800]\ttraining's l1: 0.0032002\tvalid_1's l1: 0.174687\n",
            "[4000]\ttraining's l1: 0.00287773\tvalid_1's l1: 0.174624\n",
            "[4200]\ttraining's l1: 0.00261406\tvalid_1's l1: 0.174576\n",
            "[4400]\ttraining's l1: 0.00238455\tvalid_1's l1: 0.174543\n",
            "[4600]\ttraining's l1: 0.00220468\tvalid_1's l1: 0.174492\n",
            "[4800]\ttraining's l1: 0.00204712\tvalid_1's l1: 0.174465\n",
            "[5000]\ttraining's l1: 0.00189292\tvalid_1's l1: 0.174427\n",
            "[5200]\ttraining's l1: 0.00174655\tvalid_1's l1: 0.174417\n",
            "[5400]\ttraining's l1: 0.00161597\tvalid_1's l1: 0.17439\n",
            "[5600]\ttraining's l1: 0.001504\tvalid_1's l1: 0.17438\n",
            "[5800]\ttraining's l1: 0.00140965\tvalid_1's l1: 0.174371\n",
            "[6000]\ttraining's l1: 0.00131667\tvalid_1's l1: 0.174355\n",
            "Early stopping, best iteration is:\n",
            "[5904]\ttraining's l1: 0.00135848\tvalid_1's l1: 0.174352\n",
            "\n",
            "===== Fold 9 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.149099\tvalid_1's l1: 0.217328\n",
            "[400]\ttraining's l1: 0.10404\tvalid_1's l1: 0.204303\n",
            "[600]\ttraining's l1: 0.072054\tvalid_1's l1: 0.192499\n",
            "[800]\ttraining's l1: 0.0523053\tvalid_1's l1: 0.184735\n",
            "[1000]\ttraining's l1: 0.0392409\tvalid_1's l1: 0.179299\n",
            "[1200]\ttraining's l1: 0.0299392\tvalid_1's l1: 0.174625\n",
            "[1400]\ttraining's l1: 0.0229803\tvalid_1's l1: 0.171155\n",
            "[1600]\ttraining's l1: 0.0176457\tvalid_1's l1: 0.169142\n",
            "[1800]\ttraining's l1: 0.0142501\tvalid_1's l1: 0.167584\n",
            "[2000]\ttraining's l1: 0.0114352\tvalid_1's l1: 0.166258\n",
            "[2200]\ttraining's l1: 0.00943284\tvalid_1's l1: 0.165604\n",
            "[2400]\ttraining's l1: 0.00791514\tvalid_1's l1: 0.165046\n",
            "[2600]\ttraining's l1: 0.00665312\tvalid_1's l1: 0.164559\n",
            "[2800]\ttraining's l1: 0.0056364\tvalid_1's l1: 0.164228\n",
            "[3000]\ttraining's l1: 0.00483032\tvalid_1's l1: 0.163934\n",
            "[3200]\ttraining's l1: 0.00419345\tvalid_1's l1: 0.163834\n",
            "[3400]\ttraining's l1: 0.00368164\tvalid_1's l1: 0.163715\n",
            "[3600]\ttraining's l1: 0.00324348\tvalid_1's l1: 0.163605\n",
            "[3800]\ttraining's l1: 0.0028882\tvalid_1's l1: 0.163532\n",
            "[4000]\ttraining's l1: 0.00257742\tvalid_1's l1: 0.163477\n",
            "[4200]\ttraining's l1: 0.0023218\tvalid_1's l1: 0.163432\n",
            "[4400]\ttraining's l1: 0.00208628\tvalid_1's l1: 0.163401\n",
            "[4600]\ttraining's l1: 0.00190108\tvalid_1's l1: 0.163352\n",
            "Early stopping, best iteration is:\n",
            "[4585]\ttraining's l1: 0.00191442\tvalid_1's l1: 0.163348\n",
            "\n",
            "===== Fold 10 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.157758\tvalid_1's l1: 0.21847\n",
            "[400]\ttraining's l1: 0.106251\tvalid_1's l1: 0.199926\n",
            "[600]\ttraining's l1: 0.0729908\tvalid_1's l1: 0.189343\n",
            "[800]\ttraining's l1: 0.0517233\tvalid_1's l1: 0.182011\n",
            "[1000]\ttraining's l1: 0.0383623\tvalid_1's l1: 0.17621\n",
            "[1200]\ttraining's l1: 0.0293439\tvalid_1's l1: 0.172639\n",
            "[1400]\ttraining's l1: 0.0223964\tvalid_1's l1: 0.169949\n",
            "[1600]\ttraining's l1: 0.0172524\tvalid_1's l1: 0.167804\n",
            "[1800]\ttraining's l1: 0.0136752\tvalid_1's l1: 0.16639\n",
            "[2000]\ttraining's l1: 0.0111837\tvalid_1's l1: 0.165479\n",
            "[2200]\ttraining's l1: 0.0090776\tvalid_1's l1: 0.164589\n",
            "[2400]\ttraining's l1: 0.00758864\tvalid_1's l1: 0.164122\n",
            "[2600]\ttraining's l1: 0.00640973\tvalid_1's l1: 0.163715\n",
            "[2800]\ttraining's l1: 0.00545705\tvalid_1's l1: 0.163472\n",
            "[3000]\ttraining's l1: 0.00471936\tvalid_1's l1: 0.163243\n",
            "[3200]\ttraining's l1: 0.00408287\tvalid_1's l1: 0.16307\n",
            "[3400]\ttraining's l1: 0.00355735\tvalid_1's l1: 0.16295\n",
            "[3600]\ttraining's l1: 0.00317021\tvalid_1's l1: 0.16285\n",
            "[3800]\ttraining's l1: 0.00281325\tvalid_1's l1: 0.162748\n",
            "[4000]\ttraining's l1: 0.00251802\tvalid_1's l1: 0.162722\n",
            "[4200]\ttraining's l1: 0.00228855\tvalid_1's l1: 0.162687\n",
            "[4400]\ttraining's l1: 0.00206533\tvalid_1's l1: 0.162653\n",
            "[4600]\ttraining's l1: 0.00189486\tvalid_1's l1: 0.162629\n",
            "[4800]\ttraining's l1: 0.00174055\tvalid_1's l1: 0.162597\n",
            "[5000]\ttraining's l1: 0.00160698\tvalid_1's l1: 0.162563\n",
            "[5200]\ttraining's l1: 0.00148227\tvalid_1's l1: 0.162526\n",
            "[5400]\ttraining's l1: 0.0013713\tvalid_1's l1: 0.162523\n",
            "[5600]\ttraining's l1: 0.00127032\tvalid_1's l1: 0.162504\n",
            "[5800]\ttraining's l1: 0.00117896\tvalid_1's l1: 0.162481\n",
            "[6000]\ttraining's l1: 0.00109545\tvalid_1's l1: 0.162461\n",
            "[6200]\ttraining's l1: 0.00101999\tvalid_1's l1: 0.162446\n",
            "[6400]\ttraining's l1: 0.000950753\tvalid_1's l1: 0.162433\n",
            "[6600]\ttraining's l1: 0.000883926\tvalid_1's l1: 0.162424\n",
            "[6800]\ttraining's l1: 0.000829196\tvalid_1's l1: 0.162414\n",
            "[7000]\ttraining's l1: 0.000778884\tvalid_1's l1: 0.162406\n",
            "[7200]\ttraining's l1: 0.000732258\tvalid_1's l1: 0.162401\n",
            "[7400]\ttraining's l1: 0.00069079\tvalid_1's l1: 0.162409\n",
            "Early stopping, best iteration is:\n",
            "[7255]\ttraining's l1: 0.000719169\tvalid_1's l1: 0.162398\n",
            "\n",
            "✅ CV MAE: 0.16425\n",
            "✅ submission_ensemble8.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수 + Target/Label Encoding\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 없습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 컬럼 구분\n",
        "    num_cols = [\"age\",\"height\",\"weight\",\"cholesterol\",\"glucose\",\"bone_density\",\n",
        "                \"systolic_blood_pressure\",\"diastolic_blood_pressure\",\"mean_working\"]\n",
        "\n",
        "    cat_cols = [\"gender\",\"smoke_status\",\"medical_history\",\"family_medical_history\",\n",
        "                \"edu_level\",\"activity\",\"sleep_pattern\"]\n",
        "\n",
        "    # 수치형 변환 및 결측치 처리\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\")\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # 파생 변수\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "        df[\"activity_sleep\"] = pd.to_numeric(df[\"activity\"], errors=\"coerce\") * pd.to_numeric(df.get(\"sleep_pattern_num\", df[\"sleep_pattern\"].astype('category').cat.codes), errors=\"coerce\")\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / df[\"weight\"]\n",
        "\n",
        "    # 범주형 Target Encoding + Label Encoding\n",
        "    for col in cat_cols:\n",
        "        # Target Encoding\n",
        "        mapping = train.groupby(col)[target_col].mean()\n",
        "        train[col+\"_TE\"] = train[col].map(mapping)\n",
        "        test[col+\"_TE\"]  = test[col].map(mapping)\n",
        "\n",
        "        # Label Encoding\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "        le.fit(combined)\n",
        "        train[col+\"_LE\"] = le.transform(train[col].astype(str))\n",
        "        test[col+\"_LE\"]  = le.transform(test[col].astype(str))\n",
        "\n",
        "    # 로그 변환\n",
        "    for col in [\"cholesterol\",\"glucose\",\"bone_density\",\"mean_working\"]:\n",
        "        for df in [train, test]:\n",
        "            df[col] = np.log1p(df[col])\n",
        "\n",
        "    # 최종 feature 선택\n",
        "    features = num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"] + \\\n",
        "               [c+\"_TE\" for c in cat_cols] + [c+\"_LE\" for c in cat_cols]\n",
        "    X = train[features]\n",
        "    y = train[target_col]\n",
        "    test_final = test[features]\n",
        "\n",
        "    return X, y, test_final, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측 (LightGBM + ExtraTrees 앙상블)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=10, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds_lgb = np.zeros(len(test))\n",
        "    test_preds_et = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        model_lgb = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=200)]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n",
        "        test_preds_lgb += model_lgb.predict(test, num_iteration=model_lgb.best_iteration) / n_splits\n",
        "\n",
        "        # ExtraTreesRegressor\n",
        "        model_et = ExtraTreesRegressor(n_estimators=500, max_depth=12, random_state=seed)\n",
        "        model_et.fit(X_train, y_train)\n",
        "        test_preds_et += model_et.predict(test) / n_splits\n",
        "\n",
        "    # 앙상블\n",
        "    test_preds = (test_preds_lgb + test_preds_et) / 2\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_ensemble9.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_ensemble9.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=10, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNQshd7R5uLE",
        "outputId": "fe22983e-a3d3-41b3-fd02-82438fca33e3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.158798\tvalid_1's l1: 0.20073\n",
            "[400]\ttraining's l1: 0.105163\tvalid_1's l1: 0.18469\n",
            "[600]\ttraining's l1: 0.0724455\tvalid_1's l1: 0.176327\n",
            "[800]\ttraining's l1: 0.0530599\tvalid_1's l1: 0.169152\n",
            "[1000]\ttraining's l1: 0.039061\tvalid_1's l1: 0.164864\n",
            "[1200]\ttraining's l1: 0.0290139\tvalid_1's l1: 0.161432\n",
            "[1400]\ttraining's l1: 0.0222019\tvalid_1's l1: 0.159184\n",
            "[1600]\ttraining's l1: 0.0172637\tvalid_1's l1: 0.157477\n",
            "[1800]\ttraining's l1: 0.0136142\tvalid_1's l1: 0.156241\n",
            "[2000]\ttraining's l1: 0.0111878\tvalid_1's l1: 0.155488\n",
            "[2200]\ttraining's l1: 0.00931187\tvalid_1's l1: 0.154964\n",
            "[2400]\ttraining's l1: 0.00765657\tvalid_1's l1: 0.154475\n",
            "[2600]\ttraining's l1: 0.00645422\tvalid_1's l1: 0.154102\n",
            "[2800]\ttraining's l1: 0.00555521\tvalid_1's l1: 0.153794\n",
            "[3000]\ttraining's l1: 0.00480564\tvalid_1's l1: 0.153614\n",
            "[3200]\ttraining's l1: 0.00425523\tvalid_1's l1: 0.153494\n",
            "[3400]\ttraining's l1: 0.00377628\tvalid_1's l1: 0.15343\n",
            "[3600]\ttraining's l1: 0.00332436\tvalid_1's l1: 0.153304\n",
            "[3800]\ttraining's l1: 0.00298474\tvalid_1's l1: 0.15316\n",
            "[4000]\ttraining's l1: 0.00266687\tvalid_1's l1: 0.153096\n",
            "[4200]\ttraining's l1: 0.00239693\tvalid_1's l1: 0.153056\n",
            "[4400]\ttraining's l1: 0.00221049\tvalid_1's l1: 0.153022\n",
            "[4600]\ttraining's l1: 0.00202168\tvalid_1's l1: 0.152982\n",
            "[4800]\ttraining's l1: 0.00184677\tvalid_1's l1: 0.152952\n",
            "[5000]\ttraining's l1: 0.00169451\tvalid_1's l1: 0.152921\n",
            "[5200]\ttraining's l1: 0.00156775\tvalid_1's l1: 0.152903\n",
            "[5400]\ttraining's l1: 0.00145786\tvalid_1's l1: 0.152863\n",
            "[5600]\ttraining's l1: 0.00135703\tvalid_1's l1: 0.152863\n",
            "[5800]\ttraining's l1: 0.00126885\tvalid_1's l1: 0.152828\n",
            "[6000]\ttraining's l1: 0.00118459\tvalid_1's l1: 0.152815\n",
            "[6200]\ttraining's l1: 0.00111169\tvalid_1's l1: 0.152793\n",
            "[6400]\ttraining's l1: 0.00103942\tvalid_1's l1: 0.15279\n",
            "[6600]\ttraining's l1: 0.000977833\tvalid_1's l1: 0.152778\n",
            "[6800]\ttraining's l1: 0.000916962\tvalid_1's l1: 0.152766\n",
            "[7000]\ttraining's l1: 0.00086368\tvalid_1's l1: 0.152756\n",
            "[7200]\ttraining's l1: 0.000804979\tvalid_1's l1: 0.152744\n",
            "[7400]\ttraining's l1: 0.000761081\tvalid_1's l1: 0.152745\n",
            "Early stopping, best iteration is:\n",
            "[7355]\ttraining's l1: 0.000771566\tvalid_1's l1: 0.152739\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.156954\tvalid_1's l1: 0.220287\n",
            "[400]\ttraining's l1: 0.103503\tvalid_1's l1: 0.200063\n",
            "[600]\ttraining's l1: 0.0740287\tvalid_1's l1: 0.189286\n",
            "[800]\ttraining's l1: 0.0535452\tvalid_1's l1: 0.179718\n",
            "[1000]\ttraining's l1: 0.0391338\tvalid_1's l1: 0.172009\n",
            "[1200]\ttraining's l1: 0.0297504\tvalid_1's l1: 0.166942\n",
            "[1400]\ttraining's l1: 0.0228515\tvalid_1's l1: 0.163672\n",
            "[1600]\ttraining's l1: 0.0176005\tvalid_1's l1: 0.160858\n",
            "[1800]\ttraining's l1: 0.013997\tvalid_1's l1: 0.158917\n",
            "[2000]\ttraining's l1: 0.0111002\tvalid_1's l1: 0.15748\n",
            "[2200]\ttraining's l1: 0.00916513\tvalid_1's l1: 0.1567\n",
            "[2400]\ttraining's l1: 0.00759082\tvalid_1's l1: 0.156158\n",
            "[2600]\ttraining's l1: 0.00635086\tvalid_1's l1: 0.155656\n",
            "[2800]\ttraining's l1: 0.00540931\tvalid_1's l1: 0.155283\n",
            "[3000]\ttraining's l1: 0.00460535\tvalid_1's l1: 0.154966\n",
            "[3200]\ttraining's l1: 0.00399623\tvalid_1's l1: 0.154721\n",
            "[3400]\ttraining's l1: 0.00351436\tvalid_1's l1: 0.154555\n",
            "[3600]\ttraining's l1: 0.00310052\tvalid_1's l1: 0.154421\n",
            "[3800]\ttraining's l1: 0.00275485\tvalid_1's l1: 0.154288\n",
            "[4000]\ttraining's l1: 0.00247506\tvalid_1's l1: 0.154182\n",
            "[4200]\ttraining's l1: 0.00225335\tvalid_1's l1: 0.154129\n",
            "[4400]\ttraining's l1: 0.00206363\tvalid_1's l1: 0.154048\n",
            "[4600]\ttraining's l1: 0.00188525\tvalid_1's l1: 0.154025\n",
            "[4800]\ttraining's l1: 0.00173131\tvalid_1's l1: 0.153984\n",
            "[5000]\ttraining's l1: 0.0015931\tvalid_1's l1: 0.153944\n",
            "[5200]\ttraining's l1: 0.00146003\tvalid_1's l1: 0.153921\n",
            "[5400]\ttraining's l1: 0.00134693\tvalid_1's l1: 0.153874\n",
            "[5600]\ttraining's l1: 0.00125926\tvalid_1's l1: 0.153855\n",
            "[5800]\ttraining's l1: 0.00117911\tvalid_1's l1: 0.153837\n",
            "[6000]\ttraining's l1: 0.00110021\tvalid_1's l1: 0.153793\n",
            "[6200]\ttraining's l1: 0.0010217\tvalid_1's l1: 0.153774\n",
            "[6400]\ttraining's l1: 0.000958794\tvalid_1's l1: 0.153752\n",
            "[6600]\ttraining's l1: 0.00090103\tvalid_1's l1: 0.153745\n",
            "Early stopping, best iteration is:\n",
            "[6560]\ttraining's l1: 0.000911948\tvalid_1's l1: 0.153741\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.153334\tvalid_1's l1: 0.210935\n",
            "[400]\ttraining's l1: 0.103277\tvalid_1's l1: 0.191316\n",
            "[600]\ttraining's l1: 0.0724486\tvalid_1's l1: 0.18115\n",
            "[800]\ttraining's l1: 0.052155\tvalid_1's l1: 0.173022\n",
            "[1000]\ttraining's l1: 0.0387764\tvalid_1's l1: 0.167471\n",
            "[1200]\ttraining's l1: 0.0290589\tvalid_1's l1: 0.164024\n",
            "[1400]\ttraining's l1: 0.0223179\tvalid_1's l1: 0.160752\n",
            "[1600]\ttraining's l1: 0.0176386\tvalid_1's l1: 0.158401\n",
            "[1800]\ttraining's l1: 0.0140678\tvalid_1's l1: 0.156883\n",
            "[2000]\ttraining's l1: 0.0112155\tvalid_1's l1: 0.155882\n",
            "[2200]\ttraining's l1: 0.00918982\tvalid_1's l1: 0.155317\n",
            "[2400]\ttraining's l1: 0.00763486\tvalid_1's l1: 0.154884\n",
            "[2600]\ttraining's l1: 0.00643809\tvalid_1's l1: 0.154585\n",
            "[2800]\ttraining's l1: 0.00552008\tvalid_1's l1: 0.154427\n",
            "[3000]\ttraining's l1: 0.00483072\tvalid_1's l1: 0.154279\n",
            "[3200]\ttraining's l1: 0.00419955\tvalid_1's l1: 0.154136\n",
            "[3400]\ttraining's l1: 0.00366081\tvalid_1's l1: 0.154064\n",
            "[3600]\ttraining's l1: 0.00327687\tvalid_1's l1: 0.154011\n",
            "[3800]\ttraining's l1: 0.00296667\tvalid_1's l1: 0.153912\n",
            "[4000]\ttraining's l1: 0.00270697\tvalid_1's l1: 0.153863\n",
            "[4200]\ttraining's l1: 0.00247893\tvalid_1's l1: 0.153868\n",
            "[4400]\ttraining's l1: 0.0022524\tvalid_1's l1: 0.153819\n",
            "[4600]\ttraining's l1: 0.00207477\tvalid_1's l1: 0.153786\n",
            "[4800]\ttraining's l1: 0.00189478\tvalid_1's l1: 0.15375\n",
            "[5000]\ttraining's l1: 0.00174748\tvalid_1's l1: 0.153717\n",
            "[5200]\ttraining's l1: 0.00161907\tvalid_1's l1: 0.153705\n",
            "[5400]\ttraining's l1: 0.00150989\tvalid_1's l1: 0.153691\n",
            "[5600]\ttraining's l1: 0.00140694\tvalid_1's l1: 0.153671\n",
            "[5800]\ttraining's l1: 0.001326\tvalid_1's l1: 0.153665\n",
            "[6000]\ttraining's l1: 0.00123665\tvalid_1's l1: 0.153659\n",
            "[6200]\ttraining's l1: 0.00115926\tvalid_1's l1: 0.153667\n",
            "Early stopping, best iteration is:\n",
            "[6021]\ttraining's l1: 0.00122962\tvalid_1's l1: 0.153648\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.15709\tvalid_1's l1: 0.220585\n",
            "[400]\ttraining's l1: 0.104423\tvalid_1's l1: 0.208034\n",
            "[600]\ttraining's l1: 0.0738246\tvalid_1's l1: 0.199526\n",
            "[800]\ttraining's l1: 0.0538201\tvalid_1's l1: 0.194436\n",
            "[1000]\ttraining's l1: 0.0395536\tvalid_1's l1: 0.189372\n",
            "[1200]\ttraining's l1: 0.0298097\tvalid_1's l1: 0.185978\n",
            "[1400]\ttraining's l1: 0.0227226\tvalid_1's l1: 0.183322\n",
            "[1600]\ttraining's l1: 0.0178589\tvalid_1's l1: 0.181405\n",
            "[1800]\ttraining's l1: 0.0140391\tvalid_1's l1: 0.180101\n",
            "[2000]\ttraining's l1: 0.0112852\tvalid_1's l1: 0.17904\n",
            "[2200]\ttraining's l1: 0.00933571\tvalid_1's l1: 0.178251\n",
            "[2400]\ttraining's l1: 0.0078605\tvalid_1's l1: 0.177658\n",
            "[2600]\ttraining's l1: 0.00666687\tvalid_1's l1: 0.177221\n",
            "[2800]\ttraining's l1: 0.00565823\tvalid_1's l1: 0.176874\n",
            "[3000]\ttraining's l1: 0.00491893\tvalid_1's l1: 0.176648\n",
            "[3200]\ttraining's l1: 0.00438966\tvalid_1's l1: 0.176501\n",
            "[3400]\ttraining's l1: 0.00391443\tvalid_1's l1: 0.176326\n",
            "[3600]\ttraining's l1: 0.0035046\tvalid_1's l1: 0.176168\n",
            "[3800]\ttraining's l1: 0.00316489\tvalid_1's l1: 0.176091\n",
            "[4000]\ttraining's l1: 0.00286422\tvalid_1's l1: 0.176024\n",
            "[4200]\ttraining's l1: 0.00262541\tvalid_1's l1: 0.17596\n",
            "[4400]\ttraining's l1: 0.00237956\tvalid_1's l1: 0.175891\n",
            "[4600]\ttraining's l1: 0.00218765\tvalid_1's l1: 0.175844\n",
            "[4800]\ttraining's l1: 0.00200762\tvalid_1's l1: 0.175794\n",
            "[5000]\ttraining's l1: 0.00184018\tvalid_1's l1: 0.17576\n",
            "[5200]\ttraining's l1: 0.00168348\tvalid_1's l1: 0.175726\n",
            "[5400]\ttraining's l1: 0.00155321\tvalid_1's l1: 0.175705\n",
            "[5600]\ttraining's l1: 0.00144118\tvalid_1's l1: 0.175663\n",
            "[5800]\ttraining's l1: 0.00133483\tvalid_1's l1: 0.175638\n",
            "[6000]\ttraining's l1: 0.00124452\tvalid_1's l1: 0.17561\n",
            "[6200]\ttraining's l1: 0.00115321\tvalid_1's l1: 0.175599\n",
            "[6400]\ttraining's l1: 0.00107961\tvalid_1's l1: 0.175565\n",
            "[6600]\ttraining's l1: 0.00101354\tvalid_1's l1: 0.175553\n",
            "[6800]\ttraining's l1: 0.000952212\tvalid_1's l1: 0.175544\n",
            "[7000]\ttraining's l1: 0.000895075\tvalid_1's l1: 0.175533\n",
            "[7200]\ttraining's l1: 0.000838488\tvalid_1's l1: 0.175518\n",
            "[7400]\ttraining's l1: 0.000789317\tvalid_1's l1: 0.175515\n",
            "[7600]\ttraining's l1: 0.000745943\tvalid_1's l1: 0.175499\n",
            "[7800]\ttraining's l1: 0.000703905\tvalid_1's l1: 0.175485\n",
            "[8000]\ttraining's l1: 0.000662749\tvalid_1's l1: 0.175472\n",
            "[8200]\ttraining's l1: 0.000624328\tvalid_1's l1: 0.175461\n",
            "[8400]\ttraining's l1: 0.000592317\tvalid_1's l1: 0.175456\n",
            "[8600]\ttraining's l1: 0.000555094\tvalid_1's l1: 0.175443\n",
            "[8800]\ttraining's l1: 0.000523166\tvalid_1's l1: 0.175437\n",
            "[9000]\ttraining's l1: 0.000495564\tvalid_1's l1: 0.175429\n",
            "[9200]\ttraining's l1: 0.000468718\tvalid_1's l1: 0.175422\n",
            "[9400]\ttraining's l1: 0.000443222\tvalid_1's l1: 0.175417\n",
            "Early stopping, best iteration is:\n",
            "[9245]\ttraining's l1: 0.000463647\tvalid_1's l1: 0.175416\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.156047\tvalid_1's l1: 0.226397\n",
            "[400]\ttraining's l1: 0.103767\tvalid_1's l1: 0.213334\n",
            "[600]\ttraining's l1: 0.0719584\tvalid_1's l1: 0.204033\n",
            "[800]\ttraining's l1: 0.051606\tvalid_1's l1: 0.195087\n",
            "[1000]\ttraining's l1: 0.0383263\tvalid_1's l1: 0.190879\n",
            "[1200]\ttraining's l1: 0.0284346\tvalid_1's l1: 0.186877\n",
            "[1400]\ttraining's l1: 0.0217027\tvalid_1's l1: 0.18435\n",
            "[1600]\ttraining's l1: 0.0168726\tvalid_1's l1: 0.182446\n",
            "[1800]\ttraining's l1: 0.0133852\tvalid_1's l1: 0.18108\n",
            "[2000]\ttraining's l1: 0.01093\tvalid_1's l1: 0.180049\n",
            "[2200]\ttraining's l1: 0.00900428\tvalid_1's l1: 0.179362\n",
            "[2400]\ttraining's l1: 0.00768154\tvalid_1's l1: 0.17892\n",
            "[2600]\ttraining's l1: 0.00643618\tvalid_1's l1: 0.17853\n",
            "[2800]\ttraining's l1: 0.00548837\tvalid_1's l1: 0.178252\n",
            "[3000]\ttraining's l1: 0.00471302\tvalid_1's l1: 0.178021\n",
            "[3200]\ttraining's l1: 0.00407442\tvalid_1's l1: 0.1778\n",
            "[3400]\ttraining's l1: 0.00361731\tvalid_1's l1: 0.177685\n",
            "[3600]\ttraining's l1: 0.00321617\tvalid_1's l1: 0.177629\n",
            "[3800]\ttraining's l1: 0.00285795\tvalid_1's l1: 0.177591\n",
            "[4000]\ttraining's l1: 0.00255259\tvalid_1's l1: 0.177521\n",
            "[4200]\ttraining's l1: 0.00232127\tvalid_1's l1: 0.177456\n",
            "[4400]\ttraining's l1: 0.00212361\tvalid_1's l1: 0.177414\n",
            "[4600]\ttraining's l1: 0.00194068\tvalid_1's l1: 0.177388\n",
            "[4800]\ttraining's l1: 0.00179314\tvalid_1's l1: 0.177338\n",
            "[5000]\ttraining's l1: 0.00164677\tvalid_1's l1: 0.177315\n",
            "[5200]\ttraining's l1: 0.00152313\tvalid_1's l1: 0.177328\n",
            "Early stopping, best iteration is:\n",
            "[5046]\ttraining's l1: 0.00161143\tvalid_1's l1: 0.17731\n",
            "\n",
            "===== Fold 6 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.150081\tvalid_1's l1: 0.223201\n",
            "[400]\ttraining's l1: 0.103288\tvalid_1's l1: 0.204338\n",
            "[600]\ttraining's l1: 0.0737197\tvalid_1's l1: 0.190237\n",
            "[800]\ttraining's l1: 0.0522813\tvalid_1's l1: 0.180035\n",
            "[1000]\ttraining's l1: 0.0389462\tvalid_1's l1: 0.173083\n",
            "[1200]\ttraining's l1: 0.0300496\tvalid_1's l1: 0.168701\n",
            "[1400]\ttraining's l1: 0.0228001\tvalid_1's l1: 0.165606\n",
            "[1600]\ttraining's l1: 0.0177864\tvalid_1's l1: 0.1632\n",
            "[1800]\ttraining's l1: 0.0138791\tvalid_1's l1: 0.161244\n",
            "[2000]\ttraining's l1: 0.0111159\tvalid_1's l1: 0.159907\n",
            "[2200]\ttraining's l1: 0.00915526\tvalid_1's l1: 0.158988\n",
            "[2400]\ttraining's l1: 0.0076356\tvalid_1's l1: 0.158535\n",
            "[2600]\ttraining's l1: 0.00645577\tvalid_1's l1: 0.158168\n",
            "[2800]\ttraining's l1: 0.00547145\tvalid_1's l1: 0.157879\n",
            "[3000]\ttraining's l1: 0.00468719\tvalid_1's l1: 0.157627\n",
            "[3200]\ttraining's l1: 0.00411405\tvalid_1's l1: 0.157435\n",
            "[3400]\ttraining's l1: 0.00358958\tvalid_1's l1: 0.157275\n",
            "[3600]\ttraining's l1: 0.00316808\tvalid_1's l1: 0.157153\n",
            "[3800]\ttraining's l1: 0.00283091\tvalid_1's l1: 0.157061\n",
            "[4000]\ttraining's l1: 0.0025218\tvalid_1's l1: 0.156983\n",
            "[4200]\ttraining's l1: 0.00227454\tvalid_1's l1: 0.156919\n",
            "[4400]\ttraining's l1: 0.00206355\tvalid_1's l1: 0.156883\n",
            "[4600]\ttraining's l1: 0.00186911\tvalid_1's l1: 0.156848\n",
            "[4800]\ttraining's l1: 0.00170612\tvalid_1's l1: 0.156821\n",
            "[5000]\ttraining's l1: 0.00156773\tvalid_1's l1: 0.156811\n",
            "[5200]\ttraining's l1: 0.00145013\tvalid_1's l1: 0.156775\n",
            "[5400]\ttraining's l1: 0.00134154\tvalid_1's l1: 0.156765\n",
            "[5600]\ttraining's l1: 0.00123927\tvalid_1's l1: 0.156735\n",
            "[5800]\ttraining's l1: 0.00114334\tvalid_1's l1: 0.156713\n",
            "[6000]\ttraining's l1: 0.00106783\tvalid_1's l1: 0.156681\n",
            "[6200]\ttraining's l1: 0.000999726\tvalid_1's l1: 0.156668\n",
            "[6400]\ttraining's l1: 0.000931614\tvalid_1's l1: 0.156655\n",
            "[6600]\ttraining's l1: 0.000869041\tvalid_1's l1: 0.15665\n",
            "[6800]\ttraining's l1: 0.000812728\tvalid_1's l1: 0.156637\n",
            "[7000]\ttraining's l1: 0.000764625\tvalid_1's l1: 0.156636\n",
            "[7200]\ttraining's l1: 0.000717734\tvalid_1's l1: 0.156615\n",
            "[7400]\ttraining's l1: 0.000677675\tvalid_1's l1: 0.156601\n",
            "[7600]\ttraining's l1: 0.000638668\tvalid_1's l1: 0.156599\n",
            "[7800]\ttraining's l1: 0.000602275\tvalid_1's l1: 0.156597\n",
            "[8000]\ttraining's l1: 0.000568974\tvalid_1's l1: 0.156595\n",
            "Early stopping, best iteration is:\n",
            "[7928]\ttraining's l1: 0.000581983\tvalid_1's l1: 0.156591\n",
            "\n",
            "===== Fold 7 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.153519\tvalid_1's l1: 0.229721\n",
            "[400]\ttraining's l1: 0.10309\tvalid_1's l1: 0.214732\n",
            "[600]\ttraining's l1: 0.0733377\tvalid_1's l1: 0.202849\n",
            "[800]\ttraining's l1: 0.054312\tvalid_1's l1: 0.195916\n",
            "[1000]\ttraining's l1: 0.0393864\tvalid_1's l1: 0.188145\n",
            "[1200]\ttraining's l1: 0.029251\tvalid_1's l1: 0.183607\n",
            "[1400]\ttraining's l1: 0.0225399\tvalid_1's l1: 0.180094\n",
            "[1600]\ttraining's l1: 0.0176315\tvalid_1's l1: 0.177744\n",
            "[1800]\ttraining's l1: 0.014223\tvalid_1's l1: 0.175886\n",
            "[2000]\ttraining's l1: 0.0115646\tvalid_1's l1: 0.174467\n",
            "[2200]\ttraining's l1: 0.00956107\tvalid_1's l1: 0.173568\n",
            "[2400]\ttraining's l1: 0.00793011\tvalid_1's l1: 0.172863\n",
            "[2600]\ttraining's l1: 0.00665552\tvalid_1's l1: 0.172206\n",
            "[2800]\ttraining's l1: 0.00566743\tvalid_1's l1: 0.171857\n",
            "[3000]\ttraining's l1: 0.00485356\tvalid_1's l1: 0.171534\n",
            "[3200]\ttraining's l1: 0.00419862\tvalid_1's l1: 0.171379\n",
            "[3400]\ttraining's l1: 0.00367617\tvalid_1's l1: 0.171209\n",
            "[3600]\ttraining's l1: 0.00329642\tvalid_1's l1: 0.171071\n",
            "[3800]\ttraining's l1: 0.00298257\tvalid_1's l1: 0.170981\n",
            "[4000]\ttraining's l1: 0.00268662\tvalid_1's l1: 0.170909\n",
            "[4200]\ttraining's l1: 0.00240793\tvalid_1's l1: 0.170833\n",
            "[4400]\ttraining's l1: 0.00220227\tvalid_1's l1: 0.170782\n",
            "[4600]\ttraining's l1: 0.00200274\tvalid_1's l1: 0.170722\n",
            "[4800]\ttraining's l1: 0.00185281\tvalid_1's l1: 0.17066\n",
            "[5000]\ttraining's l1: 0.00169775\tvalid_1's l1: 0.17065\n",
            "[5200]\ttraining's l1: 0.00156779\tvalid_1's l1: 0.170624\n",
            "[5400]\ttraining's l1: 0.00145649\tvalid_1's l1: 0.170585\n",
            "[5600]\ttraining's l1: 0.00135149\tvalid_1's l1: 0.17057\n",
            "[5800]\ttraining's l1: 0.00126851\tvalid_1's l1: 0.170537\n",
            "[6000]\ttraining's l1: 0.00118273\tvalid_1's l1: 0.170524\n",
            "[6200]\ttraining's l1: 0.00111224\tvalid_1's l1: 0.170514\n",
            "[6400]\ttraining's l1: 0.00104196\tvalid_1's l1: 0.170502\n",
            "[6600]\ttraining's l1: 0.000975719\tvalid_1's l1: 0.170488\n",
            "[6800]\ttraining's l1: 0.000910281\tvalid_1's l1: 0.170474\n",
            "[7000]\ttraining's l1: 0.000863907\tvalid_1's l1: 0.170462\n",
            "Early stopping, best iteration is:\n",
            "[6975]\ttraining's l1: 0.000868772\tvalid_1's l1: 0.17046\n",
            "\n",
            "===== Fold 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.152037\tvalid_1's l1: 0.228975\n",
            "[400]\ttraining's l1: 0.104447\tvalid_1's l1: 0.214725\n",
            "[600]\ttraining's l1: 0.0729177\tvalid_1's l1: 0.204128\n",
            "[800]\ttraining's l1: 0.0529576\tvalid_1's l1: 0.195674\n",
            "[1000]\ttraining's l1: 0.0392052\tvalid_1's l1: 0.189513\n",
            "[1200]\ttraining's l1: 0.0292961\tvalid_1's l1: 0.185733\n",
            "[1400]\ttraining's l1: 0.0228796\tvalid_1's l1: 0.182751\n",
            "[1600]\ttraining's l1: 0.01754\tvalid_1's l1: 0.180354\n",
            "[1800]\ttraining's l1: 0.0139199\tvalid_1's l1: 0.178594\n",
            "[2000]\ttraining's l1: 0.0113835\tvalid_1's l1: 0.177367\n",
            "[2200]\ttraining's l1: 0.00942683\tvalid_1's l1: 0.176702\n",
            "[2400]\ttraining's l1: 0.00785292\tvalid_1's l1: 0.176203\n",
            "[2600]\ttraining's l1: 0.00673546\tvalid_1's l1: 0.17577\n",
            "[2800]\ttraining's l1: 0.00580871\tvalid_1's l1: 0.175341\n",
            "[3000]\ttraining's l1: 0.00496008\tvalid_1's l1: 0.175087\n",
            "[3200]\ttraining's l1: 0.00431906\tvalid_1's l1: 0.174943\n",
            "[3400]\ttraining's l1: 0.00380185\tvalid_1's l1: 0.174766\n",
            "[3600]\ttraining's l1: 0.00338423\tvalid_1's l1: 0.174667\n",
            "[3800]\ttraining's l1: 0.00300401\tvalid_1's l1: 0.174624\n",
            "[4000]\ttraining's l1: 0.00268809\tvalid_1's l1: 0.174571\n",
            "[4200]\ttraining's l1: 0.00241577\tvalid_1's l1: 0.174511\n",
            "[4400]\ttraining's l1: 0.00216176\tvalid_1's l1: 0.174487\n",
            "[4600]\ttraining's l1: 0.00197225\tvalid_1's l1: 0.174426\n",
            "[4800]\ttraining's l1: 0.00181026\tvalid_1's l1: 0.174388\n",
            "[5000]\ttraining's l1: 0.00166364\tvalid_1's l1: 0.174381\n",
            "[5200]\ttraining's l1: 0.0015172\tvalid_1's l1: 0.174361\n",
            "Early stopping, best iteration is:\n",
            "[5192]\ttraining's l1: 0.00152303\tvalid_1's l1: 0.174356\n",
            "\n",
            "===== Fold 9 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.150375\tvalid_1's l1: 0.219836\n",
            "[400]\ttraining's l1: 0.103602\tvalid_1's l1: 0.204548\n",
            "[600]\ttraining's l1: 0.0733062\tvalid_1's l1: 0.193647\n",
            "[800]\ttraining's l1: 0.0531131\tvalid_1's l1: 0.185376\n",
            "[1000]\ttraining's l1: 0.0396126\tvalid_1's l1: 0.178583\n",
            "[1200]\ttraining's l1: 0.0298006\tvalid_1's l1: 0.174593\n",
            "[1400]\ttraining's l1: 0.0229151\tvalid_1's l1: 0.171387\n",
            "[1600]\ttraining's l1: 0.0176257\tvalid_1's l1: 0.168568\n",
            "[1800]\ttraining's l1: 0.0140879\tvalid_1's l1: 0.167229\n",
            "[2000]\ttraining's l1: 0.0114018\tvalid_1's l1: 0.166121\n",
            "[2200]\ttraining's l1: 0.00939017\tvalid_1's l1: 0.165409\n",
            "[2400]\ttraining's l1: 0.00781692\tvalid_1's l1: 0.164749\n",
            "[2600]\ttraining's l1: 0.00649607\tvalid_1's l1: 0.164263\n",
            "[2800]\ttraining's l1: 0.00549376\tvalid_1's l1: 0.163853\n",
            "[3000]\ttraining's l1: 0.0046857\tvalid_1's l1: 0.163568\n",
            "[3200]\ttraining's l1: 0.00407502\tvalid_1's l1: 0.1634\n",
            "[3400]\ttraining's l1: 0.00359586\tvalid_1's l1: 0.163251\n",
            "[3600]\ttraining's l1: 0.00319743\tvalid_1's l1: 0.163168\n",
            "[3800]\ttraining's l1: 0.00284465\tvalid_1's l1: 0.163075\n",
            "[4000]\ttraining's l1: 0.0025774\tvalid_1's l1: 0.163039\n",
            "[4200]\ttraining's l1: 0.00232621\tvalid_1's l1: 0.163007\n",
            "[4400]\ttraining's l1: 0.00210445\tvalid_1's l1: 0.162944\n",
            "[4600]\ttraining's l1: 0.00191783\tvalid_1's l1: 0.162896\n",
            "[4800]\ttraining's l1: 0.00174555\tvalid_1's l1: 0.162881\n",
            "[5000]\ttraining's l1: 0.00162072\tvalid_1's l1: 0.16285\n",
            "[5200]\ttraining's l1: 0.00149399\tvalid_1's l1: 0.162825\n",
            "[5400]\ttraining's l1: 0.00138547\tvalid_1's l1: 0.162808\n",
            "[5600]\ttraining's l1: 0.00128355\tvalid_1's l1: 0.162793\n",
            "[5800]\ttraining's l1: 0.00118919\tvalid_1's l1: 0.162761\n",
            "[6000]\ttraining's l1: 0.00111033\tvalid_1's l1: 0.162768\n",
            "Early stopping, best iteration is:\n",
            "[5822]\ttraining's l1: 0.00118007\tvalid_1's l1: 0.162759\n",
            "\n",
            "===== Fold 10 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.159543\tvalid_1's l1: 0.21887\n",
            "[400]\ttraining's l1: 0.104993\tvalid_1's l1: 0.20196\n",
            "[600]\ttraining's l1: 0.0732298\tvalid_1's l1: 0.191548\n",
            "[800]\ttraining's l1: 0.0519729\tvalid_1's l1: 0.183716\n",
            "[1000]\ttraining's l1: 0.0385014\tvalid_1's l1: 0.17789\n",
            "[1200]\ttraining's l1: 0.0295735\tvalid_1's l1: 0.173884\n",
            "[1400]\ttraining's l1: 0.0223843\tvalid_1's l1: 0.170412\n",
            "[1600]\ttraining's l1: 0.0173328\tvalid_1's l1: 0.168319\n",
            "[1800]\ttraining's l1: 0.0138119\tvalid_1's l1: 0.166921\n",
            "[2000]\ttraining's l1: 0.0111889\tvalid_1's l1: 0.165962\n",
            "[2200]\ttraining's l1: 0.00918663\tvalid_1's l1: 0.16512\n",
            "[2400]\ttraining's l1: 0.00765957\tvalid_1's l1: 0.164528\n",
            "[2600]\ttraining's l1: 0.00652922\tvalid_1's l1: 0.164355\n",
            "[2800]\ttraining's l1: 0.0055902\tvalid_1's l1: 0.164093\n",
            "[3000]\ttraining's l1: 0.00484026\tvalid_1's l1: 0.16382\n",
            "[3200]\ttraining's l1: 0.0041761\tvalid_1's l1: 0.163587\n",
            "[3400]\ttraining's l1: 0.00361757\tvalid_1's l1: 0.163492\n",
            "[3600]\ttraining's l1: 0.00322898\tvalid_1's l1: 0.163398\n",
            "[3800]\ttraining's l1: 0.00284924\tvalid_1's l1: 0.163313\n",
            "[4000]\ttraining's l1: 0.00253851\tvalid_1's l1: 0.163235\n",
            "[4200]\ttraining's l1: 0.00230051\tvalid_1's l1: 0.163197\n",
            "[4400]\ttraining's l1: 0.00207291\tvalid_1's l1: 0.163153\n",
            "Early stopping, best iteration is:\n",
            "[4357]\ttraining's l1: 0.00211831\tvalid_1's l1: 0.16315\n",
            "\n",
            "✅ CV MAE: 0.1640170300\n",
            "✅ submission_ensemble9.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수 + Target Encoding + 안정화\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 없습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 수치형 컬럼으로 강제 변환\n",
        "    for col in num_cols + [\"activity\", \"sleep_pattern\"]:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\")\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols + [\"activity\", \"sleep_pattern\"]:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # 파생 변수 생성\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "        df[\"activity_sleep\"] = df[\"activity\"] * df[\"sleep_pattern\"]\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / df[\"weight\"]\n",
        "\n",
        "    # 결측치 처리 후 파생 변수 NaN 처리\n",
        "    derived_cols = [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"]\n",
        "    for col in derived_cols:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # 범주형 Target Encoding\n",
        "    for col in cat_cols:\n",
        "        mapping = train.groupby(col)[target_col].mean()\n",
        "        train[col+\"_TE\"] = train[col].map(mapping)\n",
        "        test[col+\"_TE\"]  = test[col].map(mapping)\n",
        "\n",
        "    cat_cols_TE = [c+\"_TE\" for c in cat_cols]\n",
        "\n",
        "    # Label Encoding\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "        le.fit(combined)\n",
        "        train[col+\"_LE\"] = le.transform(train[col].astype(str))\n",
        "        test[col+\"_LE\"]  = le.transform(test[col].astype(str))\n",
        "\n",
        "    cat_cols_LE = [c+\"_LE\" for c in cat_cols]\n",
        "\n",
        "    # 로그 변환: 왜곡이 큰 컬럼\n",
        "    for col in [\"cholesterol\",\"glucose\",\"bone_density\",\"mean_working\"]:\n",
        "        for df in [train, test]:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "            df[col] = df[col].fillna(df[col].mean())\n",
        "            df[col] = np.log1p(df[col])\n",
        "\n",
        "    # 최종 feature 선택\n",
        "    features = num_cols + derived_cols + cat_cols_TE + cat_cols_LE\n",
        "    X = train[features]\n",
        "    y = train[target_col]\n",
        "    test_final = test[features]\n",
        "\n",
        "    return X, y, test_final, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측 (LightGBM + ExtraTrees 앙상블)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds_lgb = np.zeros(len(test))\n",
        "    test_preds_et  = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        model_lgb = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=200)]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n",
        "        test_preds_lgb += model_lgb.predict(test, num_iteration=model_lgb.best_iteration) / n_splits\n",
        "\n",
        "        # ExtraTreesRegressor\n",
        "        model_et = ExtraTreesRegressor(n_estimators=500, max_depth=12, random_state=seed)\n",
        "        model_et.fit(X_train, y_train)\n",
        "        test_preds_et += model_et.predict(test) / n_splits\n",
        "\n",
        "    # 앙상블\n",
        "    test_preds = (test_preds_lgb + test_preds_et) / 2\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_stable10.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_stable10.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqWwq3P75uDV",
        "outputId": "d19bccc6-fc36-4cb5-ef09-b47b2ad3946e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.157243\tvalid_1's l1: 0.212996\n",
            "[400]\ttraining's l1: 0.109731\tvalid_1's l1: 0.197115\n",
            "[600]\ttraining's l1: 0.0786692\tvalid_1's l1: 0.187444\n",
            "[800]\ttraining's l1: 0.0562663\tvalid_1's l1: 0.180902\n",
            "[1000]\ttraining's l1: 0.0422886\tvalid_1's l1: 0.175927\n",
            "[1200]\ttraining's l1: 0.032645\tvalid_1's l1: 0.172817\n",
            "[1400]\ttraining's l1: 0.0252244\tvalid_1's l1: 0.169915\n",
            "[1600]\ttraining's l1: 0.0200686\tvalid_1's l1: 0.168218\n",
            "[1800]\ttraining's l1: 0.0159076\tvalid_1's l1: 0.166862\n",
            "[2000]\ttraining's l1: 0.0126134\tvalid_1's l1: 0.165923\n",
            "[2200]\ttraining's l1: 0.0102109\tvalid_1's l1: 0.165199\n",
            "[2400]\ttraining's l1: 0.0083976\tvalid_1's l1: 0.164583\n",
            "[2600]\ttraining's l1: 0.00698515\tvalid_1's l1: 0.164157\n",
            "[2800]\ttraining's l1: 0.00590525\tvalid_1's l1: 0.16394\n",
            "[3000]\ttraining's l1: 0.00506106\tvalid_1's l1: 0.16373\n",
            "[3200]\ttraining's l1: 0.0043926\tvalid_1's l1: 0.16355\n",
            "[3400]\ttraining's l1: 0.00385469\tvalid_1's l1: 0.163425\n",
            "[3600]\ttraining's l1: 0.00338757\tvalid_1's l1: 0.163343\n",
            "[3800]\ttraining's l1: 0.00298664\tvalid_1's l1: 0.163261\n",
            "[4000]\ttraining's l1: 0.00267472\tvalid_1's l1: 0.163208\n",
            "[4200]\ttraining's l1: 0.00239848\tvalid_1's l1: 0.163169\n",
            "[4400]\ttraining's l1: 0.00218292\tvalid_1's l1: 0.163137\n",
            "[4600]\ttraining's l1: 0.00198214\tvalid_1's l1: 0.163092\n",
            "[4800]\ttraining's l1: 0.00181352\tvalid_1's l1: 0.163059\n",
            "[5000]\ttraining's l1: 0.00166571\tvalid_1's l1: 0.163031\n",
            "[5200]\ttraining's l1: 0.00153003\tvalid_1's l1: 0.163\n",
            "[5400]\ttraining's l1: 0.00141479\tvalid_1's l1: 0.162996\n",
            "[5600]\ttraining's l1: 0.00131046\tvalid_1's l1: 0.16298\n",
            "[5800]\ttraining's l1: 0.00122052\tvalid_1's l1: 0.162964\n",
            "[6000]\ttraining's l1: 0.00114306\tvalid_1's l1: 0.162955\n",
            "[6200]\ttraining's l1: 0.00107096\tvalid_1's l1: 0.162951\n",
            "[6400]\ttraining's l1: 0.00100173\tvalid_1's l1: 0.162944\n",
            "[6600]\ttraining's l1: 0.000935027\tvalid_1's l1: 0.16294\n",
            "[6800]\ttraining's l1: 0.000878231\tvalid_1's l1: 0.162917\n",
            "[7000]\ttraining's l1: 0.000829871\tvalid_1's l1: 0.162909\n",
            "[7200]\ttraining's l1: 0.000777102\tvalid_1's l1: 0.1629\n",
            "[7400]\ttraining's l1: 0.000735641\tvalid_1's l1: 0.162893\n",
            "[7600]\ttraining's l1: 0.000693574\tvalid_1's l1: 0.16289\n",
            "[7800]\ttraining's l1: 0.000653906\tvalid_1's l1: 0.162884\n",
            "[8000]\ttraining's l1: 0.000621011\tvalid_1's l1: 0.162881\n",
            "[8200]\ttraining's l1: 0.000588689\tvalid_1's l1: 0.162873\n",
            "[8400]\ttraining's l1: 0.000556771\tvalid_1's l1: 0.16286\n",
            "[8600]\ttraining's l1: 0.000527756\tvalid_1's l1: 0.162857\n",
            "[8800]\ttraining's l1: 0.000499125\tvalid_1's l1: 0.162855\n",
            "[9000]\ttraining's l1: 0.000474379\tvalid_1's l1: 0.162849\n",
            "[9200]\ttraining's l1: 0.000452307\tvalid_1's l1: 0.162846\n",
            "[9400]\ttraining's l1: 0.000428265\tvalid_1's l1: 0.162842\n",
            "[9600]\ttraining's l1: 0.000408498\tvalid_1's l1: 0.16284\n",
            "[9800]\ttraining's l1: 0.000388068\tvalid_1's l1: 0.162836\n",
            "[10000]\ttraining's l1: 0.00037093\tvalid_1's l1: 0.162831\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9975]\ttraining's l1: 0.000373213\tvalid_1's l1: 0.16283\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.153736\tvalid_1's l1: 0.215576\n",
            "[400]\ttraining's l1: 0.101406\tvalid_1's l1: 0.202019\n",
            "[600]\ttraining's l1: 0.0692081\tvalid_1's l1: 0.193651\n",
            "[800]\ttraining's l1: 0.0499753\tvalid_1's l1: 0.187622\n",
            "[1000]\ttraining's l1: 0.037975\tvalid_1's l1: 0.184483\n",
            "[1200]\ttraining's l1: 0.0285514\tvalid_1's l1: 0.181195\n",
            "[1400]\ttraining's l1: 0.0219519\tvalid_1's l1: 0.179292\n",
            "[1600]\ttraining's l1: 0.0169642\tvalid_1's l1: 0.17779\n",
            "[1800]\ttraining's l1: 0.0134719\tvalid_1's l1: 0.176568\n",
            "[2000]\ttraining's l1: 0.0110427\tvalid_1's l1: 0.175807\n",
            "[2200]\ttraining's l1: 0.00898741\tvalid_1's l1: 0.17543\n",
            "[2400]\ttraining's l1: 0.00750947\tvalid_1's l1: 0.175024\n",
            "[2600]\ttraining's l1: 0.0063474\tvalid_1's l1: 0.17466\n",
            "[2800]\ttraining's l1: 0.00543476\tvalid_1's l1: 0.174421\n",
            "[3000]\ttraining's l1: 0.0047022\tvalid_1's l1: 0.174217\n",
            "[3200]\ttraining's l1: 0.00410299\tvalid_1's l1: 0.174095\n",
            "[3400]\ttraining's l1: 0.00355586\tvalid_1's l1: 0.173963\n",
            "[3600]\ttraining's l1: 0.00311593\tvalid_1's l1: 0.173854\n",
            "[3800]\ttraining's l1: 0.00277105\tvalid_1's l1: 0.173786\n",
            "[4000]\ttraining's l1: 0.00249767\tvalid_1's l1: 0.173736\n",
            "[4200]\ttraining's l1: 0.00222936\tvalid_1's l1: 0.173675\n",
            "[4400]\ttraining's l1: 0.00203288\tvalid_1's l1: 0.173629\n",
            "[4600]\ttraining's l1: 0.00182696\tvalid_1's l1: 0.173594\n",
            "[4800]\ttraining's l1: 0.0016737\tvalid_1's l1: 0.173568\n",
            "[5000]\ttraining's l1: 0.00152553\tvalid_1's l1: 0.173547\n",
            "[5200]\ttraining's l1: 0.00141474\tvalid_1's l1: 0.173526\n",
            "[5400]\ttraining's l1: 0.00129629\tvalid_1's l1: 0.173501\n",
            "[5600]\ttraining's l1: 0.00119139\tvalid_1's l1: 0.17348\n",
            "[5800]\ttraining's l1: 0.00110287\tvalid_1's l1: 0.173471\n",
            "[6000]\ttraining's l1: 0.00102157\tvalid_1's l1: 0.17345\n",
            "[6200]\ttraining's l1: 0.000948362\tvalid_1's l1: 0.173426\n",
            "[6400]\ttraining's l1: 0.000874637\tvalid_1's l1: 0.173416\n",
            "[6600]\ttraining's l1: 0.000813929\tvalid_1's l1: 0.173404\n",
            "[6800]\ttraining's l1: 0.000759237\tvalid_1's l1: 0.173389\n",
            "[7000]\ttraining's l1: 0.000703464\tvalid_1's l1: 0.173387\n",
            "[7200]\ttraining's l1: 0.000656864\tvalid_1's l1: 0.173381\n",
            "[7400]\ttraining's l1: 0.000612133\tvalid_1's l1: 0.173377\n",
            "Early stopping, best iteration is:\n",
            "[7368]\ttraining's l1: 0.000619933\tvalid_1's l1: 0.173374\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.151339\tvalid_1's l1: 0.225139\n",
            "[400]\ttraining's l1: 0.103322\tvalid_1's l1: 0.212944\n",
            "[600]\ttraining's l1: 0.074671\tvalid_1's l1: 0.204755\n",
            "[800]\ttraining's l1: 0.0559784\tvalid_1's l1: 0.198766\n",
            "[1000]\ttraining's l1: 0.0423606\tvalid_1's l1: 0.194323\n",
            "[1200]\ttraining's l1: 0.0315665\tvalid_1's l1: 0.191019\n",
            "[1400]\ttraining's l1: 0.0241576\tvalid_1's l1: 0.188488\n",
            "[1600]\ttraining's l1: 0.0191618\tvalid_1's l1: 0.18674\n",
            "[1800]\ttraining's l1: 0.015203\tvalid_1's l1: 0.185333\n",
            "[2000]\ttraining's l1: 0.0122933\tvalid_1's l1: 0.18438\n",
            "[2200]\ttraining's l1: 0.00996388\tvalid_1's l1: 0.183734\n",
            "[2400]\ttraining's l1: 0.00823087\tvalid_1's l1: 0.183336\n",
            "[2600]\ttraining's l1: 0.00687172\tvalid_1's l1: 0.182925\n",
            "[2800]\ttraining's l1: 0.00582318\tvalid_1's l1: 0.182703\n",
            "[3000]\ttraining's l1: 0.00498526\tvalid_1's l1: 0.182504\n",
            "[3200]\ttraining's l1: 0.00436212\tvalid_1's l1: 0.182374\n",
            "[3400]\ttraining's l1: 0.00383983\tvalid_1's l1: 0.182273\n",
            "[3600]\ttraining's l1: 0.00337919\tvalid_1's l1: 0.182202\n",
            "[3800]\ttraining's l1: 0.00301453\tvalid_1's l1: 0.182109\n",
            "[4000]\ttraining's l1: 0.00269992\tvalid_1's l1: 0.182028\n",
            "[4200]\ttraining's l1: 0.00243124\tvalid_1's l1: 0.181954\n",
            "[4400]\ttraining's l1: 0.00219437\tvalid_1's l1: 0.181912\n",
            "[4600]\ttraining's l1: 0.0019914\tvalid_1's l1: 0.181872\n",
            "[4800]\ttraining's l1: 0.00182797\tvalid_1's l1: 0.181845\n",
            "[5000]\ttraining's l1: 0.00166931\tvalid_1's l1: 0.181816\n",
            "[5200]\ttraining's l1: 0.0015401\tvalid_1's l1: 0.181799\n",
            "[5400]\ttraining's l1: 0.00142506\tvalid_1's l1: 0.181774\n",
            "[5600]\ttraining's l1: 0.00132674\tvalid_1's l1: 0.181756\n",
            "[5800]\ttraining's l1: 0.00123472\tvalid_1's l1: 0.181743\n",
            "[6000]\ttraining's l1: 0.0011429\tvalid_1's l1: 0.181727\n",
            "[6200]\ttraining's l1: 0.00106953\tvalid_1's l1: 0.181704\n",
            "[6400]\ttraining's l1: 0.0010006\tvalid_1's l1: 0.18169\n",
            "[6600]\ttraining's l1: 0.000930868\tvalid_1's l1: 0.181681\n",
            "[6800]\ttraining's l1: 0.000872231\tvalid_1's l1: 0.181672\n",
            "[7000]\ttraining's l1: 0.000818322\tvalid_1's l1: 0.181663\n",
            "[7200]\ttraining's l1: 0.000761588\tvalid_1's l1: 0.181655\n",
            "[7400]\ttraining's l1: 0.000714238\tvalid_1's l1: 0.18164\n",
            "[7600]\ttraining's l1: 0.000672699\tvalid_1's l1: 0.181633\n",
            "[7800]\ttraining's l1: 0.00063511\tvalid_1's l1: 0.181628\n",
            "[8000]\ttraining's l1: 0.00059892\tvalid_1's l1: 0.181625\n",
            "[8200]\ttraining's l1: 0.000561256\tvalid_1's l1: 0.181615\n",
            "[8400]\ttraining's l1: 0.000527303\tvalid_1's l1: 0.181613\n",
            "[8600]\ttraining's l1: 0.000496127\tvalid_1's l1: 0.181605\n",
            "Early stopping, best iteration is:\n",
            "[8583]\ttraining's l1: 0.000498315\tvalid_1's l1: 0.181604\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.150709\tvalid_1's l1: 0.232846\n",
            "[400]\ttraining's l1: 0.101669\tvalid_1's l1: 0.220751\n",
            "[600]\ttraining's l1: 0.0728477\tvalid_1's l1: 0.211392\n",
            "[800]\ttraining's l1: 0.0535809\tvalid_1's l1: 0.205067\n",
            "[1000]\ttraining's l1: 0.040178\tvalid_1's l1: 0.200237\n",
            "[1200]\ttraining's l1: 0.030366\tvalid_1's l1: 0.19719\n",
            "[1400]\ttraining's l1: 0.0238409\tvalid_1's l1: 0.195345\n",
            "[1600]\ttraining's l1: 0.018659\tvalid_1's l1: 0.193797\n",
            "[1800]\ttraining's l1: 0.0150284\tvalid_1's l1: 0.192631\n",
            "[2000]\ttraining's l1: 0.0121496\tvalid_1's l1: 0.191839\n",
            "[2200]\ttraining's l1: 0.0100569\tvalid_1's l1: 0.191043\n",
            "[2400]\ttraining's l1: 0.0082962\tvalid_1's l1: 0.190607\n",
            "[2600]\ttraining's l1: 0.00690304\tvalid_1's l1: 0.19025\n",
            "[2800]\ttraining's l1: 0.00585536\tvalid_1's l1: 0.189983\n",
            "[3000]\ttraining's l1: 0.00504464\tvalid_1's l1: 0.18978\n",
            "[3200]\ttraining's l1: 0.00446799\tvalid_1's l1: 0.189611\n",
            "[3400]\ttraining's l1: 0.00394767\tvalid_1's l1: 0.189487\n",
            "[3600]\ttraining's l1: 0.0034719\tvalid_1's l1: 0.189383\n",
            "[3800]\ttraining's l1: 0.0031034\tvalid_1's l1: 0.189316\n",
            "[4000]\ttraining's l1: 0.00277813\tvalid_1's l1: 0.189272\n",
            "[4200]\ttraining's l1: 0.00250561\tvalid_1's l1: 0.189211\n",
            "[4400]\ttraining's l1: 0.00228935\tvalid_1's l1: 0.189173\n",
            "[4600]\ttraining's l1: 0.00207867\tvalid_1's l1: 0.189141\n",
            "[4800]\ttraining's l1: 0.0019027\tvalid_1's l1: 0.189113\n",
            "[5000]\ttraining's l1: 0.00175365\tvalid_1's l1: 0.189092\n",
            "[5200]\ttraining's l1: 0.00161522\tvalid_1's l1: 0.189057\n",
            "[5400]\ttraining's l1: 0.00149304\tvalid_1's l1: 0.189027\n",
            "[5600]\ttraining's l1: 0.00138284\tvalid_1's l1: 0.189022\n",
            "[5800]\ttraining's l1: 0.00127795\tvalid_1's l1: 0.18902\n",
            "[6000]\ttraining's l1: 0.0011869\tvalid_1's l1: 0.189009\n",
            "[6200]\ttraining's l1: 0.00111544\tvalid_1's l1: 0.188992\n",
            "[6400]\ttraining's l1: 0.00104491\tvalid_1's l1: 0.188988\n",
            "[6600]\ttraining's l1: 0.000978466\tvalid_1's l1: 0.188977\n",
            "[6800]\ttraining's l1: 0.00091787\tvalid_1's l1: 0.188963\n",
            "[7000]\ttraining's l1: 0.00086787\tvalid_1's l1: 0.188952\n",
            "[7200]\ttraining's l1: 0.000818063\tvalid_1's l1: 0.188948\n",
            "[7400]\ttraining's l1: 0.000767021\tvalid_1's l1: 0.188934\n",
            "[7600]\ttraining's l1: 0.000723758\tvalid_1's l1: 0.188929\n",
            "[7800]\ttraining's l1: 0.000681387\tvalid_1's l1: 0.188925\n",
            "[8000]\ttraining's l1: 0.000646503\tvalid_1's l1: 0.188923\n",
            "Early stopping, best iteration is:\n",
            "[7850]\ttraining's l1: 0.000672431\tvalid_1's l1: 0.18892\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.154384\tvalid_1's l1: 0.219556\n",
            "[400]\ttraining's l1: 0.104017\tvalid_1's l1: 0.208714\n",
            "[600]\ttraining's l1: 0.0744249\tvalid_1's l1: 0.200345\n",
            "[800]\ttraining's l1: 0.0546134\tvalid_1's l1: 0.193867\n",
            "[1000]\ttraining's l1: 0.040521\tvalid_1's l1: 0.188675\n",
            "[1200]\ttraining's l1: 0.0306162\tvalid_1's l1: 0.184944\n",
            "[1400]\ttraining's l1: 0.0237793\tvalid_1's l1: 0.182632\n",
            "[1600]\ttraining's l1: 0.0186125\tvalid_1's l1: 0.180962\n",
            "[1800]\ttraining's l1: 0.0147143\tvalid_1's l1: 0.179722\n",
            "[2000]\ttraining's l1: 0.0118827\tvalid_1's l1: 0.178977\n",
            "[2200]\ttraining's l1: 0.00981878\tvalid_1's l1: 0.178213\n",
            "[2400]\ttraining's l1: 0.00832257\tvalid_1's l1: 0.177781\n",
            "[2600]\ttraining's l1: 0.00698637\tvalid_1's l1: 0.177392\n",
            "[2800]\ttraining's l1: 0.00587248\tvalid_1's l1: 0.177099\n",
            "[3000]\ttraining's l1: 0.00503619\tvalid_1's l1: 0.176867\n",
            "[3200]\ttraining's l1: 0.00433154\tvalid_1's l1: 0.176667\n",
            "[3400]\ttraining's l1: 0.00375419\tvalid_1's l1: 0.176557\n",
            "[3600]\ttraining's l1: 0.00326641\tvalid_1's l1: 0.176449\n",
            "[3800]\ttraining's l1: 0.00291776\tvalid_1's l1: 0.176367\n",
            "[4000]\ttraining's l1: 0.00261156\tvalid_1's l1: 0.176278\n",
            "[4200]\ttraining's l1: 0.00233641\tvalid_1's l1: 0.176236\n",
            "[4400]\ttraining's l1: 0.00208951\tvalid_1's l1: 0.176183\n",
            "[4600]\ttraining's l1: 0.00188918\tvalid_1's l1: 0.176142\n",
            "[4800]\ttraining's l1: 0.00173144\tvalid_1's l1: 0.176109\n",
            "[5000]\ttraining's l1: 0.00158294\tvalid_1's l1: 0.17609\n",
            "[5200]\ttraining's l1: 0.00146033\tvalid_1's l1: 0.176073\n",
            "[5400]\ttraining's l1: 0.0013475\tvalid_1's l1: 0.176068\n",
            "[5600]\ttraining's l1: 0.00124954\tvalid_1's l1: 0.176059\n",
            "[5800]\ttraining's l1: 0.00115504\tvalid_1's l1: 0.176043\n",
            "[6000]\ttraining's l1: 0.00106897\tvalid_1's l1: 0.176037\n",
            "[6200]\ttraining's l1: 0.000991774\tvalid_1's l1: 0.176026\n",
            "[6400]\ttraining's l1: 0.000921908\tvalid_1's l1: 0.176017\n",
            "[6600]\ttraining's l1: 0.000863874\tvalid_1's l1: 0.175999\n",
            "[6800]\ttraining's l1: 0.000807515\tvalid_1's l1: 0.175991\n",
            "[7000]\ttraining's l1: 0.000754768\tvalid_1's l1: 0.175984\n",
            "[7200]\ttraining's l1: 0.000707732\tvalid_1's l1: 0.175978\n",
            "Early stopping, best iteration is:\n",
            "[7040]\ttraining's l1: 0.000742065\tvalid_1's l1: 0.175976\n",
            "\n",
            "✅ CV MAE: 0.1765409240\n",
            "✅ submission_stable10.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 전처리 + 파생변수 + Target Encoding (Out-of-Fold)\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\", n_splits=5, seed=42):\n",
        "    train_id, test_id = train.get(\"ID\"), test.get(\"ID\")\n",
        "    if train_id is not None:\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 수치형 문자열 → 숫자\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\")\n",
        "\n",
        "    # 파생 변수: 안전하게 숫자형만 사용\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "\n",
        "    # 결측치 처리\n",
        "    all_num = num_cols + [\"BMI\", \"bp_ratio\"]\n",
        "    for col in all_num:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # Label Encoding + Out-of-Fold Target Encoding\n",
        "    X = train.copy()\n",
        "    y = train[target_col].copy()\n",
        "    test_proc = test.copy()\n",
        "\n",
        "    oof_te = pd.DataFrame(index=train.index)\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "        le.fit(combined)\n",
        "        X[col+\"_LE\"] = le.transform(train[col].astype(str))\n",
        "        test_proc[col+\"_LE\"] = le.transform(test[col].astype(str))\n",
        "\n",
        "        # Out-of-Fold Target Encoding\n",
        "        te_col = col+\"_TE\"\n",
        "        oof_te[te_col] = 0\n",
        "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "        for tr_idx, val_idx in kf.split(X):\n",
        "            mapping = X.iloc[tr_idx].groupby(col)[target_col].mean()\n",
        "            oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
        "        # test set TE\n",
        "        mapping_full = X.groupby(col)[target_col].mean()\n",
        "        test_proc[te_col] = test[col].map(mapping_full).fillna(y.mean())\n",
        "\n",
        "    # 최종 feature 선택\n",
        "    features = all_num + [c+\"_LE\" for c in cat_cols] + [c+\"_TE\" for c in cat_cols]\n",
        "    X_final = pd.concat([X[all_num], oof_te, X[[c+\"_LE\" for c in cat_cols]]], axis=1)\n",
        "    test_final = pd.concat([test_proc[all_num], test_proc[[c+\"_TE\" for c in cat_cols]], test_proc[[c+\"_LE\" for c in cat_cols]]], axis=1)\n",
        "\n",
        "    return X_final, y, test_final, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 모델 학습 및 예측\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds_lgb = np.zeros(len(test))\n",
        "    test_preds_et = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        model_lgb = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_val],\n",
        "                              num_boost_round=10000, callbacks=[early_stopping(200), log_evaluation(200)])\n",
        "        oof_preds[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n",
        "        test_preds_lgb += model_lgb.predict(test, num_iteration=model_lgb.best_iteration)/n_splits\n",
        "\n",
        "        # ExtraTrees\n",
        "        model_et = ExtraTreesRegressor(n_estimators=500, max_depth=12, random_state=seed)\n",
        "        model_et.fit(X_train, y_train)\n",
        "        test_preds_et += model_et.predict(test)/n_splits\n",
        "\n",
        "    test_preds = (test_preds_lgb + test_preds_et)/2\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 제출 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_stable11.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_stable11.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 실행\n",
        "# ------------------------------\n",
        "if __name__==\"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\", n_splits=5)\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CV2aJoxBo7y",
        "outputId": "12394a7f-d932-4d79-fff6-3b9e780188ec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n",
            "/tmp/ipython-input-1970545710.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  oof_te.iloc[val_idx][te_col] = X.iloc[val_idx][col].map(mapping)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttraining's l1: 0.158733\tvalid_1's l1: 0.212867\n",
            "[400]\ttraining's l1: 0.108072\tvalid_1's l1: 0.197941\n",
            "[600]\ttraining's l1: 0.0761342\tvalid_1's l1: 0.187993\n",
            "[800]\ttraining's l1: 0.055692\tvalid_1's l1: 0.1822\n",
            "[1000]\ttraining's l1: 0.0421217\tvalid_1's l1: 0.177856\n",
            "[1200]\ttraining's l1: 0.0325783\tvalid_1's l1: 0.174538\n",
            "[1400]\ttraining's l1: 0.0253634\tvalid_1's l1: 0.172099\n",
            "[1600]\ttraining's l1: 0.0200709\tvalid_1's l1: 0.170679\n",
            "[1800]\ttraining's l1: 0.0159182\tvalid_1's l1: 0.169213\n",
            "[2000]\ttraining's l1: 0.0129131\tvalid_1's l1: 0.168186\n",
            "[2200]\ttraining's l1: 0.0105298\tvalid_1's l1: 0.167322\n",
            "[2400]\ttraining's l1: 0.00866518\tvalid_1's l1: 0.166744\n",
            "[2600]\ttraining's l1: 0.00722881\tvalid_1's l1: 0.166338\n",
            "[2800]\ttraining's l1: 0.00617474\tvalid_1's l1: 0.166033\n",
            "[3000]\ttraining's l1: 0.00529218\tvalid_1's l1: 0.165816\n",
            "[3200]\ttraining's l1: 0.00459172\tvalid_1's l1: 0.165646\n",
            "[3400]\ttraining's l1: 0.00402351\tvalid_1's l1: 0.165516\n",
            "[3600]\ttraining's l1: 0.0035165\tvalid_1's l1: 0.165361\n",
            "[3800]\ttraining's l1: 0.00311432\tvalid_1's l1: 0.165275\n",
            "[4000]\ttraining's l1: 0.00280111\tvalid_1's l1: 0.165225\n",
            "[4200]\ttraining's l1: 0.00251203\tvalid_1's l1: 0.165167\n",
            "[4400]\ttraining's l1: 0.00228837\tvalid_1's l1: 0.165118\n",
            "[4600]\ttraining's l1: 0.00209717\tvalid_1's l1: 0.165065\n",
            "[4800]\ttraining's l1: 0.00191826\tvalid_1's l1: 0.16502\n",
            "[5000]\ttraining's l1: 0.00176885\tvalid_1's l1: 0.164985\n",
            "[5200]\ttraining's l1: 0.00162301\tvalid_1's l1: 0.164942\n",
            "[5400]\ttraining's l1: 0.00149849\tvalid_1's l1: 0.164909\n",
            "[5600]\ttraining's l1: 0.00138213\tvalid_1's l1: 0.164875\n",
            "[5800]\ttraining's l1: 0.00128757\tvalid_1's l1: 0.16487\n",
            "[6000]\ttraining's l1: 0.00120161\tvalid_1's l1: 0.16485\n",
            "[6200]\ttraining's l1: 0.00112506\tvalid_1's l1: 0.164838\n",
            "[6400]\ttraining's l1: 0.00104359\tvalid_1's l1: 0.164821\n",
            "[6600]\ttraining's l1: 0.000980948\tvalid_1's l1: 0.164807\n",
            "[6800]\ttraining's l1: 0.000918678\tvalid_1's l1: 0.164795\n",
            "[7000]\ttraining's l1: 0.000862729\tvalid_1's l1: 0.164788\n",
            "[7200]\ttraining's l1: 0.00081052\tvalid_1's l1: 0.164765\n",
            "[7400]\ttraining's l1: 0.000760692\tvalid_1's l1: 0.164756\n",
            "[7600]\ttraining's l1: 0.000720073\tvalid_1's l1: 0.164745\n",
            "[7800]\ttraining's l1: 0.000678882\tvalid_1's l1: 0.164735\n",
            "[8000]\ttraining's l1: 0.000642743\tvalid_1's l1: 0.164738\n",
            "Early stopping, best iteration is:\n",
            "[7849]\ttraining's l1: 0.000667414\tvalid_1's l1: 0.164732\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.154145\tvalid_1's l1: 0.216449\n",
            "[400]\ttraining's l1: 0.105005\tvalid_1's l1: 0.203433\n",
            "[600]\ttraining's l1: 0.073897\tvalid_1's l1: 0.196213\n",
            "[800]\ttraining's l1: 0.0531448\tvalid_1's l1: 0.189297\n",
            "[1000]\ttraining's l1: 0.0398421\tvalid_1's l1: 0.185589\n",
            "[1200]\ttraining's l1: 0.030548\tvalid_1's l1: 0.182418\n",
            "[1400]\ttraining's l1: 0.0235393\tvalid_1's l1: 0.180024\n",
            "[1600]\ttraining's l1: 0.0184617\tvalid_1's l1: 0.178311\n",
            "[1800]\ttraining's l1: 0.0146952\tvalid_1's l1: 0.177066\n",
            "[2000]\ttraining's l1: 0.0119173\tvalid_1's l1: 0.176422\n",
            "[2200]\ttraining's l1: 0.00971178\tvalid_1's l1: 0.175687\n",
            "[2400]\ttraining's l1: 0.00805851\tvalid_1's l1: 0.175144\n",
            "[2600]\ttraining's l1: 0.00678252\tvalid_1's l1: 0.174837\n",
            "[2800]\ttraining's l1: 0.00585077\tvalid_1's l1: 0.174631\n",
            "[3000]\ttraining's l1: 0.00499026\tvalid_1's l1: 0.174462\n",
            "[3200]\ttraining's l1: 0.00439659\tvalid_1's l1: 0.174307\n",
            "[3400]\ttraining's l1: 0.00385316\tvalid_1's l1: 0.174185\n",
            "[3600]\ttraining's l1: 0.00343324\tvalid_1's l1: 0.174053\n",
            "[3800]\ttraining's l1: 0.00304736\tvalid_1's l1: 0.173979\n",
            "[4000]\ttraining's l1: 0.00271398\tvalid_1's l1: 0.173927\n",
            "[4200]\ttraining's l1: 0.00242388\tvalid_1's l1: 0.173853\n",
            "[4400]\ttraining's l1: 0.00219057\tvalid_1's l1: 0.173784\n",
            "[4600]\ttraining's l1: 0.00198357\tvalid_1's l1: 0.173766\n",
            "[4800]\ttraining's l1: 0.00180665\tvalid_1's l1: 0.173743\n",
            "[5000]\ttraining's l1: 0.00164428\tvalid_1's l1: 0.173726\n",
            "[5200]\ttraining's l1: 0.00152153\tvalid_1's l1: 0.173701\n",
            "[5400]\ttraining's l1: 0.00140201\tvalid_1's l1: 0.173685\n",
            "[5600]\ttraining's l1: 0.00129157\tvalid_1's l1: 0.173678\n",
            "[5800]\ttraining's l1: 0.00119417\tvalid_1's l1: 0.173664\n",
            "[6000]\ttraining's l1: 0.00110628\tvalid_1's l1: 0.173645\n",
            "[6200]\ttraining's l1: 0.00103427\tvalid_1's l1: 0.173634\n",
            "[6400]\ttraining's l1: 0.00096039\tvalid_1's l1: 0.173625\n",
            "[6600]\ttraining's l1: 0.000897132\tvalid_1's l1: 0.173626\n",
            "[6800]\ttraining's l1: 0.00083915\tvalid_1's l1: 0.173605\n",
            "[7000]\ttraining's l1: 0.000785738\tvalid_1's l1: 0.173603\n",
            "[7200]\ttraining's l1: 0.000738371\tvalid_1's l1: 0.173592\n",
            "[7400]\ttraining's l1: 0.000684881\tvalid_1's l1: 0.173583\n",
            "[7600]\ttraining's l1: 0.000637498\tvalid_1's l1: 0.173576\n",
            "Early stopping, best iteration is:\n",
            "[7513]\ttraining's l1: 0.000657774\tvalid_1's l1: 0.173573\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.150477\tvalid_1's l1: 0.227554\n",
            "[400]\ttraining's l1: 0.10385\tvalid_1's l1: 0.215613\n",
            "[600]\ttraining's l1: 0.0742602\tvalid_1's l1: 0.206512\n",
            "[800]\ttraining's l1: 0.054745\tvalid_1's l1: 0.20084\n",
            "[1000]\ttraining's l1: 0.0412879\tvalid_1's l1: 0.196888\n",
            "[1200]\ttraining's l1: 0.0313365\tvalid_1's l1: 0.193966\n",
            "[1400]\ttraining's l1: 0.0238487\tvalid_1's l1: 0.191431\n",
            "[1600]\ttraining's l1: 0.0188948\tvalid_1's l1: 0.189805\n",
            "[1800]\ttraining's l1: 0.0150381\tvalid_1's l1: 0.188661\n",
            "[2000]\ttraining's l1: 0.0120913\tvalid_1's l1: 0.187821\n",
            "[2200]\ttraining's l1: 0.00984442\tvalid_1's l1: 0.187059\n",
            "[2400]\ttraining's l1: 0.00811218\tvalid_1's l1: 0.186674\n",
            "[2600]\ttraining's l1: 0.00678314\tvalid_1's l1: 0.186304\n",
            "[2800]\ttraining's l1: 0.00579377\tvalid_1's l1: 0.186087\n",
            "[3000]\ttraining's l1: 0.00492641\tvalid_1's l1: 0.185897\n",
            "[3200]\ttraining's l1: 0.00432172\tvalid_1's l1: 0.185783\n",
            "[3400]\ttraining's l1: 0.00379629\tvalid_1's l1: 0.185623\n",
            "[3600]\ttraining's l1: 0.00333515\tvalid_1's l1: 0.185558\n",
            "[3800]\ttraining's l1: 0.00297583\tvalid_1's l1: 0.185511\n",
            "[4000]\ttraining's l1: 0.00267862\tvalid_1's l1: 0.185478\n",
            "[4200]\ttraining's l1: 0.00242152\tvalid_1's l1: 0.185458\n",
            "[4400]\ttraining's l1: 0.00219825\tvalid_1's l1: 0.185444\n",
            "[4600]\ttraining's l1: 0.00199562\tvalid_1's l1: 0.185417\n",
            "[4800]\ttraining's l1: 0.00183336\tvalid_1's l1: 0.1854\n",
            "[5000]\ttraining's l1: 0.00168786\tvalid_1's l1: 0.185372\n",
            "[5200]\ttraining's l1: 0.00155234\tvalid_1's l1: 0.185351\n",
            "[5400]\ttraining's l1: 0.00143786\tvalid_1's l1: 0.185338\n",
            "[5600]\ttraining's l1: 0.00133622\tvalid_1's l1: 0.185322\n",
            "[5800]\ttraining's l1: 0.00124162\tvalid_1's l1: 0.185327\n",
            "Early stopping, best iteration is:\n",
            "[5684]\ttraining's l1: 0.00129778\tvalid_1's l1: 0.185314\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.153865\tvalid_1's l1: 0.23071\n",
            "[400]\ttraining's l1: 0.103391\tvalid_1's l1: 0.218507\n",
            "[600]\ttraining's l1: 0.0731549\tvalid_1's l1: 0.208726\n",
            "[800]\ttraining's l1: 0.0537284\tvalid_1's l1: 0.201496\n",
            "[1000]\ttraining's l1: 0.0402451\tvalid_1's l1: 0.197016\n",
            "[1200]\ttraining's l1: 0.0302828\tvalid_1's l1: 0.193519\n",
            "[1400]\ttraining's l1: 0.0234676\tvalid_1's l1: 0.191206\n",
            "[1600]\ttraining's l1: 0.0185442\tvalid_1's l1: 0.189831\n",
            "[1800]\ttraining's l1: 0.0148484\tvalid_1's l1: 0.188853\n",
            "[2000]\ttraining's l1: 0.0119085\tvalid_1's l1: 0.187832\n",
            "[2200]\ttraining's l1: 0.00995518\tvalid_1's l1: 0.187122\n",
            "[2400]\ttraining's l1: 0.00830665\tvalid_1's l1: 0.186736\n",
            "[2600]\ttraining's l1: 0.00698551\tvalid_1's l1: 0.186349\n",
            "[2800]\ttraining's l1: 0.00595543\tvalid_1's l1: 0.186119\n",
            "[3000]\ttraining's l1: 0.0051328\tvalid_1's l1: 0.18593\n",
            "[3200]\ttraining's l1: 0.00451814\tvalid_1's l1: 0.185803\n",
            "[3400]\ttraining's l1: 0.00399868\tvalid_1's l1: 0.185704\n",
            "[3600]\ttraining's l1: 0.00353197\tvalid_1's l1: 0.185594\n",
            "[3800]\ttraining's l1: 0.00315951\tvalid_1's l1: 0.185495\n",
            "[4000]\ttraining's l1: 0.00283848\tvalid_1's l1: 0.185437\n",
            "[4200]\ttraining's l1: 0.00256782\tvalid_1's l1: 0.185401\n",
            "[4400]\ttraining's l1: 0.002349\tvalid_1's l1: 0.185381\n",
            "[4600]\ttraining's l1: 0.00212911\tvalid_1's l1: 0.185327\n",
            "[4800]\ttraining's l1: 0.00194874\tvalid_1's l1: 0.1853\n",
            "[5000]\ttraining's l1: 0.00178687\tvalid_1's l1: 0.185257\n",
            "[5200]\ttraining's l1: 0.00165084\tvalid_1's l1: 0.185243\n",
            "[5400]\ttraining's l1: 0.00153198\tvalid_1's l1: 0.185227\n",
            "[5600]\ttraining's l1: 0.00142726\tvalid_1's l1: 0.185208\n",
            "[5800]\ttraining's l1: 0.00132349\tvalid_1's l1: 0.185202\n",
            "[6000]\ttraining's l1: 0.00123172\tvalid_1's l1: 0.185202\n",
            "Early stopping, best iteration is:\n",
            "[5849]\ttraining's l1: 0.00130009\tvalid_1's l1: 0.185193\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.15471\tvalid_1's l1: 0.223256\n",
            "[400]\ttraining's l1: 0.104829\tvalid_1's l1: 0.211216\n",
            "[600]\ttraining's l1: 0.0757712\tvalid_1's l1: 0.202642\n",
            "[800]\ttraining's l1: 0.0559294\tvalid_1's l1: 0.196539\n",
            "[1000]\ttraining's l1: 0.0423224\tvalid_1's l1: 0.19209\n",
            "[1200]\ttraining's l1: 0.0321735\tvalid_1's l1: 0.188487\n",
            "[1400]\ttraining's l1: 0.0249919\tvalid_1's l1: 0.185637\n",
            "[1600]\ttraining's l1: 0.019492\tvalid_1's l1: 0.183579\n",
            "[1800]\ttraining's l1: 0.0152954\tvalid_1's l1: 0.182027\n",
            "[2000]\ttraining's l1: 0.0124115\tvalid_1's l1: 0.181064\n",
            "[2200]\ttraining's l1: 0.0104125\tvalid_1's l1: 0.180318\n",
            "[2400]\ttraining's l1: 0.00879072\tvalid_1's l1: 0.179844\n",
            "[2600]\ttraining's l1: 0.00748887\tvalid_1's l1: 0.179475\n",
            "[2800]\ttraining's l1: 0.00628408\tvalid_1's l1: 0.179159\n",
            "[3000]\ttraining's l1: 0.0053985\tvalid_1's l1: 0.178883\n",
            "[3200]\ttraining's l1: 0.0046872\tvalid_1's l1: 0.178725\n",
            "[3400]\ttraining's l1: 0.00405195\tvalid_1's l1: 0.178541\n",
            "[3600]\ttraining's l1: 0.00357918\tvalid_1's l1: 0.178434\n",
            "[3800]\ttraining's l1: 0.00317224\tvalid_1's l1: 0.178354\n",
            "[4000]\ttraining's l1: 0.00282131\tvalid_1's l1: 0.178243\n",
            "[4200]\ttraining's l1: 0.00252464\tvalid_1's l1: 0.178176\n",
            "[4400]\ttraining's l1: 0.00227415\tvalid_1's l1: 0.178136\n",
            "[4600]\ttraining's l1: 0.00207385\tvalid_1's l1: 0.178113\n",
            "[4800]\ttraining's l1: 0.00190531\tvalid_1's l1: 0.178067\n",
            "[5000]\ttraining's l1: 0.00173986\tvalid_1's l1: 0.178055\n",
            "[5200]\ttraining's l1: 0.00160363\tvalid_1's l1: 0.178037\n",
            "[5400]\ttraining's l1: 0.00147038\tvalid_1's l1: 0.178004\n",
            "[5600]\ttraining's l1: 0.00135484\tvalid_1's l1: 0.177999\n",
            "[5800]\ttraining's l1: 0.00125324\tvalid_1's l1: 0.17798\n",
            "[6000]\ttraining's l1: 0.00115685\tvalid_1's l1: 0.177978\n",
            "[6200]\ttraining's l1: 0.00108236\tvalid_1's l1: 0.177965\n",
            "[6400]\ttraining's l1: 0.00101336\tvalid_1's l1: 0.177955\n",
            "[6600]\ttraining's l1: 0.000936562\tvalid_1's l1: 0.177939\n",
            "[6800]\ttraining's l1: 0.000874987\tvalid_1's l1: 0.177921\n",
            "[7000]\ttraining's l1: 0.000818103\tvalid_1's l1: 0.177912\n",
            "[7200]\ttraining's l1: 0.000761921\tvalid_1's l1: 0.177908\n",
            "[7400]\ttraining's l1: 0.000711629\tvalid_1's l1: 0.177904\n",
            "[7600]\ttraining's l1: 0.000673079\tvalid_1's l1: 0.177898\n",
            "[7800]\ttraining's l1: 0.000630686\tvalid_1's l1: 0.177889\n",
            "[8000]\ttraining's l1: 0.000595754\tvalid_1's l1: 0.177882\n",
            "[8200]\ttraining's l1: 0.000560945\tvalid_1's l1: 0.177879\n",
            "[8400]\ttraining's l1: 0.000525479\tvalid_1's l1: 0.177878\n",
            "Early stopping, best iteration is:\n",
            "[8295]\ttraining's l1: 0.000545076\tvalid_1's l1: 0.177877\n",
            "\n",
            "✅ CV MAE: 0.1773377094\n",
            "✅ submission_stable11.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수 + Target Encoding\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 없습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 문자열 컬럼 숫자 매핑 (activity, sleep_pattern)\n",
        "    activity_map = {'light':1, 'moderate':2, 'intense':3}\n",
        "    sleep_map    = {'sleep difficulty':1, 'normal':2, 'oversleeping':3}\n",
        "\n",
        "    for df in [train, test]:\n",
        "        if \"activity\" in df.columns:\n",
        "            df[\"activity_num\"] = df[\"activity\"].map(activity_map)\n",
        "            df[\"activity_num\"].fillna(df[\"activity_num\"].mean(), inplace=True)\n",
        "        else:\n",
        "            df[\"activity_num\"] = 0\n",
        "\n",
        "        if \"sleep_pattern\" in df.columns:\n",
        "            df[\"sleep_num\"] = df[\"sleep_pattern\"].map(sleep_map)\n",
        "            df[\"sleep_num\"].fillna(df[\"sleep_num\"].mean(), inplace=True)\n",
        "        else:\n",
        "            df[\"sleep_num\"] = 0\n",
        "\n",
        "        # 파생 변수\n",
        "        df[\"activity_sleep\"] = df[\"activity_num\"] * df[\"sleep_num\"]\n",
        "        df[\"BMI\"]            = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"]       = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "        df[\"age_weight_ratio\"]= df[\"age\"] / df[\"weight\"]\n",
        "\n",
        "    # 수치형 결측치 처리\n",
        "    for col in num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"]:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # 범주형 Target Encoding\n",
        "    for col in cat_cols:\n",
        "        mapping = train.groupby(col)[target_col].mean()\n",
        "        train[col+\"_TE\"] = train[col].map(mapping)\n",
        "        test[col+\"_TE\"]  = test[col].map(mapping)\n",
        "    cat_cols_TE = [c+\"_TE\" for c in cat_cols]\n",
        "\n",
        "    # Label Encoding\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "        le.fit(combined)\n",
        "        train[col+\"_LE\"] = le.transform(train[col].astype(str))\n",
        "        test[col+\"_LE\"]  = le.transform(test[col].astype(str))\n",
        "    cat_cols_LE = [c+\"_LE\" for c in cat_cols]\n",
        "\n",
        "    # 로그 변환: 왜곡이 큰 컬럼\n",
        "    for col in [\"cholesterol\",\"glucose\",\"bone_density\",\"mean_working\"]:\n",
        "        if col in train.columns:\n",
        "            train[col] = np.log1p(train[col])\n",
        "            test[col]  = np.log1p(test[col])\n",
        "\n",
        "    # 최종 feature 선택\n",
        "    features = num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"] + cat_cols_TE + cat_cols_LE\n",
        "    X = train[features]\n",
        "    y = train[target_col]\n",
        "    test_final = test[features]\n",
        "\n",
        "    return X, y, test_final, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 및 예측 (LightGBM + ExtraTrees 앙상블)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds_lgb = np.zeros(len(test))\n",
        "    test_preds_et  = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        model_lgb = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=200)]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n",
        "        test_preds_lgb += model_lgb.predict(test, num_iteration=model_lgb.best_iteration) / n_splits\n",
        "\n",
        "        # ExtraTreesRegressor\n",
        "        model_et = ExtraTreesRegressor(n_estimators=500, max_depth=12, random_state=seed)\n",
        "        model_et.fit(X_train, y_train)\n",
        "        test_preds_et += model_et.predict(test) / n_splits\n",
        "\n",
        "    # 앙상블: LightGBM + ExtraTrees\n",
        "    test_preds = (test_preds_lgb + test_preds_et) / 2\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_stable_final12.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"✅ submission_stable_final12.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)  # KFold 5\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKnIonFaBo5y",
        "outputId": "fc6c108b-dbef-4726-cc46-ca11f1f7f3e8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3545527360.py:54: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"activity_num\"].fillna(df[\"activity_num\"].mean(), inplace=True)\n",
            "/tmp/ipython-input-3545527360.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"sleep_num\"].fillna(df[\"sleep_num\"].mean(), inplace=True)\n",
            "/tmp/ipython-input-3545527360.py:54: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"activity_num\"].fillna(df[\"activity_num\"].mean(), inplace=True)\n",
            "/tmp/ipython-input-3545527360.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"sleep_num\"].fillna(df[\"sleep_num\"].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttraining's l1: 0.155613\tvalid_1's l1: 0.212971\n",
            "[400]\ttraining's l1: 0.107217\tvalid_1's l1: 0.19947\n",
            "[600]\ttraining's l1: 0.0749955\tvalid_1's l1: 0.188296\n",
            "[800]\ttraining's l1: 0.0534595\tvalid_1's l1: 0.180494\n",
            "[1000]\ttraining's l1: 0.0392856\tvalid_1's l1: 0.17553\n",
            "[1200]\ttraining's l1: 0.0302429\tvalid_1's l1: 0.172131\n",
            "[1400]\ttraining's l1: 0.0231905\tvalid_1's l1: 0.169667\n",
            "[1600]\ttraining's l1: 0.0179688\tvalid_1's l1: 0.167463\n",
            "[1800]\ttraining's l1: 0.0139769\tvalid_1's l1: 0.166072\n",
            "[2000]\ttraining's l1: 0.0110618\tvalid_1's l1: 0.165147\n",
            "[2200]\ttraining's l1: 0.00882452\tvalid_1's l1: 0.164576\n",
            "[2400]\ttraining's l1: 0.00728902\tvalid_1's l1: 0.164141\n",
            "[2600]\ttraining's l1: 0.00601608\tvalid_1's l1: 0.163785\n",
            "[2800]\ttraining's l1: 0.00506943\tvalid_1's l1: 0.163459\n",
            "[3000]\ttraining's l1: 0.00432016\tvalid_1's l1: 0.163351\n",
            "[3200]\ttraining's l1: 0.00374967\tvalid_1's l1: 0.163247\n",
            "[3400]\ttraining's l1: 0.0033045\tvalid_1's l1: 0.163143\n",
            "[3600]\ttraining's l1: 0.0028994\tvalid_1's l1: 0.163028\n",
            "[3800]\ttraining's l1: 0.00255735\tvalid_1's l1: 0.162959\n",
            "[4000]\ttraining's l1: 0.00228861\tvalid_1's l1: 0.162925\n",
            "[4200]\ttraining's l1: 0.00208119\tvalid_1's l1: 0.162849\n",
            "[4400]\ttraining's l1: 0.00189288\tvalid_1's l1: 0.162821\n",
            "[4600]\ttraining's l1: 0.00170278\tvalid_1's l1: 0.162796\n",
            "[4800]\ttraining's l1: 0.00156232\tvalid_1's l1: 0.162776\n",
            "[5000]\ttraining's l1: 0.00143218\tvalid_1's l1: 0.162769\n",
            "[5200]\ttraining's l1: 0.00131016\tvalid_1's l1: 0.162755\n",
            "[5400]\ttraining's l1: 0.00121221\tvalid_1's l1: 0.162749\n",
            "Early stopping, best iteration is:\n",
            "[5350]\ttraining's l1: 0.00123607\tvalid_1's l1: 0.162741\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.149782\tvalid_1's l1: 0.216064\n",
            "[400]\ttraining's l1: 0.0952956\tvalid_1's l1: 0.200408\n",
            "[600]\ttraining's l1: 0.0665284\tvalid_1's l1: 0.193178\n",
            "[800]\ttraining's l1: 0.047391\tvalid_1's l1: 0.188125\n",
            "[1000]\ttraining's l1: 0.035414\tvalid_1's l1: 0.184446\n",
            "[1200]\ttraining's l1: 0.026534\tvalid_1's l1: 0.181912\n",
            "[1400]\ttraining's l1: 0.0199529\tvalid_1's l1: 0.179692\n",
            "[1600]\ttraining's l1: 0.0155268\tvalid_1's l1: 0.178244\n",
            "[1800]\ttraining's l1: 0.0122329\tvalid_1's l1: 0.177319\n",
            "[2000]\ttraining's l1: 0.00985951\tvalid_1's l1: 0.176636\n",
            "[2200]\ttraining's l1: 0.00816911\tvalid_1's l1: 0.176175\n",
            "[2400]\ttraining's l1: 0.00676571\tvalid_1's l1: 0.175813\n",
            "[2600]\ttraining's l1: 0.00562027\tvalid_1's l1: 0.175459\n",
            "[2800]\ttraining's l1: 0.00482019\tvalid_1's l1: 0.1753\n",
            "[3000]\ttraining's l1: 0.00414491\tvalid_1's l1: 0.17513\n",
            "[3200]\ttraining's l1: 0.00363\tvalid_1's l1: 0.175011\n",
            "[3400]\ttraining's l1: 0.00317774\tvalid_1's l1: 0.174896\n",
            "[3600]\ttraining's l1: 0.0028191\tvalid_1's l1: 0.174802\n",
            "[3800]\ttraining's l1: 0.00249347\tvalid_1's l1: 0.174756\n",
            "[4000]\ttraining's l1: 0.002241\tvalid_1's l1: 0.174721\n",
            "[4200]\ttraining's l1: 0.00200981\tvalid_1's l1: 0.174674\n",
            "[4400]\ttraining's l1: 0.00182054\tvalid_1's l1: 0.174625\n",
            "[4600]\ttraining's l1: 0.00165208\tvalid_1's l1: 0.174612\n",
            "[4800]\ttraining's l1: 0.00151308\tvalid_1's l1: 0.174595\n",
            "[5000]\ttraining's l1: 0.00137655\tvalid_1's l1: 0.174577\n",
            "[5200]\ttraining's l1: 0.00126289\tvalid_1's l1: 0.174571\n",
            "[5400]\ttraining's l1: 0.00116472\tvalid_1's l1: 0.174545\n",
            "[5600]\ttraining's l1: 0.001078\tvalid_1's l1: 0.174538\n",
            "[5800]\ttraining's l1: 0.00100431\tvalid_1's l1: 0.174519\n",
            "[6000]\ttraining's l1: 0.000936581\tvalid_1's l1: 0.174518\n",
            "[6200]\ttraining's l1: 0.000868435\tvalid_1's l1: 0.174516\n",
            "[6400]\ttraining's l1: 0.000810411\tvalid_1's l1: 0.17451\n",
            "[6600]\ttraining's l1: 0.000753413\tvalid_1's l1: 0.174504\n",
            "[6800]\ttraining's l1: 0.000706103\tvalid_1's l1: 0.174494\n",
            "[7000]\ttraining's l1: 0.000660138\tvalid_1's l1: 0.174484\n",
            "[7200]\ttraining's l1: 0.000618713\tvalid_1's l1: 0.174478\n",
            "[7400]\ttraining's l1: 0.000579137\tvalid_1's l1: 0.174477\n",
            "[7600]\ttraining's l1: 0.000539025\tvalid_1's l1: 0.174474\n",
            "[7800]\ttraining's l1: 0.000507462\tvalid_1's l1: 0.174472\n",
            "[8000]\ttraining's l1: 0.000477621\tvalid_1's l1: 0.174465\n",
            "[8200]\ttraining's l1: 0.000451033\tvalid_1's l1: 0.174456\n",
            "[8400]\ttraining's l1: 0.00042236\tvalid_1's l1: 0.17445\n",
            "[8600]\ttraining's l1: 0.000396992\tvalid_1's l1: 0.174448\n",
            "[8800]\ttraining's l1: 0.000374611\tvalid_1's l1: 0.174445\n",
            "[9000]\ttraining's l1: 0.000352708\tvalid_1's l1: 0.174445\n",
            "Early stopping, best iteration is:\n",
            "[8845]\ttraining's l1: 0.000368018\tvalid_1's l1: 0.174444\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.149523\tvalid_1's l1: 0.226487\n",
            "[400]\ttraining's l1: 0.0993384\tvalid_1's l1: 0.212139\n",
            "[600]\ttraining's l1: 0.0697624\tvalid_1's l1: 0.203698\n",
            "[800]\ttraining's l1: 0.0510011\tvalid_1's l1: 0.197984\n",
            "[1000]\ttraining's l1: 0.0378587\tvalid_1's l1: 0.193578\n",
            "[1200]\ttraining's l1: 0.0280923\tvalid_1's l1: 0.190196\n",
            "[1400]\ttraining's l1: 0.0216108\tvalid_1's l1: 0.187825\n",
            "[1600]\ttraining's l1: 0.0167513\tvalid_1's l1: 0.18617\n",
            "[1800]\ttraining's l1: 0.01328\tvalid_1's l1: 0.184765\n",
            "[2000]\ttraining's l1: 0.0106209\tvalid_1's l1: 0.183855\n",
            "[2200]\ttraining's l1: 0.00854212\tvalid_1's l1: 0.183139\n",
            "[2400]\ttraining's l1: 0.00699339\tvalid_1's l1: 0.182734\n",
            "[2600]\ttraining's l1: 0.00582904\tvalid_1's l1: 0.182425\n",
            "[2800]\ttraining's l1: 0.00494334\tvalid_1's l1: 0.182254\n",
            "[3000]\ttraining's l1: 0.00422401\tvalid_1's l1: 0.182099\n",
            "[3200]\ttraining's l1: 0.00366422\tvalid_1's l1: 0.181987\n",
            "[3400]\ttraining's l1: 0.00321357\tvalid_1's l1: 0.181872\n",
            "[3600]\ttraining's l1: 0.00285132\tvalid_1's l1: 0.181758\n",
            "[3800]\ttraining's l1: 0.00252496\tvalid_1's l1: 0.181684\n",
            "[4000]\ttraining's l1: 0.0022679\tvalid_1's l1: 0.181659\n",
            "[4200]\ttraining's l1: 0.00205052\tvalid_1's l1: 0.181634\n",
            "[4400]\ttraining's l1: 0.00183339\tvalid_1's l1: 0.181586\n",
            "[4600]\ttraining's l1: 0.00166166\tvalid_1's l1: 0.181552\n",
            "[4800]\ttraining's l1: 0.00153808\tvalid_1's l1: 0.181537\n",
            "[5000]\ttraining's l1: 0.00141422\tvalid_1's l1: 0.181524\n",
            "[5200]\ttraining's l1: 0.00129689\tvalid_1's l1: 0.181525\n",
            "Early stopping, best iteration is:\n",
            "[5095]\ttraining's l1: 0.00136509\tvalid_1's l1: 0.181515\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.148477\tvalid_1's l1: 0.230644\n",
            "[400]\ttraining's l1: 0.0974441\tvalid_1's l1: 0.216552\n",
            "[600]\ttraining's l1: 0.0685655\tvalid_1's l1: 0.208221\n",
            "[800]\ttraining's l1: 0.0495894\tvalid_1's l1: 0.201489\n",
            "[1000]\ttraining's l1: 0.0371765\tvalid_1's l1: 0.19682\n",
            "[1200]\ttraining's l1: 0.0279966\tvalid_1's l1: 0.193136\n",
            "[1400]\ttraining's l1: 0.0211441\tvalid_1's l1: 0.190949\n",
            "[1600]\ttraining's l1: 0.0166042\tvalid_1's l1: 0.189246\n",
            "[1800]\ttraining's l1: 0.0132414\tvalid_1's l1: 0.188201\n",
            "[2000]\ttraining's l1: 0.0104309\tvalid_1's l1: 0.187397\n",
            "[2200]\ttraining's l1: 0.00852616\tvalid_1's l1: 0.186765\n",
            "[2400]\ttraining's l1: 0.006994\tvalid_1's l1: 0.186424\n",
            "[2600]\ttraining's l1: 0.00580363\tvalid_1's l1: 0.18612\n",
            "[2800]\ttraining's l1: 0.00496521\tvalid_1's l1: 0.185908\n",
            "[3000]\ttraining's l1: 0.00427756\tvalid_1's l1: 0.185768\n",
            "[3200]\ttraining's l1: 0.00377661\tvalid_1's l1: 0.185644\n",
            "[3400]\ttraining's l1: 0.00331971\tvalid_1's l1: 0.185547\n",
            "[3600]\ttraining's l1: 0.00293746\tvalid_1's l1: 0.185464\n",
            "[3800]\ttraining's l1: 0.00261251\tvalid_1's l1: 0.185402\n",
            "[4000]\ttraining's l1: 0.00234061\tvalid_1's l1: 0.185384\n",
            "[4200]\ttraining's l1: 0.00211957\tvalid_1's l1: 0.185357\n",
            "[4400]\ttraining's l1: 0.00193615\tvalid_1's l1: 0.185336\n",
            "[4600]\ttraining's l1: 0.00175477\tvalid_1's l1: 0.185308\n",
            "[4800]\ttraining's l1: 0.00161364\tvalid_1's l1: 0.185296\n",
            "[5000]\ttraining's l1: 0.00149899\tvalid_1's l1: 0.185257\n",
            "[5200]\ttraining's l1: 0.00138081\tvalid_1's l1: 0.185237\n",
            "[5400]\ttraining's l1: 0.00128501\tvalid_1's l1: 0.185215\n",
            "[5600]\ttraining's l1: 0.00118726\tvalid_1's l1: 0.185203\n",
            "[5800]\ttraining's l1: 0.00110184\tvalid_1's l1: 0.18522\n",
            "Early stopping, best iteration is:\n",
            "[5716]\ttraining's l1: 0.00114131\tvalid_1's l1: 0.185202\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.155021\tvalid_1's l1: 0.223565\n",
            "[400]\ttraining's l1: 0.0993649\tvalid_1's l1: 0.208517\n",
            "[600]\ttraining's l1: 0.0701971\tvalid_1's l1: 0.200099\n",
            "[800]\ttraining's l1: 0.0512457\tvalid_1's l1: 0.193529\n",
            "[1000]\ttraining's l1: 0.038003\tvalid_1's l1: 0.188477\n",
            "[1200]\ttraining's l1: 0.0286079\tvalid_1's l1: 0.185157\n",
            "[1400]\ttraining's l1: 0.0218418\tvalid_1's l1: 0.182553\n",
            "[1600]\ttraining's l1: 0.0167472\tvalid_1's l1: 0.181044\n",
            "[1800]\ttraining's l1: 0.0131643\tvalid_1's l1: 0.179825\n",
            "[2000]\ttraining's l1: 0.0104696\tvalid_1's l1: 0.178949\n",
            "[2200]\ttraining's l1: 0.00852275\tvalid_1's l1: 0.17829\n",
            "[2400]\ttraining's l1: 0.00710302\tvalid_1's l1: 0.177826\n",
            "[2600]\ttraining's l1: 0.00595397\tvalid_1's l1: 0.17752\n",
            "[2800]\ttraining's l1: 0.00501526\tvalid_1's l1: 0.177274\n",
            "[3000]\ttraining's l1: 0.00426866\tvalid_1's l1: 0.177119\n",
            "[3200]\ttraining's l1: 0.00368329\tvalid_1's l1: 0.176926\n",
            "[3400]\ttraining's l1: 0.0032082\tvalid_1's l1: 0.176822\n",
            "[3600]\ttraining's l1: 0.0028057\tvalid_1's l1: 0.176745\n",
            "[3800]\ttraining's l1: 0.00247967\tvalid_1's l1: 0.176687\n",
            "[4000]\ttraining's l1: 0.00221082\tvalid_1's l1: 0.176603\n",
            "[4200]\ttraining's l1: 0.00198018\tvalid_1's l1: 0.176577\n",
            "[4400]\ttraining's l1: 0.00178657\tvalid_1's l1: 0.176547\n",
            "[4600]\ttraining's l1: 0.00162452\tvalid_1's l1: 0.176534\n",
            "[4800]\ttraining's l1: 0.00148714\tvalid_1's l1: 0.176515\n",
            "[5000]\ttraining's l1: 0.00136058\tvalid_1's l1: 0.17649\n",
            "[5200]\ttraining's l1: 0.00125646\tvalid_1's l1: 0.176488\n",
            "[5400]\ttraining's l1: 0.00116073\tvalid_1's l1: 0.176476\n",
            "[5600]\ttraining's l1: 0.00107715\tvalid_1's l1: 0.176469\n",
            "[5800]\ttraining's l1: 0.000997449\tvalid_1's l1: 0.176461\n",
            "[6000]\ttraining's l1: 0.00091972\tvalid_1's l1: 0.176451\n",
            "[6200]\ttraining's l1: 0.000848188\tvalid_1's l1: 0.176449\n",
            "Early stopping, best iteration is:\n",
            "[6175]\ttraining's l1: 0.000853862\tvalid_1's l1: 0.176444\n",
            "\n",
            "✅ CV MAE: 0.1760691732\n",
            "✅ submission_stable_final12.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 전처리 + 파생변수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 문자열 컬럼 숫자화\n",
        "    activity_map = {'light':1, 'moderate':2, 'intense':3}\n",
        "    sleep_map    = {'sleep difficulty':1, 'normal':2, 'oversleeping':3}\n",
        "\n",
        "    for df in [train, test]:\n",
        "        df[\"activity_num\"] = df.get(\"activity\", \"\").map(activity_map).fillna(2)\n",
        "        df[\"sleep_num\"] = df.get(\"sleep_pattern\", \"\").map(sleep_map).fillna(2)\n",
        "        df[\"activity_sleep\"] = df[\"activity_num\"] * df[\"sleep_num\"]\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / df[\"diastolic_blood_pressure\"]\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / df[\"weight\"]\n",
        "\n",
        "    # 결측치 처리\n",
        "    for col in num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"]:\n",
        "        mean_val = train[col].mean()\n",
        "        train[col] = train[col].fillna(mean_val)\n",
        "        test[col]  = test[col].fillna(mean_val)\n",
        "\n",
        "    # 범주형 Target Encoding\n",
        "    for col in cat_cols:\n",
        "        mapping = train.groupby(col)[target_col].mean()\n",
        "        train[col+\"_TE\"] = train[col].map(mapping)\n",
        "        test[col+\"_TE\"]  = test[col].map(mapping)\n",
        "\n",
        "    # Label Encoding\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "        le.fit(combined)\n",
        "        train[col+\"_LE\"] = le.transform(train[col].astype(str))\n",
        "        test[col+\"_LE\"]  = le.transform(test[col].astype(str))\n",
        "\n",
        "    features = num_cols + [\"BMI\",\"bp_ratio\",\"activity_sleep\",\"age_weight_ratio\"] + [c+\"_TE\" for c in cat_cols] + [c+\"_LE\" for c in cat_cols]\n",
        "    X = train[features]\n",
        "    y = train[target_col]\n",
        "    test_final = test[features]\n",
        "    return X, y, test_final, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 모델 학습 + 앙상블\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds_lgb = np.zeros(len(test))\n",
        "    test_preds_et  = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 63,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        model_lgb = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=200)]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n",
        "        test_preds_lgb += model_lgb.predict(test, num_iteration=model_lgb.best_iteration) / n_splits\n",
        "\n",
        "        # ExtraTrees\n",
        "        model_et = ExtraTreesRegressor(n_estimators=500, max_depth=12, random_state=seed)\n",
        "        model_et.fit(X_train, y_train)\n",
        "        test_preds_et += model_et.predict(test) / n_splits\n",
        "\n",
        "    test_preds = (test_preds_lgb + test_preds_et)/2\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_stable13.csv\", index=False)\n",
        "    print(\"✅ submission_stable13.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 전체 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgXXXZHoEMqU",
        "outputId": "28ec188f-7c12-42af-c1cb-581b4828a322"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.155613\tvalid_1's l1: 0.212978\n",
            "[400]\ttraining's l1: 0.107217\tvalid_1's l1: 0.199495\n",
            "[600]\ttraining's l1: 0.0749955\tvalid_1's l1: 0.188332\n",
            "[800]\ttraining's l1: 0.0534595\tvalid_1's l1: 0.180539\n",
            "[1000]\ttraining's l1: 0.0392856\tvalid_1's l1: 0.175584\n",
            "[1200]\ttraining's l1: 0.0302429\tvalid_1's l1: 0.172183\n",
            "[1400]\ttraining's l1: 0.0231905\tvalid_1's l1: 0.169718\n",
            "[1600]\ttraining's l1: 0.0179688\tvalid_1's l1: 0.167517\n",
            "[1800]\ttraining's l1: 0.0139769\tvalid_1's l1: 0.166126\n",
            "[2000]\ttraining's l1: 0.0110618\tvalid_1's l1: 0.165207\n",
            "[2200]\ttraining's l1: 0.00882452\tvalid_1's l1: 0.164635\n",
            "[2400]\ttraining's l1: 0.00728902\tvalid_1's l1: 0.164202\n",
            "[2600]\ttraining's l1: 0.00601608\tvalid_1's l1: 0.163846\n",
            "[2800]\ttraining's l1: 0.00506943\tvalid_1's l1: 0.16352\n",
            "[3000]\ttraining's l1: 0.00432016\tvalid_1's l1: 0.163412\n",
            "[3200]\ttraining's l1: 0.00374967\tvalid_1's l1: 0.163308\n",
            "[3400]\ttraining's l1: 0.0033045\tvalid_1's l1: 0.163204\n",
            "[3600]\ttraining's l1: 0.0028994\tvalid_1's l1: 0.163089\n",
            "[3800]\ttraining's l1: 0.00255735\tvalid_1's l1: 0.163021\n",
            "[4000]\ttraining's l1: 0.00228861\tvalid_1's l1: 0.162986\n",
            "[4200]\ttraining's l1: 0.00208119\tvalid_1's l1: 0.162911\n",
            "[4400]\ttraining's l1: 0.00189288\tvalid_1's l1: 0.162883\n",
            "[4600]\ttraining's l1: 0.00170278\tvalid_1's l1: 0.162858\n",
            "[4800]\ttraining's l1: 0.00156232\tvalid_1's l1: 0.162837\n",
            "[5000]\ttraining's l1: 0.00143218\tvalid_1's l1: 0.16283\n",
            "[5200]\ttraining's l1: 0.00131016\tvalid_1's l1: 0.162817\n",
            "[5400]\ttraining's l1: 0.00121221\tvalid_1's l1: 0.16281\n",
            "Early stopping, best iteration is:\n",
            "[5350]\ttraining's l1: 0.00123607\tvalid_1's l1: 0.162803\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.149782\tvalid_1's l1: 0.216053\n",
            "[400]\ttraining's l1: 0.0952956\tvalid_1's l1: 0.20039\n",
            "[600]\ttraining's l1: 0.0665284\tvalid_1's l1: 0.193162\n",
            "[800]\ttraining's l1: 0.047391\tvalid_1's l1: 0.188114\n",
            "[1000]\ttraining's l1: 0.035414\tvalid_1's l1: 0.184426\n",
            "[1200]\ttraining's l1: 0.026534\tvalid_1's l1: 0.181892\n",
            "[1400]\ttraining's l1: 0.0199529\tvalid_1's l1: 0.179689\n",
            "[1600]\ttraining's l1: 0.0155268\tvalid_1's l1: 0.178248\n",
            "[1800]\ttraining's l1: 0.0122329\tvalid_1's l1: 0.177325\n",
            "[2000]\ttraining's l1: 0.00985951\tvalid_1's l1: 0.176646\n",
            "[2200]\ttraining's l1: 0.00816911\tvalid_1's l1: 0.176183\n",
            "[2400]\ttraining's l1: 0.00676571\tvalid_1's l1: 0.175825\n",
            "[2600]\ttraining's l1: 0.00562027\tvalid_1's l1: 0.175476\n",
            "[2800]\ttraining's l1: 0.00482019\tvalid_1's l1: 0.175314\n",
            "[3000]\ttraining's l1: 0.00414491\tvalid_1's l1: 0.175147\n",
            "[3200]\ttraining's l1: 0.00363\tvalid_1's l1: 0.175028\n",
            "[3400]\ttraining's l1: 0.00317774\tvalid_1's l1: 0.17491\n",
            "[3600]\ttraining's l1: 0.0028191\tvalid_1's l1: 0.174816\n",
            "[3800]\ttraining's l1: 0.00249347\tvalid_1's l1: 0.174769\n",
            "[4000]\ttraining's l1: 0.002241\tvalid_1's l1: 0.174734\n",
            "[4200]\ttraining's l1: 0.00200981\tvalid_1's l1: 0.174688\n",
            "[4400]\ttraining's l1: 0.00182054\tvalid_1's l1: 0.17464\n",
            "[4600]\ttraining's l1: 0.00165208\tvalid_1's l1: 0.174627\n",
            "[4800]\ttraining's l1: 0.00151308\tvalid_1's l1: 0.174611\n",
            "[5000]\ttraining's l1: 0.00137655\tvalid_1's l1: 0.174593\n",
            "[5200]\ttraining's l1: 0.00126289\tvalid_1's l1: 0.174587\n",
            "[5400]\ttraining's l1: 0.00116472\tvalid_1's l1: 0.174561\n",
            "[5600]\ttraining's l1: 0.001078\tvalid_1's l1: 0.174554\n",
            "[5800]\ttraining's l1: 0.00100431\tvalid_1's l1: 0.174534\n",
            "[6000]\ttraining's l1: 0.000936581\tvalid_1's l1: 0.174534\n",
            "[6200]\ttraining's l1: 0.000868435\tvalid_1's l1: 0.174532\n",
            "[6400]\ttraining's l1: 0.000810411\tvalid_1's l1: 0.174526\n",
            "[6600]\ttraining's l1: 0.000753413\tvalid_1's l1: 0.17452\n",
            "[6800]\ttraining's l1: 0.000706103\tvalid_1's l1: 0.17451\n",
            "[7000]\ttraining's l1: 0.000660138\tvalid_1's l1: 0.174499\n",
            "[7200]\ttraining's l1: 0.000618713\tvalid_1's l1: 0.174493\n",
            "[7400]\ttraining's l1: 0.000579137\tvalid_1's l1: 0.174492\n",
            "[7600]\ttraining's l1: 0.000539025\tvalid_1's l1: 0.174489\n",
            "[7800]\ttraining's l1: 0.000507462\tvalid_1's l1: 0.174487\n",
            "[8000]\ttraining's l1: 0.000477621\tvalid_1's l1: 0.17448\n",
            "[8200]\ttraining's l1: 0.000451033\tvalid_1's l1: 0.174472\n",
            "[8400]\ttraining's l1: 0.00042236\tvalid_1's l1: 0.174465\n",
            "[8600]\ttraining's l1: 0.000396992\tvalid_1's l1: 0.174464\n",
            "[8800]\ttraining's l1: 0.000374611\tvalid_1's l1: 0.174461\n",
            "[9000]\ttraining's l1: 0.000352708\tvalid_1's l1: 0.174461\n",
            "Early stopping, best iteration is:\n",
            "[8845]\ttraining's l1: 0.000368018\tvalid_1's l1: 0.174459\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.149523\tvalid_1's l1: 0.226459\n",
            "[400]\ttraining's l1: 0.0993384\tvalid_1's l1: 0.212075\n",
            "[600]\ttraining's l1: 0.0697624\tvalid_1's l1: 0.203611\n",
            "[800]\ttraining's l1: 0.0510011\tvalid_1's l1: 0.197866\n",
            "[1000]\ttraining's l1: 0.0378587\tvalid_1's l1: 0.193444\n",
            "[1200]\ttraining's l1: 0.0280923\tvalid_1's l1: 0.190061\n",
            "[1400]\ttraining's l1: 0.0216108\tvalid_1's l1: 0.187682\n",
            "[1600]\ttraining's l1: 0.0167513\tvalid_1's l1: 0.186022\n",
            "[1800]\ttraining's l1: 0.01328\tvalid_1's l1: 0.184617\n",
            "[2000]\ttraining's l1: 0.0106209\tvalid_1's l1: 0.183704\n",
            "[2200]\ttraining's l1: 0.00854212\tvalid_1's l1: 0.182988\n",
            "[2400]\ttraining's l1: 0.00699339\tvalid_1's l1: 0.182582\n",
            "[2600]\ttraining's l1: 0.00582904\tvalid_1's l1: 0.182272\n",
            "[2800]\ttraining's l1: 0.00494334\tvalid_1's l1: 0.182102\n",
            "[3000]\ttraining's l1: 0.00422401\tvalid_1's l1: 0.181946\n",
            "[3200]\ttraining's l1: 0.00366422\tvalid_1's l1: 0.181834\n",
            "[3400]\ttraining's l1: 0.00321357\tvalid_1's l1: 0.181719\n",
            "[3600]\ttraining's l1: 0.00285132\tvalid_1's l1: 0.181606\n",
            "[3800]\ttraining's l1: 0.00252496\tvalid_1's l1: 0.181531\n",
            "[4000]\ttraining's l1: 0.0022679\tvalid_1's l1: 0.181506\n",
            "[4200]\ttraining's l1: 0.00205052\tvalid_1's l1: 0.181481\n",
            "[4400]\ttraining's l1: 0.00183339\tvalid_1's l1: 0.181433\n",
            "[4600]\ttraining's l1: 0.00166166\tvalid_1's l1: 0.1814\n",
            "[4800]\ttraining's l1: 0.00153808\tvalid_1's l1: 0.181385\n",
            "[5000]\ttraining's l1: 0.00141422\tvalid_1's l1: 0.181371\n",
            "[5200]\ttraining's l1: 0.00129689\tvalid_1's l1: 0.181372\n",
            "Early stopping, best iteration is:\n",
            "[5095]\ttraining's l1: 0.00136509\tvalid_1's l1: 0.181362\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.148477\tvalid_1's l1: 0.230644\n",
            "[400]\ttraining's l1: 0.0974441\tvalid_1's l1: 0.216549\n",
            "[600]\ttraining's l1: 0.0685655\tvalid_1's l1: 0.208196\n",
            "[800]\ttraining's l1: 0.0495894\tvalid_1's l1: 0.201453\n",
            "[1000]\ttraining's l1: 0.0371765\tvalid_1's l1: 0.196782\n",
            "[1200]\ttraining's l1: 0.0279966\tvalid_1's l1: 0.193097\n",
            "[1400]\ttraining's l1: 0.0211441\tvalid_1's l1: 0.19091\n",
            "[1600]\ttraining's l1: 0.0166042\tvalid_1's l1: 0.189208\n",
            "[1800]\ttraining's l1: 0.0132414\tvalid_1's l1: 0.188163\n",
            "[2000]\ttraining's l1: 0.0104309\tvalid_1's l1: 0.187358\n",
            "[2200]\ttraining's l1: 0.00852616\tvalid_1's l1: 0.186726\n",
            "[2400]\ttraining's l1: 0.006994\tvalid_1's l1: 0.186385\n",
            "[2600]\ttraining's l1: 0.00580363\tvalid_1's l1: 0.186081\n",
            "[2800]\ttraining's l1: 0.00496521\tvalid_1's l1: 0.185868\n",
            "[3000]\ttraining's l1: 0.00427756\tvalid_1's l1: 0.185728\n",
            "[3200]\ttraining's l1: 0.00377661\tvalid_1's l1: 0.185603\n",
            "[3400]\ttraining's l1: 0.00331971\tvalid_1's l1: 0.185507\n",
            "[3600]\ttraining's l1: 0.00293746\tvalid_1's l1: 0.185423\n",
            "[3800]\ttraining's l1: 0.00261251\tvalid_1's l1: 0.185361\n",
            "[4000]\ttraining's l1: 0.00234061\tvalid_1's l1: 0.185343\n",
            "[4200]\ttraining's l1: 0.00211957\tvalid_1's l1: 0.185316\n",
            "[4400]\ttraining's l1: 0.00193615\tvalid_1's l1: 0.185295\n",
            "[4600]\ttraining's l1: 0.00175477\tvalid_1's l1: 0.185267\n",
            "[4800]\ttraining's l1: 0.00161364\tvalid_1's l1: 0.185255\n",
            "[5000]\ttraining's l1: 0.00149899\tvalid_1's l1: 0.185216\n",
            "[5200]\ttraining's l1: 0.00138081\tvalid_1's l1: 0.185196\n",
            "[5400]\ttraining's l1: 0.00128501\tvalid_1's l1: 0.185173\n",
            "[5600]\ttraining's l1: 0.00118726\tvalid_1's l1: 0.185162\n",
            "[5800]\ttraining's l1: 0.00110184\tvalid_1's l1: 0.185179\n",
            "Early stopping, best iteration is:\n",
            "[5716]\ttraining's l1: 0.00114131\tvalid_1's l1: 0.185161\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttraining's l1: 0.155021\tvalid_1's l1: 0.223551\n",
            "[400]\ttraining's l1: 0.0993649\tvalid_1's l1: 0.208502\n",
            "[600]\ttraining's l1: 0.0701971\tvalid_1's l1: 0.200084\n",
            "[800]\ttraining's l1: 0.0512457\tvalid_1's l1: 0.193514\n",
            "[1000]\ttraining's l1: 0.038003\tvalid_1's l1: 0.188464\n",
            "[1200]\ttraining's l1: 0.0286079\tvalid_1's l1: 0.185147\n",
            "[1400]\ttraining's l1: 0.0218418\tvalid_1's l1: 0.182544\n",
            "[1600]\ttraining's l1: 0.0167472\tvalid_1's l1: 0.181032\n",
            "[1800]\ttraining's l1: 0.0131643\tvalid_1's l1: 0.179812\n",
            "[2000]\ttraining's l1: 0.0104696\tvalid_1's l1: 0.178937\n",
            "[2200]\ttraining's l1: 0.00852275\tvalid_1's l1: 0.178277\n",
            "[2400]\ttraining's l1: 0.00710302\tvalid_1's l1: 0.177815\n",
            "[2600]\ttraining's l1: 0.00595397\tvalid_1's l1: 0.177509\n",
            "[2800]\ttraining's l1: 0.00501526\tvalid_1's l1: 0.177263\n",
            "[3000]\ttraining's l1: 0.00426866\tvalid_1's l1: 0.177108\n",
            "[3200]\ttraining's l1: 0.00368329\tvalid_1's l1: 0.176915\n",
            "[3400]\ttraining's l1: 0.0032082\tvalid_1's l1: 0.176811\n",
            "[3600]\ttraining's l1: 0.0028057\tvalid_1's l1: 0.176734\n",
            "[3800]\ttraining's l1: 0.00247967\tvalid_1's l1: 0.176676\n",
            "[4000]\ttraining's l1: 0.00221082\tvalid_1's l1: 0.176592\n",
            "[4200]\ttraining's l1: 0.00198018\tvalid_1's l1: 0.176566\n",
            "[4400]\ttraining's l1: 0.00178657\tvalid_1's l1: 0.176537\n",
            "[4600]\ttraining's l1: 0.00162452\tvalid_1's l1: 0.176523\n",
            "[4800]\ttraining's l1: 0.00148714\tvalid_1's l1: 0.176505\n",
            "[5000]\ttraining's l1: 0.00136058\tvalid_1's l1: 0.17648\n",
            "[5200]\ttraining's l1: 0.00125646\tvalid_1's l1: 0.176476\n",
            "[5400]\ttraining's l1: 0.00116073\tvalid_1's l1: 0.176465\n",
            "[5600]\ttraining's l1: 0.00107715\tvalid_1's l1: 0.176458\n",
            "[5800]\ttraining's l1: 0.000997449\tvalid_1's l1: 0.17645\n",
            "[6000]\ttraining's l1: 0.00091972\tvalid_1's l1: 0.17644\n",
            "[6200]\ttraining's l1: 0.000848188\tvalid_1's l1: 0.176438\n",
            "Early stopping, best iteration is:\n",
            "[6175]\ttraining's l1: 0.000853862\tvalid_1's l1: 0.176433\n",
            "\n",
            "✅ CV MAE: 0.1760435171\n",
            "✅ submission_stable13.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드 함수\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수 함수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 존재하지 않습니다.\")\n",
        "\n",
        "    # ID 제거\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id = train[\"ID\"]\n",
        "        test_id = test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 숫자 / 범주형 컬럼 구분\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 숫자 컬럼 변환\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "\n",
        "    # 범주형 결측치 처리\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode)\n",
        "        test[col]  = test[col].fillna(mode)\n",
        "\n",
        "    # 파생변수 생성\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2 + 1e-6)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / (df[\"diastolic_blood_pressure\"] + 1e-6)\n",
        "        df[\"activity_sleep\"] = pd.to_numeric(df[\"activity\"], errors=\"coerce\").fillna(0) * pd.to_numeric(df[\"sleep_pattern\"], errors=\"coerce\").fillna(0)\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / (df[\"weight\"] + 1e-6)\n",
        "\n",
        "    # 범주형 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 + 예측 (KFold + LGBM)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"num_leaves\": 50,\n",
        "            \"feature_fraction\": 0.9,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=100),\n",
        "                log_evaluation(period=200)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        test_preds += model.predict(test, num_iteration=model.best_iteration) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_stable114.csv\", index=False)\n",
        "    print(\"✅ submission_stable14.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 파이프라인 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxEjvez0Bo3e",
        "outputId": "171324d8-3a9b-4d1a-a938-4ec6a3fa44de"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0780643\tvalid_1's l1: 0.19049\n",
            "[400]\ttraining's l1: 0.0346026\tvalid_1's l1: 0.176302\n",
            "[600]\ttraining's l1: 0.0181017\tvalid_1's l1: 0.170847\n",
            "[800]\ttraining's l1: 0.0103361\tvalid_1's l1: 0.168592\n",
            "[1000]\ttraining's l1: 0.00635712\tvalid_1's l1: 0.167532\n",
            "[1200]\ttraining's l1: 0.0041836\tvalid_1's l1: 0.167075\n",
            "[1400]\ttraining's l1: 0.00292437\tvalid_1's l1: 0.16676\n",
            "[1600]\ttraining's l1: 0.00213607\tvalid_1's l1: 0.166582\n",
            "[1800]\ttraining's l1: 0.00161625\tvalid_1's l1: 0.166482\n",
            "[2000]\ttraining's l1: 0.00125822\tvalid_1's l1: 0.166432\n",
            "[2200]\ttraining's l1: 0.00100079\tvalid_1's l1: 0.166377\n",
            "[2400]\ttraining's l1: 0.000808962\tvalid_1's l1: 0.166356\n",
            "[2600]\ttraining's l1: 0.000657053\tvalid_1's l1: 0.166334\n",
            "Early stopping, best iteration is:\n",
            "[2620]\ttraining's l1: 0.000643373\tvalid_1's l1: 0.166328\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0776078\tvalid_1's l1: 0.196613\n",
            "[400]\ttraining's l1: 0.0333898\tvalid_1's l1: 0.183926\n",
            "[600]\ttraining's l1: 0.0172884\tvalid_1's l1: 0.179411\n",
            "[800]\ttraining's l1: 0.0098839\tvalid_1's l1: 0.177398\n",
            "[1000]\ttraining's l1: 0.00615824\tvalid_1's l1: 0.17661\n",
            "[1200]\ttraining's l1: 0.00411451\tvalid_1's l1: 0.176172\n",
            "[1400]\ttraining's l1: 0.00288549\tvalid_1's l1: 0.175963\n",
            "[1600]\ttraining's l1: 0.0021165\tvalid_1's l1: 0.175778\n",
            "[1800]\ttraining's l1: 0.00160249\tvalid_1's l1: 0.17568\n",
            "[2000]\ttraining's l1: 0.00123731\tvalid_1's l1: 0.175635\n",
            "[2200]\ttraining's l1: 0.000986498\tvalid_1's l1: 0.175607\n",
            "[2400]\ttraining's l1: 0.000792388\tvalid_1's l1: 0.175575\n",
            "[2600]\ttraining's l1: 0.000641793\tvalid_1's l1: 0.175559\n",
            "[2800]\ttraining's l1: 0.000524264\tvalid_1's l1: 0.175543\n",
            "[3000]\ttraining's l1: 0.000429395\tvalid_1's l1: 0.175531\n",
            "Early stopping, best iteration is:\n",
            "[3005]\ttraining's l1: 0.000427074\tvalid_1's l1: 0.175529\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0759263\tvalid_1's l1: 0.2054\n",
            "[400]\ttraining's l1: 0.0335268\tvalid_1's l1: 0.19164\n",
            "[600]\ttraining's l1: 0.0173527\tvalid_1's l1: 0.186354\n",
            "[800]\ttraining's l1: 0.00998477\tvalid_1's l1: 0.184003\n",
            "[1000]\ttraining's l1: 0.00618225\tvalid_1's l1: 0.182921\n",
            "[1200]\ttraining's l1: 0.00405699\tvalid_1's l1: 0.182449\n",
            "[1400]\ttraining's l1: 0.00284016\tvalid_1's l1: 0.182211\n",
            "[1600]\ttraining's l1: 0.0020873\tvalid_1's l1: 0.18211\n",
            "[1800]\ttraining's l1: 0.00158847\tvalid_1's l1: 0.182025\n",
            "[2000]\ttraining's l1: 0.00123027\tvalid_1's l1: 0.181986\n",
            "[2200]\ttraining's l1: 0.000978358\tvalid_1's l1: 0.181939\n",
            "Early stopping, best iteration is:\n",
            "[2264]\ttraining's l1: 0.000914568\tvalid_1's l1: 0.18193\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0754637\tvalid_1's l1: 0.212622\n",
            "[400]\ttraining's l1: 0.0335202\tvalid_1's l1: 0.19771\n",
            "[600]\ttraining's l1: 0.0171359\tvalid_1's l1: 0.191141\n",
            "[800]\ttraining's l1: 0.00974088\tvalid_1's l1: 0.188559\n",
            "[1000]\ttraining's l1: 0.0059737\tvalid_1's l1: 0.187377\n",
            "[1200]\ttraining's l1: 0.00392901\tvalid_1's l1: 0.18691\n",
            "[1400]\ttraining's l1: 0.00270787\tvalid_1's l1: 0.186668\n",
            "[1600]\ttraining's l1: 0.00195341\tvalid_1's l1: 0.186499\n",
            "[1800]\ttraining's l1: 0.00146318\tvalid_1's l1: 0.186455\n",
            "Early stopping, best iteration is:\n",
            "[1783]\ttraining's l1: 0.0014975\tvalid_1's l1: 0.186448\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0770097\tvalid_1's l1: 0.196466\n",
            "[400]\ttraining's l1: 0.0343756\tvalid_1's l1: 0.181077\n",
            "[600]\ttraining's l1: 0.017781\tvalid_1's l1: 0.175399\n",
            "[800]\ttraining's l1: 0.0101541\tvalid_1's l1: 0.172726\n",
            "[1000]\ttraining's l1: 0.00623303\tvalid_1's l1: 0.171875\n",
            "[1200]\ttraining's l1: 0.00403683\tvalid_1's l1: 0.171293\n",
            "[1400]\ttraining's l1: 0.00278725\tvalid_1's l1: 0.170993\n",
            "[1600]\ttraining's l1: 0.00201843\tvalid_1's l1: 0.170838\n",
            "[1800]\ttraining's l1: 0.00151981\tvalid_1's l1: 0.170737\n",
            "[2000]\ttraining's l1: 0.00117919\tvalid_1's l1: 0.170679\n",
            "[2200]\ttraining's l1: 0.000938194\tvalid_1's l1: 0.170618\n",
            "[2400]\ttraining's l1: 0.000751093\tvalid_1's l1: 0.170593\n",
            "[2600]\ttraining's l1: 0.000607787\tvalid_1's l1: 0.17057\n",
            "[2800]\ttraining's l1: 0.00050067\tvalid_1's l1: 0.170562\n",
            "[3000]\ttraining's l1: 0.000413044\tvalid_1's l1: 0.170541\n",
            "[3200]\ttraining's l1: 0.00034484\tvalid_1's l1: 0.170534\n",
            "[3400]\ttraining's l1: 0.000287495\tvalid_1's l1: 0.170523\n",
            "[3600]\ttraining's l1: 0.000241552\tvalid_1's l1: 0.170519\n",
            "Early stopping, best iteration is:\n",
            "[3550]\ttraining's l1: 0.000252922\tvalid_1's l1: 0.170517\n",
            "\n",
            "✅ CV MAE: 0.1761505871\n",
            "✅ submission_stable14.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드 함수\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    if target_col not in train.columns:\n",
        "        raise ValueError(f\"{target_col} 컬럼이 train 데이터에 존재하지 않습니다.\")\n",
        "\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id = train[\"ID\"]\n",
        "        test_id = test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 숫자 / 범주형 컬럼 구분\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 숫자 컬럼 처리\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "        test[col] = pd.to_numeric(test[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "\n",
        "    # 범주형 결측치 처리\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode)\n",
        "        test[col] = test[col].fillna(mode)\n",
        "\n",
        "    # 파생변수\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2 + 1e-6)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / (df[\"diastolic_blood_pressure\"] + 1e-6)\n",
        "        df[\"activity_sleep\"] = pd.to_numeric(df[\"activity\"], errors=\"coerce\").fillna(0) * pd.to_numeric(df[\"sleep_pattern\"], errors=\"coerce\").fillna(0)\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / (df[\"weight\"] + 1e-6)\n",
        "\n",
        "    # 범주형 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = np.log1p(train[target_col])  # target scaling\n",
        "\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 + 예측 (LGBM + ExtraTrees)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        lgb_params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 64,\n",
        "            \"feature_fraction\": 0.9,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        lgb_model = lgb.train(\n",
        "            lgb_params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=500)]\n",
        "        )\n",
        "        lgb_val_pred = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
        "        lgb_test_pred = lgb_model.predict(test, num_iteration=lgb_model.best_iteration)\n",
        "\n",
        "        # ExtraTrees\n",
        "        et_model = ExtraTreesRegressor(n_estimators=500, random_state=seed, n_jobs=-1)\n",
        "        et_model.fit(X_train, y_train)\n",
        "        et_val_pred = et_model.predict(X_val)\n",
        "        et_test_pred = et_model.predict(test)\n",
        "\n",
        "        # Fold 별 앙상블 (0.6 LGBM + 0.4 ET)\n",
        "        val_pred = 0.6*lgb_val_pred + 0.4*et_val_pred\n",
        "        test_pred = 0.6*lgb_test_pred + 0.4*et_test_pred\n",
        "\n",
        "        oof_preds[val_idx] = val_pred\n",
        "        test_preds += test_pred / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(np.expm1(y), np.expm1(oof_preds))  # 스케일 원복\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return np.expm1(test_preds)  # 제출용 스케일 원복\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_stable15.csv\", index=False)\n",
        "    print(\"✅ submission_stable15.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 파이프라인 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUOgxsNYBo0-",
        "outputId": "b57a411a-6b87-4aa5-c703-edee0cea1afe"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[500]\ttraining's l1: 0.0250615\tvalid_1's l1: 0.121009\n",
            "[1000]\ttraining's l1: 0.00739319\tvalid_1's l1: 0.114673\n",
            "[1500]\ttraining's l1: 0.00296279\tvalid_1's l1: 0.113084\n",
            "[2000]\ttraining's l1: 0.00146787\tvalid_1's l1: 0.112659\n",
            "[2500]\ttraining's l1: 0.000851143\tvalid_1's l1: 0.112519\n",
            "[3000]\ttraining's l1: 0.000546174\tvalid_1's l1: 0.112475\n",
            "Early stopping, best iteration is:\n",
            "[3271]\ttraining's l1: 0.000439186\tvalid_1's l1: 0.112465\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[500]\ttraining's l1: 0.0236695\tvalid_1's l1: 0.126254\n",
            "[1000]\ttraining's l1: 0.00688538\tvalid_1's l1: 0.120121\n",
            "[1500]\ttraining's l1: 0.00283079\tvalid_1's l1: 0.118793\n",
            "[2000]\ttraining's l1: 0.00142387\tvalid_1's l1: 0.118457\n",
            "[2500]\ttraining's l1: 0.000825909\tvalid_1's l1: 0.118346\n",
            "[3000]\ttraining's l1: 0.000518465\tvalid_1's l1: 0.118305\n",
            "Early stopping, best iteration is:\n",
            "[3320]\ttraining's l1: 0.000400992\tvalid_1's l1: 0.118285\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[500]\ttraining's l1: 0.0242854\tvalid_1's l1: 0.131861\n",
            "[1000]\ttraining's l1: 0.00714102\tvalid_1's l1: 0.126153\n",
            "[1500]\ttraining's l1: 0.00290468\tvalid_1's l1: 0.124699\n",
            "[2000]\ttraining's l1: 0.0014656\tvalid_1's l1: 0.1243\n",
            "[2500]\ttraining's l1: 0.00085245\tvalid_1's l1: 0.124155\n",
            "[3000]\ttraining's l1: 0.000541325\tvalid_1's l1: 0.124091\n",
            "[3500]\ttraining's l1: 0.000367688\tvalid_1's l1: 0.124067\n",
            "[4000]\ttraining's l1: 0.000260079\tvalid_1's l1: 0.124054\n",
            "Early stopping, best iteration is:\n",
            "[4087]\ttraining's l1: 0.000245614\tvalid_1's l1: 0.124051\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[500]\ttraining's l1: 0.0236516\tvalid_1's l1: 0.131885\n",
            "[1000]\ttraining's l1: 0.00699479\tvalid_1's l1: 0.126065\n",
            "[1500]\ttraining's l1: 0.00282875\tvalid_1's l1: 0.124825\n",
            "[2000]\ttraining's l1: 0.00141645\tvalid_1's l1: 0.124537\n",
            "[2500]\ttraining's l1: 0.000818417\tvalid_1's l1: 0.124467\n",
            "Early stopping, best iteration is:\n",
            "[2650]\ttraining's l1: 0.000704067\tvalid_1's l1: 0.124448\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[500]\ttraining's l1: 0.0242555\tvalid_1's l1: 0.12744\n",
            "[1000]\ttraining's l1: 0.00722835\tvalid_1's l1: 0.120949\n",
            "[1500]\ttraining's l1: 0.00296647\tvalid_1's l1: 0.119549\n",
            "[2000]\ttraining's l1: 0.00152569\tvalid_1's l1: 0.119179\n",
            "[2500]\ttraining's l1: 0.000888013\tvalid_1's l1: 0.119032\n",
            "[3000]\ttraining's l1: 0.000570198\tvalid_1's l1: 0.118972\n",
            "Early stopping, best iteration is:\n",
            "[3231]\ttraining's l1: 0.000473754\tvalid_1's l1: 0.118957\n",
            "\n",
            "✅ CV MAE: 0.1755371081\n",
            "✅ submission_stable15.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로 설정\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id = train[\"ID\"]\n",
        "        test_id = test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    # 숫자/범주형 구분\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 숫자 결측치 처리\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "        test[col] = pd.to_numeric(test[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "\n",
        "    # 범주형 결측치 처리\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode)\n",
        "        test[col] = test[col].fillna(mode)\n",
        "\n",
        "    # 파생변수\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2 + 1e-6)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / (df[\"diastolic_blood_pressure\"] + 1e-6)\n",
        "        df[\"activity_sleep\"] = pd.to_numeric(df[\"activity\"], errors=\"coerce\").fillna(0) * pd.to_numeric(df[\"sleep_pattern\"], errors=\"coerce\").fillna(0)\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / (df[\"weight\"] + 1e-6)\n",
        "\n",
        "    # 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 + 예측 (LGBM + ExtraTrees 앙상블)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=5, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        lgb_params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"num_leaves\": 50,\n",
        "            \"feature_fraction\": 0.9,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        lgb_model = lgb.train(\n",
        "            lgb_params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=200)]\n",
        "        )\n",
        "\n",
        "        # ExtraTrees\n",
        "        et_model = ExtraTreesRegressor(\n",
        "            n_estimators=500,\n",
        "            max_depth=None,\n",
        "            min_samples_split=4,\n",
        "            min_samples_leaf=2,\n",
        "            n_jobs=-1,\n",
        "            random_state=seed\n",
        "        )\n",
        "        et_model.fit(X_train, y_train)\n",
        "\n",
        "        # 앙상블 예측\n",
        "        oof_preds[val_idx] += 0.55*lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration) + 0.45*et_model.predict(X_val)\n",
        "        test_preds += (0.55*lgb_model.predict(test, num_iteration=lgb_model.best_iteration) + 0.45*et_model.predict(test)) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 파일 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_stable_no_catboost16.csv\", index=False)\n",
        "    print(\"✅ submission_stable_no_catboost16.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 전체 파이프라인 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=5, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-m3WLsmBoyi",
        "outputId": "f01c2ce8-fbca-4d1e-d642-0b34e03cef39"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0780643\tvalid_1's l1: 0.19049\n",
            "[400]\ttraining's l1: 0.0346026\tvalid_1's l1: 0.176302\n",
            "[600]\ttraining's l1: 0.0181017\tvalid_1's l1: 0.170847\n",
            "[800]\ttraining's l1: 0.0103361\tvalid_1's l1: 0.168592\n",
            "[1000]\ttraining's l1: 0.00635712\tvalid_1's l1: 0.167532\n",
            "[1200]\ttraining's l1: 0.0041836\tvalid_1's l1: 0.167075\n",
            "[1400]\ttraining's l1: 0.00292437\tvalid_1's l1: 0.16676\n",
            "[1600]\ttraining's l1: 0.00213607\tvalid_1's l1: 0.166582\n",
            "[1800]\ttraining's l1: 0.00161625\tvalid_1's l1: 0.166482\n",
            "[2000]\ttraining's l1: 0.00125822\tvalid_1's l1: 0.166432\n",
            "[2200]\ttraining's l1: 0.00100079\tvalid_1's l1: 0.166377\n",
            "[2400]\ttraining's l1: 0.000808962\tvalid_1's l1: 0.166356\n",
            "[2600]\ttraining's l1: 0.000657053\tvalid_1's l1: 0.166334\n",
            "Early stopping, best iteration is:\n",
            "[2620]\ttraining's l1: 0.000643373\tvalid_1's l1: 0.166328\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0776078\tvalid_1's l1: 0.196613\n",
            "[400]\ttraining's l1: 0.0333898\tvalid_1's l1: 0.183926\n",
            "[600]\ttraining's l1: 0.0172884\tvalid_1's l1: 0.179411\n",
            "[800]\ttraining's l1: 0.0098839\tvalid_1's l1: 0.177398\n",
            "[1000]\ttraining's l1: 0.00615824\tvalid_1's l1: 0.17661\n",
            "[1200]\ttraining's l1: 0.00411451\tvalid_1's l1: 0.176172\n",
            "[1400]\ttraining's l1: 0.00288549\tvalid_1's l1: 0.175963\n",
            "[1600]\ttraining's l1: 0.0021165\tvalid_1's l1: 0.175778\n",
            "[1800]\ttraining's l1: 0.00160249\tvalid_1's l1: 0.17568\n",
            "[2000]\ttraining's l1: 0.00123731\tvalid_1's l1: 0.175635\n",
            "[2200]\ttraining's l1: 0.000986498\tvalid_1's l1: 0.175607\n",
            "[2400]\ttraining's l1: 0.000792388\tvalid_1's l1: 0.175575\n",
            "[2600]\ttraining's l1: 0.000641793\tvalid_1's l1: 0.175559\n",
            "[2800]\ttraining's l1: 0.000524264\tvalid_1's l1: 0.175543\n",
            "[3000]\ttraining's l1: 0.000429395\tvalid_1's l1: 0.175531\n",
            "Early stopping, best iteration is:\n",
            "[3005]\ttraining's l1: 0.000427074\tvalid_1's l1: 0.175529\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0759263\tvalid_1's l1: 0.2054\n",
            "[400]\ttraining's l1: 0.0335268\tvalid_1's l1: 0.19164\n",
            "[600]\ttraining's l1: 0.0173527\tvalid_1's l1: 0.186354\n",
            "[800]\ttraining's l1: 0.00998477\tvalid_1's l1: 0.184003\n",
            "[1000]\ttraining's l1: 0.00618225\tvalid_1's l1: 0.182921\n",
            "[1200]\ttraining's l1: 0.00405699\tvalid_1's l1: 0.182449\n",
            "[1400]\ttraining's l1: 0.00284016\tvalid_1's l1: 0.182211\n",
            "[1600]\ttraining's l1: 0.0020873\tvalid_1's l1: 0.18211\n",
            "[1800]\ttraining's l1: 0.00158847\tvalid_1's l1: 0.182025\n",
            "[2000]\ttraining's l1: 0.00123027\tvalid_1's l1: 0.181986\n",
            "[2200]\ttraining's l1: 0.000978358\tvalid_1's l1: 0.181939\n",
            "Early stopping, best iteration is:\n",
            "[2264]\ttraining's l1: 0.000914568\tvalid_1's l1: 0.18193\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0754637\tvalid_1's l1: 0.212622\n",
            "[400]\ttraining's l1: 0.0335202\tvalid_1's l1: 0.19771\n",
            "[600]\ttraining's l1: 0.0171359\tvalid_1's l1: 0.191141\n",
            "[800]\ttraining's l1: 0.00974088\tvalid_1's l1: 0.188559\n",
            "[1000]\ttraining's l1: 0.0059737\tvalid_1's l1: 0.187377\n",
            "[1200]\ttraining's l1: 0.00392901\tvalid_1's l1: 0.18691\n",
            "[1400]\ttraining's l1: 0.00270787\tvalid_1's l1: 0.186668\n",
            "[1600]\ttraining's l1: 0.00195341\tvalid_1's l1: 0.186499\n",
            "[1800]\ttraining's l1: 0.00146318\tvalid_1's l1: 0.186455\n",
            "Early stopping, best iteration is:\n",
            "[1783]\ttraining's l1: 0.0014975\tvalid_1's l1: 0.186448\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.0770097\tvalid_1's l1: 0.196466\n",
            "[400]\ttraining's l1: 0.0343756\tvalid_1's l1: 0.181077\n",
            "[600]\ttraining's l1: 0.017781\tvalid_1's l1: 0.175399\n",
            "[800]\ttraining's l1: 0.0101541\tvalid_1's l1: 0.172726\n",
            "[1000]\ttraining's l1: 0.00623303\tvalid_1's l1: 0.171875\n",
            "[1200]\ttraining's l1: 0.00403683\tvalid_1's l1: 0.171293\n",
            "[1400]\ttraining's l1: 0.00278725\tvalid_1's l1: 0.170993\n",
            "[1600]\ttraining's l1: 0.00201843\tvalid_1's l1: 0.170838\n",
            "[1800]\ttraining's l1: 0.00151981\tvalid_1's l1: 0.170737\n",
            "[2000]\ttraining's l1: 0.00117919\tvalid_1's l1: 0.170679\n",
            "[2200]\ttraining's l1: 0.000938194\tvalid_1's l1: 0.170618\n",
            "[2400]\ttraining's l1: 0.000751093\tvalid_1's l1: 0.170593\n",
            "[2600]\ttraining's l1: 0.000607787\tvalid_1's l1: 0.17057\n",
            "[2800]\ttraining's l1: 0.00050067\tvalid_1's l1: 0.170562\n",
            "[3000]\ttraining's l1: 0.000413044\tvalid_1's l1: 0.170541\n",
            "[3200]\ttraining's l1: 0.00034484\tvalid_1's l1: 0.170534\n",
            "[3400]\ttraining's l1: 0.000287495\tvalid_1's l1: 0.170523\n",
            "[3600]\ttraining's l1: 0.000241552\tvalid_1's l1: 0.170519\n",
            "Early stopping, best iteration is:\n",
            "[3550]\ttraining's l1: 0.000252922\tvalid_1's l1: 0.170517\n",
            "\n",
            "✅ CV MAE: 0.1808025198\n",
            "✅ submission_stable_no_catboost16.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# ------------------------------\n",
        "# 1. 경로\n",
        "# ------------------------------\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "SUB_CSV   = \"sample_submission.csv\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2. 데이터 로드\n",
        "# ------------------------------\n",
        "def load_data(train_path, test_path, sub_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    submission = pd.read_csv(sub_path)\n",
        "    print(f\"Train: {train.shape}, Test: {test.shape}, Submission: {submission.shape}\")\n",
        "    return train, test, submission\n",
        "\n",
        "# ------------------------------\n",
        "# 3. 전처리 + 파생변수\n",
        "# ------------------------------\n",
        "def preprocess(train, test, target_col=\"stress_score\"):\n",
        "    train_id, test_id = None, None\n",
        "    if \"ID\" in train.columns:\n",
        "        train_id, test_id = train[\"ID\"], test[\"ID\"]\n",
        "        train = train.drop(columns=[\"ID\"])\n",
        "        test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    if target_col in num_cols: num_cols.remove(target_col)\n",
        "    if target_col in cat_cols: cat_cols.remove(target_col)\n",
        "\n",
        "    # 숫자 결측치 처리\n",
        "    for col in num_cols:\n",
        "        train[col] = pd.to_numeric(train[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "        test[col]  = pd.to_numeric(test[col], errors=\"coerce\").fillna(train[col].mean())\n",
        "\n",
        "    # 범주형 결측치 처리\n",
        "    for col in cat_cols:\n",
        "        mode = train[col].mode()[0]\n",
        "        train[col] = train[col].fillna(mode)\n",
        "        test[col]  = test[col].fillna(mode)\n",
        "\n",
        "    # 파생변수\n",
        "    for df in [train, test]:\n",
        "        df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"]/100)**2 + 1e-6)\n",
        "        df[\"bp_ratio\"] = df[\"systolic_blood_pressure\"] / (df[\"diastolic_blood_pressure\"] + 1e-6)\n",
        "        df[\"pulse_pressure\"] = df[\"systolic_blood_pressure\"] - df[\"diastolic_blood_pressure\"]\n",
        "        df[\"activity_sleep\"] = pd.to_numeric(df[\"activity\"], errors=\"coerce\").fillna(0) * pd.to_numeric(df[\"sleep_pattern\"], errors=\"coerce\").fillna(0)\n",
        "        df[\"age_weight_ratio\"] = df[\"age\"] / (df[\"weight\"] + 1e-6)\n",
        "        df[\"height_weight_interaction\"] = df[\"height\"] * df[\"weight\"]\n",
        "\n",
        "    # 숫자형 정규화\n",
        "    pt = PowerTransformer()\n",
        "    train[num_cols] = pt.fit_transform(train[num_cols])\n",
        "    test[num_cols] = pt.transform(test[num_cols])\n",
        "\n",
        "    # 원-핫 인코딩\n",
        "    train = pd.get_dummies(train, columns=cat_cols)\n",
        "    test = pd.get_dummies(test, columns=cat_cols)\n",
        "    test = test.reindex(columns=train.drop(columns=[target_col]).columns, fill_value=0)\n",
        "\n",
        "    X = train.drop(columns=[target_col])\n",
        "    y = train[target_col]\n",
        "    return X, y, test, train_id, test_id\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 모델 학습 + 예측 (KFold 10 + LGBM + ExtraTrees)\n",
        "# ------------------------------\n",
        "def train_and_predict(X, y, test, n_splits=10, seed=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(test))\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n===== Fold {fold+1} =====\")\n",
        "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "        lgb_params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 64,\n",
        "            \"max_depth\": 8,\n",
        "            \"feature_fraction\": 0.85,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"lambda_l1\": 0.5,\n",
        "            \"lambda_l2\": 0.5,\n",
        "            \"seed\": seed,\n",
        "            \"verbose\": -1\n",
        "        }\n",
        "        lgb_model = lgb.train(\n",
        "            lgb_params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_val],\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=200)]\n",
        "        )\n",
        "\n",
        "        # ExtraTrees\n",
        "        et_model = ExtraTreesRegressor(\n",
        "            n_estimators=800,\n",
        "            max_depth=None,\n",
        "            min_samples_split=4,\n",
        "            min_samples_leaf=2,\n",
        "            n_jobs=-1,\n",
        "            random_state=seed\n",
        "        )\n",
        "        et_model.fit(X_train, y_train)\n",
        "\n",
        "        # 앙상블 예측\n",
        "        oof_preds[val_idx] += 0.55*lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration) + 0.45*et_model.predict(X_val)\n",
        "        test_preds += (0.55*lgb_model.predict(test, num_iteration=lgb_model.best_iteration) + 0.45*et_model.predict(test)) / n_splits\n",
        "\n",
        "    mae = mean_absolute_error(y, oof_preds)\n",
        "    print(f\"\\n✅ CV MAE: {mae:.10f}\")\n",
        "    return test_preds\n",
        "\n",
        "# ------------------------------\n",
        "# 5. 제출 저장\n",
        "# ------------------------------\n",
        "def save_submission(submission, preds, target_col=\"stress_score\", test_id=None):\n",
        "    if target_col not in submission.columns:\n",
        "        submission[target_col] = 0.0\n",
        "    submission[target_col] = preds\n",
        "    if test_id is not None:\n",
        "        submission[\"ID\"] = test_id\n",
        "    submission.to_csv(\"submission_ensemble_kfold17.csv\", index=False)\n",
        "    print(\"✅ submission_ensemble_kfold17.csv 저장 완료\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. 실행\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    train, test, submission = load_data(TRAIN_CSV, TEST_CSV, SUB_CSV)\n",
        "    X, y, test_proc, train_id, test_id = preprocess(train, test, target_col=\"stress_score\")\n",
        "    preds = train_and_predict(X, y, test_proc, n_splits=10, seed=42)\n",
        "    save_submission(submission, preds, target_col=\"stress_score\", test_id=test_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Xifa1tBob8",
        "outputId": "d4eeb6df-4c5a-43fd-cad1-f1f64326397f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3000, 18), Test: (3000, 17), Submission: (3000, 2)\n",
            "\n",
            "===== Fold 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.160303\tvalid_1's l1: 0.201423\n",
            "[400]\ttraining's l1: 0.108391\tvalid_1's l1: 0.187561\n",
            "[600]\ttraining's l1: 0.0771801\tvalid_1's l1: 0.178092\n",
            "[800]\ttraining's l1: 0.0597429\tvalid_1's l1: 0.173022\n",
            "[1000]\ttraining's l1: 0.0477679\tvalid_1's l1: 0.169625\n",
            "[1200]\ttraining's l1: 0.0402488\tvalid_1's l1: 0.167466\n",
            "[1400]\ttraining's l1: 0.0356047\tvalid_1's l1: 0.166186\n",
            "[1600]\ttraining's l1: 0.0322667\tvalid_1's l1: 0.165188\n",
            "[1800]\ttraining's l1: 0.0297167\tvalid_1's l1: 0.164368\n",
            "[2000]\ttraining's l1: 0.0278391\tvalid_1's l1: 0.163772\n",
            "[2200]\ttraining's l1: 0.0264257\tvalid_1's l1: 0.163468\n",
            "[2400]\ttraining's l1: 0.0252323\tvalid_1's l1: 0.163153\n",
            "[2600]\ttraining's l1: 0.0242368\tvalid_1's l1: 0.162739\n",
            "[2800]\ttraining's l1: 0.0233145\tvalid_1's l1: 0.162503\n",
            "[3000]\ttraining's l1: 0.0225815\tvalid_1's l1: 0.162306\n",
            "[3200]\ttraining's l1: 0.0219829\tvalid_1's l1: 0.162139\n",
            "[3400]\ttraining's l1: 0.0214103\tvalid_1's l1: 0.161998\n",
            "[3600]\ttraining's l1: 0.0209194\tvalid_1's l1: 0.161766\n",
            "[3800]\ttraining's l1: 0.0204216\tvalid_1's l1: 0.161506\n",
            "[4000]\ttraining's l1: 0.0200589\tvalid_1's l1: 0.161392\n",
            "[4200]\ttraining's l1: 0.019668\tvalid_1's l1: 0.16129\n",
            "Early stopping, best iteration is:\n",
            "[4299]\ttraining's l1: 0.0195095\tvalid_1's l1: 0.161225\n",
            "\n",
            "===== Fold 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.161463\tvalid_1's l1: 0.223762\n",
            "[400]\ttraining's l1: 0.108121\tvalid_1's l1: 0.204606\n",
            "[600]\ttraining's l1: 0.0782353\tvalid_1's l1: 0.191423\n",
            "[800]\ttraining's l1: 0.0593635\tvalid_1's l1: 0.185521\n",
            "[1000]\ttraining's l1: 0.0476324\tvalid_1's l1: 0.180587\n",
            "[1200]\ttraining's l1: 0.0404501\tvalid_1's l1: 0.17786\n",
            "[1400]\ttraining's l1: 0.0354113\tvalid_1's l1: 0.176017\n",
            "[1600]\ttraining's l1: 0.032186\tvalid_1's l1: 0.174431\n",
            "[1800]\ttraining's l1: 0.0297157\tvalid_1's l1: 0.173371\n",
            "[2000]\ttraining's l1: 0.0279092\tvalid_1's l1: 0.172632\n",
            "[2200]\ttraining's l1: 0.0264456\tvalid_1's l1: 0.172116\n",
            "[2400]\ttraining's l1: 0.0252573\tvalid_1's l1: 0.171566\n",
            "[2600]\ttraining's l1: 0.0242885\tvalid_1's l1: 0.171131\n",
            "[2800]\ttraining's l1: 0.0234274\tvalid_1's l1: 0.170667\n",
            "[3000]\ttraining's l1: 0.0226856\tvalid_1's l1: 0.17027\n",
            "[3200]\ttraining's l1: 0.0220442\tvalid_1's l1: 0.169993\n",
            "[3400]\ttraining's l1: 0.0215259\tvalid_1's l1: 0.169731\n",
            "[3600]\ttraining's l1: 0.0210007\tvalid_1's l1: 0.169422\n",
            "[3800]\ttraining's l1: 0.0205641\tvalid_1's l1: 0.169156\n",
            "[4000]\ttraining's l1: 0.0201372\tvalid_1's l1: 0.168966\n",
            "[4200]\ttraining's l1: 0.0197583\tvalid_1's l1: 0.168705\n",
            "[4400]\ttraining's l1: 0.0194133\tvalid_1's l1: 0.168563\n",
            "[4600]\ttraining's l1: 0.0191133\tvalid_1's l1: 0.168436\n",
            "[4800]\ttraining's l1: 0.0188019\tvalid_1's l1: 0.168314\n",
            "[5000]\ttraining's l1: 0.0185523\tvalid_1's l1: 0.168113\n",
            "[5200]\ttraining's l1: 0.0183184\tvalid_1's l1: 0.168037\n",
            "Early stopping, best iteration is:\n",
            "[5281]\ttraining's l1: 0.0182354\tvalid_1's l1: 0.167996\n",
            "\n",
            "===== Fold 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.157231\tvalid_1's l1: 0.210331\n",
            "[400]\ttraining's l1: 0.107593\tvalid_1's l1: 0.191404\n",
            "[600]\ttraining's l1: 0.0777498\tvalid_1's l1: 0.180667\n",
            "[800]\ttraining's l1: 0.0593641\tvalid_1's l1: 0.173975\n",
            "[1000]\ttraining's l1: 0.0481\tvalid_1's l1: 0.169234\n",
            "[1200]\ttraining's l1: 0.040932\tvalid_1's l1: 0.166449\n",
            "[1400]\ttraining's l1: 0.036023\tvalid_1's l1: 0.164376\n",
            "[1600]\ttraining's l1: 0.0325858\tvalid_1's l1: 0.163237\n",
            "[1800]\ttraining's l1: 0.0300092\tvalid_1's l1: 0.162018\n",
            "[2000]\ttraining's l1: 0.0281699\tvalid_1's l1: 0.161295\n",
            "[2200]\ttraining's l1: 0.0265539\tvalid_1's l1: 0.16058\n",
            "[2400]\ttraining's l1: 0.0254348\tvalid_1's l1: 0.160095\n",
            "[2600]\ttraining's l1: 0.024399\tvalid_1's l1: 0.159526\n",
            "[2800]\ttraining's l1: 0.023566\tvalid_1's l1: 0.159149\n",
            "[3000]\ttraining's l1: 0.0228203\tvalid_1's l1: 0.158834\n",
            "[3200]\ttraining's l1: 0.0220558\tvalid_1's l1: 0.158564\n",
            "[3400]\ttraining's l1: 0.02144\tvalid_1's l1: 0.158205\n",
            "[3600]\ttraining's l1: 0.0209238\tvalid_1's l1: 0.158105\n",
            "[3800]\ttraining's l1: 0.0204834\tvalid_1's l1: 0.15798\n",
            "[4000]\ttraining's l1: 0.0200338\tvalid_1's l1: 0.157701\n",
            "[4200]\ttraining's l1: 0.0197007\tvalid_1's l1: 0.15759\n",
            "[4400]\ttraining's l1: 0.0193676\tvalid_1's l1: 0.157531\n",
            "Early stopping, best iteration is:\n",
            "[4310]\ttraining's l1: 0.0195077\tvalid_1's l1: 0.157496\n",
            "\n",
            "===== Fold 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.159274\tvalid_1's l1: 0.224032\n",
            "[400]\ttraining's l1: 0.109537\tvalid_1's l1: 0.212332\n",
            "[600]\ttraining's l1: 0.0779227\tvalid_1's l1: 0.203979\n",
            "[800]\ttraining's l1: 0.0585631\tvalid_1's l1: 0.198547\n",
            "[1000]\ttraining's l1: 0.0470648\tvalid_1's l1: 0.194253\n",
            "[1200]\ttraining's l1: 0.0399816\tvalid_1's l1: 0.191814\n",
            "[1400]\ttraining's l1: 0.0350723\tvalid_1's l1: 0.190401\n",
            "[1600]\ttraining's l1: 0.0316788\tvalid_1's l1: 0.189034\n",
            "[1800]\ttraining's l1: 0.0293078\tvalid_1's l1: 0.188287\n",
            "[2000]\ttraining's l1: 0.0275122\tvalid_1's l1: 0.187447\n",
            "[2200]\ttraining's l1: 0.0259656\tvalid_1's l1: 0.186946\n",
            "[2400]\ttraining's l1: 0.0247615\tvalid_1's l1: 0.186642\n",
            "[2600]\ttraining's l1: 0.023807\tvalid_1's l1: 0.186293\n",
            "[2800]\ttraining's l1: 0.022933\tvalid_1's l1: 0.185919\n",
            "[3000]\ttraining's l1: 0.0222466\tvalid_1's l1: 0.18559\n",
            "[3200]\ttraining's l1: 0.0216707\tvalid_1's l1: 0.18538\n",
            "[3400]\ttraining's l1: 0.0211059\tvalid_1's l1: 0.185116\n",
            "[3600]\ttraining's l1: 0.0205607\tvalid_1's l1: 0.184879\n",
            "[3800]\ttraining's l1: 0.0201442\tvalid_1's l1: 0.184684\n",
            "[4000]\ttraining's l1: 0.0197597\tvalid_1's l1: 0.184605\n",
            "[4200]\ttraining's l1: 0.0193822\tvalid_1's l1: 0.184371\n",
            "[4400]\ttraining's l1: 0.0190217\tvalid_1's l1: 0.184208\n",
            "[4600]\ttraining's l1: 0.0187351\tvalid_1's l1: 0.184058\n",
            "Early stopping, best iteration is:\n",
            "[4688]\ttraining's l1: 0.0186056\tvalid_1's l1: 0.18398\n",
            "\n",
            "===== Fold 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.162085\tvalid_1's l1: 0.229792\n",
            "[400]\ttraining's l1: 0.109186\tvalid_1's l1: 0.216752\n",
            "[600]\ttraining's l1: 0.0782952\tvalid_1's l1: 0.20805\n",
            "[800]\ttraining's l1: 0.0597243\tvalid_1's l1: 0.200497\n",
            "[1000]\ttraining's l1: 0.0485429\tvalid_1's l1: 0.196252\n",
            "[1200]\ttraining's l1: 0.0409256\tvalid_1's l1: 0.193589\n",
            "[1400]\ttraining's l1: 0.03601\tvalid_1's l1: 0.191359\n",
            "[1600]\ttraining's l1: 0.0326079\tvalid_1's l1: 0.189859\n",
            "[1800]\ttraining's l1: 0.0300959\tvalid_1's l1: 0.189029\n",
            "[2000]\ttraining's l1: 0.0281506\tvalid_1's l1: 0.188262\n",
            "[2200]\ttraining's l1: 0.0267277\tvalid_1's l1: 0.187476\n",
            "[2400]\ttraining's l1: 0.0255878\tvalid_1's l1: 0.186937\n",
            "[2600]\ttraining's l1: 0.0245859\tvalid_1's l1: 0.186538\n",
            "[2800]\ttraining's l1: 0.0237057\tvalid_1's l1: 0.186064\n",
            "[3000]\ttraining's l1: 0.0229691\tvalid_1's l1: 0.185756\n",
            "[3200]\ttraining's l1: 0.0223093\tvalid_1's l1: 0.185463\n",
            "[3400]\ttraining's l1: 0.0217619\tvalid_1's l1: 0.185259\n",
            "[3600]\ttraining's l1: 0.0212592\tvalid_1's l1: 0.185065\n",
            "[3800]\ttraining's l1: 0.020789\tvalid_1's l1: 0.184947\n",
            "[4000]\ttraining's l1: 0.0203525\tvalid_1's l1: 0.184754\n",
            "[4200]\ttraining's l1: 0.0199533\tvalid_1's l1: 0.184568\n",
            "[4400]\ttraining's l1: 0.0196513\tvalid_1's l1: 0.184521\n",
            "[4600]\ttraining's l1: 0.0193217\tvalid_1's l1: 0.184371\n",
            "[4800]\ttraining's l1: 0.0190271\tvalid_1's l1: 0.184233\n",
            "[5000]\ttraining's l1: 0.0187804\tvalid_1's l1: 0.184119\n",
            "Early stopping, best iteration is:\n",
            "[5078]\ttraining's l1: 0.0187013\tvalid_1's l1: 0.184045\n",
            "\n",
            "===== Fold 6 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.154836\tvalid_1's l1: 0.223919\n",
            "[400]\ttraining's l1: 0.107792\tvalid_1's l1: 0.206049\n",
            "[600]\ttraining's l1: 0.0787164\tvalid_1's l1: 0.193071\n",
            "[800]\ttraining's l1: 0.0591785\tvalid_1's l1: 0.18487\n",
            "[1000]\ttraining's l1: 0.0477222\tvalid_1's l1: 0.179853\n",
            "[1200]\ttraining's l1: 0.0402408\tvalid_1's l1: 0.176695\n",
            "[1400]\ttraining's l1: 0.0355314\tvalid_1's l1: 0.174476\n",
            "[1600]\ttraining's l1: 0.0321507\tvalid_1's l1: 0.172653\n",
            "[1800]\ttraining's l1: 0.0295853\tvalid_1's l1: 0.171126\n",
            "[2000]\ttraining's l1: 0.0276298\tvalid_1's l1: 0.170181\n",
            "[2200]\ttraining's l1: 0.0261094\tvalid_1's l1: 0.169447\n",
            "[2400]\ttraining's l1: 0.0249166\tvalid_1's l1: 0.168815\n",
            "[2600]\ttraining's l1: 0.0239399\tvalid_1's l1: 0.168396\n",
            "[2800]\ttraining's l1: 0.0230273\tvalid_1's l1: 0.167893\n",
            "[3000]\ttraining's l1: 0.022292\tvalid_1's l1: 0.167502\n",
            "[3200]\ttraining's l1: 0.0217022\tvalid_1's l1: 0.167149\n",
            "[3400]\ttraining's l1: 0.0211211\tvalid_1's l1: 0.166885\n",
            "[3600]\ttraining's l1: 0.0206227\tvalid_1's l1: 0.166637\n",
            "[3800]\ttraining's l1: 0.0201727\tvalid_1's l1: 0.166443\n",
            "Early stopping, best iteration is:\n",
            "[3891]\ttraining's l1: 0.0199899\tvalid_1's l1: 0.166332\n",
            "\n",
            "===== Fold 7 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.158384\tvalid_1's l1: 0.23038\n",
            "[400]\ttraining's l1: 0.107089\tvalid_1's l1: 0.215864\n",
            "[600]\ttraining's l1: 0.0766966\tvalid_1's l1: 0.205021\n",
            "[800]\ttraining's l1: 0.0578553\tvalid_1's l1: 0.198537\n",
            "[1000]\ttraining's l1: 0.0468765\tvalid_1's l1: 0.194239\n",
            "[1200]\ttraining's l1: 0.0397568\tvalid_1's l1: 0.191458\n",
            "[1400]\ttraining's l1: 0.0348674\tvalid_1's l1: 0.188982\n",
            "[1600]\ttraining's l1: 0.0315796\tvalid_1's l1: 0.187583\n",
            "[1800]\ttraining's l1: 0.029228\tvalid_1's l1: 0.186808\n",
            "[2000]\ttraining's l1: 0.0273465\tvalid_1's l1: 0.185746\n",
            "[2200]\ttraining's l1: 0.0258729\tvalid_1's l1: 0.185008\n",
            "[2400]\ttraining's l1: 0.0247682\tvalid_1's l1: 0.184448\n",
            "[2600]\ttraining's l1: 0.0237604\tvalid_1's l1: 0.183928\n",
            "[2800]\ttraining's l1: 0.0229442\tvalid_1's l1: 0.18358\n",
            "[3000]\ttraining's l1: 0.0222596\tvalid_1's l1: 0.183222\n",
            "[3200]\ttraining's l1: 0.0215495\tvalid_1's l1: 0.182893\n",
            "[3400]\ttraining's l1: 0.0210505\tvalid_1's l1: 0.182574\n",
            "[3600]\ttraining's l1: 0.0205634\tvalid_1's l1: 0.182403\n",
            "[3800]\ttraining's l1: 0.0201216\tvalid_1's l1: 0.182226\n",
            "[4000]\ttraining's l1: 0.0197368\tvalid_1's l1: 0.182055\n",
            "[4200]\ttraining's l1: 0.0193992\tvalid_1's l1: 0.181939\n",
            "[4400]\ttraining's l1: 0.01908\tvalid_1's l1: 0.181763\n",
            "[4600]\ttraining's l1: 0.0187683\tvalid_1's l1: 0.181544\n",
            "[4800]\ttraining's l1: 0.0184646\tvalid_1's l1: 0.181417\n",
            "[5000]\ttraining's l1: 0.0182143\tvalid_1's l1: 0.181282\n",
            "[5200]\ttraining's l1: 0.0179559\tvalid_1's l1: 0.181219\n",
            "Early stopping, best iteration is:\n",
            "[5180]\ttraining's l1: 0.0179713\tvalid_1's l1: 0.181207\n",
            "\n",
            "===== Fold 8 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.156666\tvalid_1's l1: 0.230229\n",
            "[400]\ttraining's l1: 0.10779\tvalid_1's l1: 0.214608\n",
            "[600]\ttraining's l1: 0.0784007\tvalid_1's l1: 0.204924\n",
            "[800]\ttraining's l1: 0.0591947\tvalid_1's l1: 0.198324\n",
            "[1000]\ttraining's l1: 0.0479753\tvalid_1's l1: 0.193736\n",
            "[1200]\ttraining's l1: 0.0405426\tvalid_1's l1: 0.190318\n",
            "[1400]\ttraining's l1: 0.0355559\tvalid_1's l1: 0.187958\n",
            "[1600]\ttraining's l1: 0.0319872\tvalid_1's l1: 0.186419\n",
            "[1800]\ttraining's l1: 0.0294731\tvalid_1's l1: 0.185276\n",
            "[2000]\ttraining's l1: 0.027644\tvalid_1's l1: 0.184492\n",
            "[2200]\ttraining's l1: 0.0261287\tvalid_1's l1: 0.183792\n",
            "[2400]\ttraining's l1: 0.024929\tvalid_1's l1: 0.183447\n",
            "[2600]\ttraining's l1: 0.0239217\tvalid_1's l1: 0.183077\n",
            "[2800]\ttraining's l1: 0.0230646\tvalid_1's l1: 0.182758\n",
            "[3000]\ttraining's l1: 0.0223376\tvalid_1's l1: 0.182555\n",
            "[3200]\ttraining's l1: 0.0216976\tvalid_1's l1: 0.182227\n",
            "[3400]\ttraining's l1: 0.0211753\tvalid_1's l1: 0.181933\n",
            "[3600]\ttraining's l1: 0.0206913\tvalid_1's l1: 0.1817\n",
            "[3800]\ttraining's l1: 0.0202249\tvalid_1's l1: 0.181581\n",
            "Early stopping, best iteration is:\n",
            "[3739]\ttraining's l1: 0.0203729\tvalid_1's l1: 0.18152\n",
            "\n",
            "===== Fold 9 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.154951\tvalid_1's l1: 0.219732\n",
            "[400]\ttraining's l1: 0.107762\tvalid_1's l1: 0.202786\n",
            "[600]\ttraining's l1: 0.0772759\tvalid_1's l1: 0.192507\n",
            "[800]\ttraining's l1: 0.0592186\tvalid_1's l1: 0.185633\n",
            "[1000]\ttraining's l1: 0.0477546\tvalid_1's l1: 0.180973\n",
            "[1200]\ttraining's l1: 0.0406071\tvalid_1's l1: 0.178434\n",
            "[1400]\ttraining's l1: 0.0356582\tvalid_1's l1: 0.176312\n",
            "[1600]\ttraining's l1: 0.0322442\tvalid_1's l1: 0.175077\n",
            "[1800]\ttraining's l1: 0.0297219\tvalid_1's l1: 0.173947\n",
            "[2000]\ttraining's l1: 0.0277912\tvalid_1's l1: 0.173137\n",
            "[2200]\ttraining's l1: 0.026345\tvalid_1's l1: 0.172378\n",
            "[2400]\ttraining's l1: 0.0251815\tvalid_1's l1: 0.171584\n",
            "[2600]\ttraining's l1: 0.0241579\tvalid_1's l1: 0.17102\n",
            "[2800]\ttraining's l1: 0.023348\tvalid_1's l1: 0.170712\n",
            "[3000]\ttraining's l1: 0.0226234\tvalid_1's l1: 0.170317\n",
            "[3200]\ttraining's l1: 0.0220129\tvalid_1's l1: 0.169997\n",
            "[3400]\ttraining's l1: 0.0214017\tvalid_1's l1: 0.169782\n",
            "[3600]\ttraining's l1: 0.0208867\tvalid_1's l1: 0.169561\n",
            "Early stopping, best iteration is:\n",
            "[3661]\ttraining's l1: 0.0207415\tvalid_1's l1: 0.169398\n",
            "\n",
            "===== Fold 10 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\ttraining's l1: 0.15885\tvalid_1's l1: 0.217939\n",
            "[400]\ttraining's l1: 0.109065\tvalid_1's l1: 0.202586\n",
            "[600]\ttraining's l1: 0.0779833\tvalid_1's l1: 0.194456\n",
            "[800]\ttraining's l1: 0.0593221\tvalid_1's l1: 0.18953\n",
            "[1000]\ttraining's l1: 0.0477254\tvalid_1's l1: 0.184996\n",
            "[1200]\ttraining's l1: 0.0405442\tvalid_1's l1: 0.182012\n",
            "[1400]\ttraining's l1: 0.0355687\tvalid_1's l1: 0.179785\n",
            "[1600]\ttraining's l1: 0.0320628\tvalid_1's l1: 0.178235\n",
            "[1800]\ttraining's l1: 0.0296373\tvalid_1's l1: 0.177007\n",
            "[2000]\ttraining's l1: 0.0276933\tvalid_1's l1: 0.176238\n",
            "[2200]\ttraining's l1: 0.0262588\tvalid_1's l1: 0.175639\n",
            "[2400]\ttraining's l1: 0.0250427\tvalid_1's l1: 0.17527\n",
            "[2600]\ttraining's l1: 0.0240618\tvalid_1's l1: 0.174915\n",
            "[2800]\ttraining's l1: 0.0232562\tvalid_1's l1: 0.174494\n",
            "[3000]\ttraining's l1: 0.0224522\tvalid_1's l1: 0.174321\n",
            "[3200]\ttraining's l1: 0.0218515\tvalid_1's l1: 0.173996\n",
            "[3400]\ttraining's l1: 0.0212688\tvalid_1's l1: 0.173861\n",
            "[3600]\ttraining's l1: 0.0207901\tvalid_1's l1: 0.173718\n",
            "Early stopping, best iteration is:\n",
            "[3522]\ttraining's l1: 0.0209835\tvalid_1's l1: 0.173692\n",
            "\n",
            "✅ CV MAE: 0.1759392782\n",
            "✅ submission_ensemble_kfold17.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsWQTYrCBoTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgbOwllP19Ys",
        "outputId": "4346936d-46b5-408e-f232-a4413a0c39a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ID', 'gender', 'age', 'height', 'weight', 'cholesterol', 'systolic_blood_pressure', 'diastolic_blood_pressure', 'glucose', 'bone_density', 'activity', 'smoke_status', 'medical_history', 'family_medical_history', 'sleep_pattern', 'edu_level', 'mean_working', 'stress_score']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "print(train.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E51jY1PN08rt",
        "outputId": "75373f45-a00e-428e-b61d-00c13fbc0e22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'gender', 'age', 'height', 'weight', 'cholesterol',\n",
            "       'systolic_blood_pressure', 'diastolic_blood_pressure', 'glucose',\n",
            "       'bone_density', 'activity', 'smoke_status', 'medical_history',\n",
            "       'family_medical_history', 'sleep_pattern', 'edu_level', 'mean_working',\n",
            "       'stress_score'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ]
}